{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 13:00:43.185908: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-02 13:00:43.379042: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-02 13:00:44.139322: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 13:00:46.673853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>20.209999</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>18.086271</td>\n",
       "      <td>30182600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>19.809999</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>18.738441</td>\n",
       "      <td>30552600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>20.330000</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>20.170000</td>\n",
       "      <td>20.430000</td>\n",
       "      <td>18.766001</td>\n",
       "      <td>36141000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>20.480000</td>\n",
       "      <td>20.670000</td>\n",
       "      <td>19.950001</td>\n",
       "      <td>20.080000</td>\n",
       "      <td>18.444506</td>\n",
       "      <td>28069600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.230000</td>\n",
       "      <td>19.459999</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>17.911745</td>\n",
       "      <td>29091300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2013-01-02  19.990000  20.209999  19.690001  19.690001  18.086271   \n",
       "1  2013-01-03  19.809999  20.400000  19.700001  20.400000  18.738441   \n",
       "2  2013-01-04  20.330000  20.620001  20.170000  20.430000  18.766001   \n",
       "3  2013-01-07  20.480000  20.670000  19.950001  20.080000  18.444506   \n",
       "4  2013-01-08  20.110001  20.230000  19.459999  19.500000  17.911745   \n",
       "\n",
       "       Volume  \n",
       "0  30182600.0  \n",
       "1  30552600.0  \n",
       "2  36141000.0  \n",
       "3  28069600.0  \n",
       "4  29091300.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_train_csv = pd.read_csv('bases/petr4_treinamento.csv')\n",
    "base_train_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.516966</td>\n",
       "      <td>33461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>16.490000</td>\n",
       "      <td>16.719999</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.666668</td>\n",
       "      <td>55940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>16.780001</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>16.620001</td>\n",
       "      <td>16.730000</td>\n",
       "      <td>16.696608</td>\n",
       "      <td>37064900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>16.570000</td>\n",
       "      <td>16.830000</td>\n",
       "      <td>16.796408</td>\n",
       "      <td>26958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>16.740000</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.709999</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.996010</td>\n",
       "      <td>28400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2018-01-02  16.190001  16.549999  16.190001  16.549999  16.516966  33461800\n",
       "1  2018-01-03  16.490000  16.719999  16.370001  16.700001  16.666668  55940900\n",
       "2  2018-01-04  16.780001  16.959999  16.620001  16.730000  16.696608  37064900\n",
       "3  2018-01-05  16.700001  16.860001  16.570000  16.830000  16.796408  26958200\n",
       "4  2018-01-08  16.740000  17.030001  16.709999  17.030001  16.996010  28400000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_test_csv = pd.read_csv('bases/petr4_teste.csv')\n",
    "base_test_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train_csv = base_train_csv.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9990000e+01, 2.0209999e+01, 1.9690001e+01, 1.9690001e+01,\n",
       "        1.8086271e+01, 3.0182600e+07],\n",
       "       [1.9809999e+01, 2.0400000e+01, 1.9700001e+01, 2.0400000e+01,\n",
       "        1.8738441e+01, 3.0552600e+07],\n",
       "       [2.0330000e+01, 2.0620001e+01, 2.0170000e+01, 2.0430000e+01,\n",
       "        1.8766001e+01, 3.6141000e+07],\n",
       "       ...,\n",
       "       [1.5990000e+01, 1.6139999e+01, 1.5980000e+01, 1.6049999e+01,\n",
       "        1.6017963e+01, 2.3552200e+07],\n",
       "       [1.6100000e+01, 1.6129999e+01, 1.6000000e+01, 1.6100000e+01,\n",
       "        1.6067865e+01, 1.9011500e+07],\n",
       "       [1.6100000e+01, 1.6100000e+01, 1.6100000e+01, 1.6100000e+01,\n",
       "        1.6067865e+01, 0.0000000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_train = base_train_csv.iloc[:, 1:7].values\n",
    "base_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler(feature_range=(0, 1))\n",
    "base_train_ = normalizer.fit_transform(base_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevs_normalizer = MinMaxScaler(feature_range=(0, 1))\n",
    "base_train_ = prevs_normalizer.fit_transform(base_train[:, 0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76501938],\n",
       "       [0.7562984 ],\n",
       "       [0.78149225],\n",
       "       ...,\n",
       "       [0.57122093],\n",
       "       [0.57655039],\n",
       "       [0.57655039]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_train_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "antecipator = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [] # Previsores\n",
    "y_train = [] # Preços reais\n",
    "for i in range(antecipator, base_train_.shape[0]): # 90 preços anteriores para prever intervalo atual\n",
    "    x_train.append(base_train_[i - antecipator:i, 0:base_train_.shape[1]])\n",
    "    y_train.append(base_train_[i, 0])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.76501938],\n",
       "        [0.7562984 ],\n",
       "        [0.78149225],\n",
       "        ...,\n",
       "        [0.74273261],\n",
       "        [0.74127907],\n",
       "        [0.74224806]],\n",
       "\n",
       "       [[0.7562984 ],\n",
       "        [0.78149225],\n",
       "        [0.78875969],\n",
       "        ...,\n",
       "        [0.74127907],\n",
       "        [0.74224806],\n",
       "        [0.76114341]],\n",
       "\n",
       "       [[0.78149225],\n",
       "        [0.78875969],\n",
       "        [0.77083338],\n",
       "        ...,\n",
       "        [0.74224806],\n",
       "        [0.76114341],\n",
       "        [0.76114341]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.46414729],\n",
       "        [0.46414729],\n",
       "        [0.46850775],\n",
       "        ...,\n",
       "        [0.55959302],\n",
       "        [0.55959302],\n",
       "        [0.55959302]],\n",
       "\n",
       "       [[0.46414729],\n",
       "        [0.46850775],\n",
       "        [0.47141473],\n",
       "        ...,\n",
       "        [0.55959302],\n",
       "        [0.55959302],\n",
       "        [0.57122093]],\n",
       "\n",
       "       [[0.46850775],\n",
       "        [0.47141473],\n",
       "        [0.46317829],\n",
       "        ...,\n",
       "        [0.55959302],\n",
       "        [0.57122093],\n",
       "        [0.57655039]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 90, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input((x_train.shape[1], x_train.shape[2])))\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "          \n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "          \n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m40,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m30,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,451</span> (435.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,451\u001b[0m (435.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,451</span> (435.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,451\u001b[0m (435.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=1e-10,\n",
    "    patience=10,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_plateau = ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='checkpoints/weights_prev_one.keras',\n",
    "    monitor='loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621ms/step - loss: 0.0545 - mean_absolute_error: 0.1763\n",
      "Epoch 1: loss improved from inf to 0.02975, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 632ms/step - loss: 0.0538 - mean_absolute_error: 0.1751 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 0.0123 - mean_absolute_error: 0.0835\n",
      "Epoch 2: loss improved from 0.02975 to 0.01392, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 232ms/step - loss: 0.0124 - mean_absolute_error: 0.0836 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.0131 - mean_absolute_error: 0.0915\n",
      "Epoch 3: loss improved from 0.01392 to 0.01199, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 293ms/step - loss: 0.0131 - mean_absolute_error: 0.0913 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: 0.0112 - mean_absolute_error: 0.0804\n",
      "Epoch 4: loss improved from 0.01199 to 0.01052, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 428ms/step - loss: 0.0112 - mean_absolute_error: 0.0804 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - loss: 0.0110 - mean_absolute_error: 0.0809\n",
      "Epoch 5: loss improved from 0.01052 to 0.00978, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 526ms/step - loss: 0.0109 - mean_absolute_error: 0.0807 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - loss: 0.0105 - mean_absolute_error: 0.0784\n",
      "Epoch 6: loss improved from 0.00978 to 0.00919, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 567ms/step - loss: 0.0105 - mean_absolute_error: 0.0783 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - loss: 0.0087 - mean_absolute_error: 0.0719\n",
      "Epoch 7: loss did not improve from 0.00919\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 496ms/step - loss: 0.0087 - mean_absolute_error: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: 0.0066 - mean_absolute_error: 0.0618\n",
      "Epoch 8: loss improved from 0.00919 to 0.00749, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 374ms/step - loss: 0.0066 - mean_absolute_error: 0.0619 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.0080 - mean_absolute_error: 0.0691\n",
      "Epoch 9: loss did not improve from 0.00749\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 179ms/step - loss: 0.0080 - mean_absolute_error: 0.0691 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.0073 - mean_absolute_error: 0.0660\n",
      "Epoch 10: loss improved from 0.00749 to 0.00705, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 196ms/step - loss: 0.0073 - mean_absolute_error: 0.0659 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0069 - mean_absolute_error: 0.0638\n",
      "Epoch 11: loss improved from 0.00705 to 0.00646, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 197ms/step - loss: 0.0069 - mean_absolute_error: 0.0638 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.0066 - mean_absolute_error: 0.0626\n",
      "Epoch 12: loss improved from 0.00646 to 0.00639, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 198ms/step - loss: 0.0066 - mean_absolute_error: 0.0625 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.0060 - mean_absolute_error: 0.0581\n",
      "Epoch 13: loss improved from 0.00639 to 0.00609, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 213ms/step - loss: 0.0060 - mean_absolute_error: 0.0581 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.0057 - mean_absolute_error: 0.0577\n",
      "Epoch 14: loss improved from 0.00609 to 0.00603, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 209ms/step - loss: 0.0057 - mean_absolute_error: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 0.0060 - mean_absolute_error: 0.0589\n",
      "Epoch 15: loss improved from 0.00603 to 0.00540, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 339ms/step - loss: 0.0059 - mean_absolute_error: 0.0589 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.0051 - mean_absolute_error: 0.0542\n",
      "Epoch 16: loss improved from 0.00540 to 0.00532, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 227ms/step - loss: 0.0051 - mean_absolute_error: 0.0542 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 0.0053 - mean_absolute_error: 0.0560\n",
      "Epoch 17: loss did not improve from 0.00532\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 246ms/step - loss: 0.0053 - mean_absolute_error: 0.0560 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 0.0046 - mean_absolute_error: 0.0526\n",
      "Epoch 18: loss improved from 0.00532 to 0.00495, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 276ms/step - loss: 0.0046 - mean_absolute_error: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - loss: 0.0044 - mean_absolute_error: 0.0515\n",
      "Epoch 19: loss improved from 0.00495 to 0.00473, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 381ms/step - loss: 0.0044 - mean_absolute_error: 0.0516 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517ms/step - loss: 0.0052 - mean_absolute_error: 0.0539\n",
      "Epoch 20: loss did not improve from 0.00473\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 518ms/step - loss: 0.0052 - mean_absolute_error: 0.0538 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 0.0048 - mean_absolute_error: 0.0518\n",
      "Epoch 21: loss did not improve from 0.00473\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 251ms/step - loss: 0.0048 - mean_absolute_error: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - loss: 0.0045 - mean_absolute_error: 0.0511\n",
      "Epoch 22: loss improved from 0.00473 to 0.00463, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 401ms/step - loss: 0.0045 - mean_absolute_error: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.0047 - mean_absolute_error: 0.0531\n",
      "Epoch 23: loss improved from 0.00463 to 0.00453, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 292ms/step - loss: 0.0047 - mean_absolute_error: 0.0530 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 0.0044 - mean_absolute_error: 0.0497\n",
      "Epoch 24: loss improved from 0.00453 to 0.00419, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 293ms/step - loss: 0.0044 - mean_absolute_error: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0045 - mean_absolute_error: 0.0507\n",
      "Epoch 25: loss did not improve from 0.00419\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 376ms/step - loss: 0.0045 - mean_absolute_error: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - loss: 0.0039 - mean_absolute_error: 0.0486\n",
      "Epoch 26: loss improved from 0.00419 to 0.00388, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 220ms/step - loss: 0.0039 - mean_absolute_error: 0.0486 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 0.0047 - mean_absolute_error: 0.0513\n",
      "Epoch 27: loss did not improve from 0.00388\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 246ms/step - loss: 0.0047 - mean_absolute_error: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - loss: 0.0039 - mean_absolute_error: 0.0476\n",
      "Epoch 28: loss improved from 0.00388 to 0.00386, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 331ms/step - loss: 0.0039 - mean_absolute_error: 0.0476 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579ms/step - loss: 0.0039 - mean_absolute_error: 0.0478\n",
      "Epoch 29: loss did not improve from 0.00386\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 582ms/step - loss: 0.0039 - mean_absolute_error: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - loss: 0.0040 - mean_absolute_error: 0.0478\n",
      "Epoch 30: loss improved from 0.00386 to 0.00363, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 403ms/step - loss: 0.0040 - mean_absolute_error: 0.0477 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - loss: 0.0038 - mean_absolute_error: 0.0466\n",
      "Epoch 31: loss improved from 0.00363 to 0.00358, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 338ms/step - loss: 0.0038 - mean_absolute_error: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - loss: 0.0039 - mean_absolute_error: 0.0470\n",
      "Epoch 32: loss did not improve from 0.00358\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 328ms/step - loss: 0.0039 - mean_absolute_error: 0.0469 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.0034 - mean_absolute_error: 0.0445\n",
      "Epoch 33: loss did not improve from 0.00358\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 247ms/step - loss: 0.0034 - mean_absolute_error: 0.0446 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.0035 - mean_absolute_error: 0.0453\n",
      "Epoch 34: loss improved from 0.00358 to 0.00343, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 187ms/step - loss: 0.0035 - mean_absolute_error: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.0032 - mean_absolute_error: 0.0437\n",
      "Epoch 35: loss did not improve from 0.00343\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - loss: 0.0032 - mean_absolute_error: 0.0438 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 0.0037 - mean_absolute_error: 0.0454\n",
      "Epoch 36: loss did not improve from 0.00343\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 270ms/step - loss: 0.0037 - mean_absolute_error: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - loss: 0.0035 - mean_absolute_error: 0.0451\n",
      "Epoch 37: loss improved from 0.00343 to 0.00340, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 457ms/step - loss: 0.0035 - mean_absolute_error: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - loss: 0.0029 - mean_absolute_error: 0.0407\n",
      "Epoch 38: loss improved from 0.00340 to 0.00319, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 585ms/step - loss: 0.0029 - mean_absolute_error: 0.0408 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - loss: 0.0032 - mean_absolute_error: 0.0426\n",
      "Epoch 39: loss improved from 0.00319 to 0.00317, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 406ms/step - loss: 0.0032 - mean_absolute_error: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.0028 - mean_absolute_error: 0.0400\n",
      "Epoch 40: loss improved from 0.00317 to 0.00290, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 252ms/step - loss: 0.0028 - mean_absolute_error: 0.0400 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.0027 - mean_absolute_error: 0.0408\n",
      "Epoch 41: loss did not improve from 0.00290\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 183ms/step - loss: 0.0027 - mean_absolute_error: 0.0408 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0031 - mean_absolute_error: 0.0427\n",
      "Epoch 42: loss did not improve from 0.00290\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 175ms/step - loss: 0.0031 - mean_absolute_error: 0.0427 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - loss: 0.0031 - mean_absolute_error: 0.0418\n",
      "Epoch 43: loss did not improve from 0.00290\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 328ms/step - loss: 0.0031 - mean_absolute_error: 0.0418 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.0028 - mean_absolute_error: 0.0407\n",
      "Epoch 44: loss improved from 0.00290 to 0.00280, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - loss: 0.0028 - mean_absolute_error: 0.0406 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.0028 - mean_absolute_error: 0.0402\n",
      "Epoch 45: loss improved from 0.00280 to 0.00275, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 185ms/step - loss: 0.0028 - mean_absolute_error: 0.0402 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - loss: 0.0031 - mean_absolute_error: 0.0424\n",
      "Epoch 46: loss did not improve from 0.00275\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 214ms/step - loss: 0.0031 - mean_absolute_error: 0.0424 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 0.0028 - mean_absolute_error: 0.0406\n",
      "Epoch 47: loss did not improve from 0.00275\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 248ms/step - loss: 0.0028 - mean_absolute_error: 0.0406 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.0028 - mean_absolute_error: 0.0400\n",
      "Epoch 48: loss did not improve from 0.00275\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 251ms/step - loss: 0.0028 - mean_absolute_error: 0.0400 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 0.0031 - mean_absolute_error: 0.0421\n",
      "Epoch 49: loss did not improve from 0.00275\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 250ms/step - loss: 0.0031 - mean_absolute_error: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 0.0030 - mean_absolute_error: 0.0410\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00275\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 270ms/step - loss: 0.0030 - mean_absolute_error: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - loss: 0.0024 - mean_absolute_error: 0.0375\n",
      "Epoch 51: loss improved from 0.00275 to 0.00237, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 283ms/step - loss: 0.0024 - mean_absolute_error: 0.0375 - learning_rate: 2.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 0.0024 - mean_absolute_error: 0.0374\n",
      "Epoch 52: loss improved from 0.00237 to 0.00229, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - loss: 0.0024 - mean_absolute_error: 0.0374 - learning_rate: 2.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.0022 - mean_absolute_error: 0.0355\n",
      "Epoch 53: loss improved from 0.00229 to 0.00221, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 215ms/step - loss: 0.0022 - mean_absolute_error: 0.0355 - learning_rate: 2.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0022 - mean_absolute_error: 0.0347\n",
      "Epoch 54: loss did not improve from 0.00221\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 185ms/step - loss: 0.0022 - mean_absolute_error: 0.0347 - learning_rate: 2.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0023 - mean_absolute_error: 0.0362\n",
      "Epoch 55: loss did not improve from 0.00221\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 171ms/step - loss: 0.0023 - mean_absolute_error: 0.0362 - learning_rate: 2.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0023 - mean_absolute_error: 0.0362\n",
      "Epoch 56: loss did not improve from 0.00221\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 171ms/step - loss: 0.0023 - mean_absolute_error: 0.0362 - learning_rate: 2.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0023 - mean_absolute_error: 0.0365\n",
      "Epoch 57: loss did not improve from 0.00221\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 171ms/step - loss: 0.0023 - mean_absolute_error: 0.0365 - learning_rate: 2.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0019 - mean_absolute_error: 0.0336\n",
      "Epoch 58: loss improved from 0.00221 to 0.00201, saving model to checkpoints/weights_prev_one.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 172ms/step - loss: 0.0019 - mean_absolute_error: 0.0337 - learning_rate: 2.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - loss: 0.0021 - mean_absolute_error: 0.0347\n",
      "Epoch 59: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - loss: 0.0021 - mean_absolute_error: 0.0347 - learning_rate: 2.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0025 - mean_absolute_error: 0.0376\n",
      "Epoch 60: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 171ms/step - loss: 0.0025 - mean_absolute_error: 0.0375 - learning_rate: 2.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0023 - mean_absolute_error: 0.0358\n",
      "Epoch 61: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - loss: 0.0023 - mean_absolute_error: 0.0358 - learning_rate: 2.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - loss: 0.0021 - mean_absolute_error: 0.0346\n",
      "Epoch 62: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 216ms/step - loss: 0.0021 - mean_absolute_error: 0.0346 - learning_rate: 2.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 0.0023 - mean_absolute_error: 0.0366\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 63: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 271ms/step - loss: 0.0023 - mean_absolute_error: 0.0365 - learning_rate: 2.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0020 - mean_absolute_error: 0.0337\n",
      "Epoch 64: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 375ms/step - loss: 0.0020 - mean_absolute_error: 0.0337 - learning_rate: 4.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 0.0025 - mean_absolute_error: 0.0374\n",
      "Epoch 65: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 290ms/step - loss: 0.0025 - mean_absolute_error: 0.0374 - learning_rate: 4.0000e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.0021 - mean_absolute_error: 0.0343\n",
      "Epoch 66: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 225ms/step - loss: 0.0021 - mean_absolute_error: 0.0343 - learning_rate: 4.0000e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.0024 - mean_absolute_error: 0.0360\n",
      "Epoch 67: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 174ms/step - loss: 0.0024 - mean_absolute_error: 0.0360 - learning_rate: 4.0000e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - loss: 0.0022 - mean_absolute_error: 0.0346\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 68: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 420ms/step - loss: 0.0022 - mean_absolute_error: 0.0346 - learning_rate: 4.0000e-05\n",
      "Epoch 68: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x779bad5a0820>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=32, callbacks=[early_stop, reduce_plateau, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.190001],\n",
       "       [16.49    ],\n",
       "       [16.780001],\n",
       "       [16.700001],\n",
       "       [16.74    ],\n",
       "       [17.030001],\n",
       "       [16.92    ],\n",
       "       [16.879999],\n",
       "       [17.040001],\n",
       "       [17.32    ],\n",
       "       [17.35    ],\n",
       "       [17.92    ],\n",
       "       [18.35    ],\n",
       "       [18.309999],\n",
       "       [18.26    ],\n",
       "       [18.4     ],\n",
       "       [18.42    ],\n",
       "       [19.34    ],\n",
       "       [19.620001],\n",
       "       [19.67    ],\n",
       "       [19.77    ],\n",
       "       [19.74    ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = base_test_csv.iloc[:, 1:2].values\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            Date       Open       High        Low      Close  Adj Close  \\\n",
       " 0     2013-01-02  19.990000  20.209999  19.690001  19.690001  18.086271   \n",
       " 1     2013-01-03  19.809999  20.400000  19.700001  20.400000  18.738441   \n",
       " 2     2013-01-04  20.330000  20.620001  20.170000  20.430000  18.766001   \n",
       " 3     2013-01-07  20.480000  20.670000  19.950001  20.080000  18.444506   \n",
       " 4     2013-01-08  20.110001  20.230000  19.459999  19.500000  17.911745   \n",
       " ...          ...        ...        ...        ...        ...        ...   \n",
       " 1240  2017-12-25  15.750000  15.750000  15.750000  15.750000  15.718563   \n",
       " 1241  2017-12-26  15.750000  15.990000  15.690000  15.970000  15.938125   \n",
       " 1242  2017-12-27  15.990000  16.139999  15.980000  16.049999  16.017963   \n",
       " 1243  2017-12-28  16.100000  16.129999  16.000000  16.100000  16.067865   \n",
       " 1244  2017-12-29  16.100000  16.100000  16.100000  16.100000  16.067865   \n",
       " \n",
       "           Volume  \n",
       " 0     30182600.0  \n",
       " 1     30552600.0  \n",
       " 2     36141000.0  \n",
       " 3     28069600.0  \n",
       " 4     29091300.0  \n",
       " ...          ...  \n",
       " 1240         0.0  \n",
       " 1241  22173100.0  \n",
       " 1242  23552200.0  \n",
       " 1243  19011500.0  \n",
       " 1244         0.0  \n",
       " \n",
       " [1242 rows x 7 columns],\n",
       "           Date       Open       High        Low      Close  Adj Close  \\\n",
       " 0   2018-01-02  16.190001  16.549999  16.190001  16.549999  16.516966   \n",
       " 1   2018-01-03  16.490000  16.719999  16.370001  16.700001  16.666668   \n",
       " 2   2018-01-04  16.780001  16.959999  16.620001  16.730000  16.696608   \n",
       " 3   2018-01-05  16.700001  16.860001  16.570000  16.830000  16.796408   \n",
       " 4   2018-01-08  16.740000  17.030001  16.709999  17.030001  16.996010   \n",
       " 5   2018-01-09  17.030001  17.160000  16.959999  17.030001  16.996010   \n",
       " 6   2018-01-10  16.920000  17.049999  16.770000  16.799999  16.766466   \n",
       " 7   2018-01-11  16.879999  17.299999  16.840000  17.250000  17.215569   \n",
       " 8   2018-01-12  17.040001  17.410000  17.020000  17.299999  17.265469   \n",
       " 9   2018-01-15  17.320000  17.440001  17.150000  17.350000  17.315371   \n",
       " 10  2018-01-16  17.350000  17.840000  17.299999  17.650000  17.614771   \n",
       " 11  2018-01-17  17.920000  18.360001  17.809999  18.360001  18.323355   \n",
       " 12  2018-01-18  18.350000  18.530001  17.930000  18.219999  18.183632   \n",
       " 13  2018-01-19  18.309999  18.420000  18.030001  18.260000  18.223553   \n",
       " 14  2018-01-22  18.260000  18.469999  18.090000  18.469999  18.433134   \n",
       " 15  2018-01-23  18.400000  18.459999  18.000000  18.240000  18.203592   \n",
       " 16  2018-01-24  18.420000  19.629999  18.420000  19.340000  19.301397   \n",
       " 17  2018-01-25  19.340000  19.340000  19.340000  19.340000  19.301397   \n",
       " 18  2018-01-26  19.620001  19.980000  19.100000  19.930000  19.890221   \n",
       " 19  2018-01-29  19.670000  20.049999  19.570000  19.850000  19.810381   \n",
       " 20  2018-01-30  19.770000  19.770000  19.360001  19.490000  19.451097   \n",
       " 21  2018-01-31  19.740000  19.930000  19.680000  19.700001  19.660681   \n",
       " \n",
       "       Volume  \n",
       " 0   33461800  \n",
       " 1   55940900  \n",
       " 2   37064900  \n",
       " 3   26958200  \n",
       " 4   28400000  \n",
       " 5   35070900  \n",
       " 6   28547700  \n",
       " 7   37921500  \n",
       " 8   45912100  \n",
       " 9   28945400  \n",
       " 10  58618300  \n",
       " 11  58488900  \n",
       " 12  48575800  \n",
       " 13  33470200  \n",
       " 14  33920000  \n",
       " 15  35567700  \n",
       " 16  89768200  \n",
       " 17         0  \n",
       " 18  81989500  \n",
       " 19  55726200  \n",
       " 20  46203000  \n",
       " 21  41576600  ]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [base_train_csv, base_test_csv]\n",
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>20.209999</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>18.086271</td>\n",
       "      <td>30182600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>19.809999</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>18.738441</td>\n",
       "      <td>30552600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>20.330000</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>20.170000</td>\n",
       "      <td>20.430000</td>\n",
       "      <td>18.766001</td>\n",
       "      <td>36141000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>20.480000</td>\n",
       "      <td>20.670000</td>\n",
       "      <td>19.950001</td>\n",
       "      <td>20.080000</td>\n",
       "      <td>18.444506</td>\n",
       "      <td>28069600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.230000</td>\n",
       "      <td>19.459999</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>17.911745</td>\n",
       "      <td>29091300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.301397</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>19.620001</td>\n",
       "      <td>19.980000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.890221</td>\n",
       "      <td>81989500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>19.670000</td>\n",
       "      <td>20.049999</td>\n",
       "      <td>19.570000</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>19.810381</td>\n",
       "      <td>55726200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.360001</td>\n",
       "      <td>19.490000</td>\n",
       "      <td>19.451097</td>\n",
       "      <td>46203000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>19.740000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.680000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>19.660681</td>\n",
       "      <td>41576600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1264 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date       Open       High        Low      Close  Adj Close  \\\n",
       "0   2013-01-02  19.990000  20.209999  19.690001  19.690001  18.086271   \n",
       "1   2013-01-03  19.809999  20.400000  19.700001  20.400000  18.738441   \n",
       "2   2013-01-04  20.330000  20.620001  20.170000  20.430000  18.766001   \n",
       "3   2013-01-07  20.480000  20.670000  19.950001  20.080000  18.444506   \n",
       "4   2013-01-08  20.110001  20.230000  19.459999  19.500000  17.911745   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "17  2018-01-25  19.340000  19.340000  19.340000  19.340000  19.301397   \n",
       "18  2018-01-26  19.620001  19.980000  19.100000  19.930000  19.890221   \n",
       "19  2018-01-29  19.670000  20.049999  19.570000  19.850000  19.810381   \n",
       "20  2018-01-30  19.770000  19.770000  19.360001  19.490000  19.451097   \n",
       "21  2018-01-31  19.740000  19.930000  19.680000  19.700001  19.660681   \n",
       "\n",
       "        Volume  \n",
       "0   30182600.0  \n",
       "1   30552600.0  \n",
       "2   36141000.0  \n",
       "3   28069600.0  \n",
       "4   29091300.0  \n",
       "..         ...  \n",
       "17         0.0  \n",
       "18  81989500.0  \n",
       "19  55726200.0  \n",
       "20  46203000.0  \n",
       "21  41576600.0  \n",
       "\n",
       "[1264 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_complete = pd.concat(frames)\n",
    "base_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_complete = base_complete.drop('Date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3930000e+01, 1.4030000e+01, 1.3760000e+01, 1.3870000e+01,\n",
       "        1.3842316e+01, 2.7208100e+07],\n",
       "       [1.3760000e+01, 1.3850000e+01, 1.3680000e+01, 1.3850000e+01,\n",
       "        1.3822356e+01, 2.7306400e+07],\n",
       "       [1.3790000e+01, 1.3900000e+01, 1.3440000e+01, 1.3450000e+01,\n",
       "        1.3423154e+01, 5.8871700e+07],\n",
       "       [1.3530000e+01, 1.3770000e+01, 1.3470000e+01, 1.3650000e+01,\n",
       "        1.3622754e+01, 8.2909400e+07],\n",
       "       [1.3850000e+01, 1.4190000e+01, 1.3820000e+01, 1.4020000e+01,\n",
       "        1.3992017e+01, 6.0260300e+07],\n",
       "       [1.3960000e+01, 1.4180000e+01, 1.3940000e+01, 1.4170000e+01,\n",
       "        1.4141717e+01, 1.8139300e+07],\n",
       "       [1.4570000e+01, 1.4650000e+01, 1.4230000e+01, 1.4410000e+01,\n",
       "        1.4381238e+01, 5.6476800e+07],\n",
       "       [1.4650000e+01, 1.5020000e+01, 1.4510000e+01, 1.5020000e+01,\n",
       "        1.4990021e+01, 6.8418200e+07],\n",
       "       [1.5020000e+01, 1.5020000e+01, 1.5020000e+01, 1.5020000e+01,\n",
       "        1.4990021e+01, 0.0000000e+00],\n",
       "       [1.5100000e+01, 1.5150000e+01, 1.4690000e+01, 1.4710000e+01,\n",
       "        1.4680639e+01, 3.6337400e+07],\n",
       "       [1.4880000e+01, 1.5050000e+01, 1.4810000e+01, 1.4990000e+01,\n",
       "        1.4960080e+01, 3.4915900e+07],\n",
       "       [1.4980000e+01, 1.5160000e+01, 1.4860000e+01, 1.4870000e+01,\n",
       "        1.4840320e+01, 4.9702800e+07],\n",
       "       [1.4940000e+01, 1.5100000e+01, 1.4810000e+01, 1.5030000e+01,\n",
       "        1.5000000e+01, 3.7010200e+07],\n",
       "       [1.5030000e+01, 1.5260000e+01, 1.5020000e+01, 1.5040000e+01,\n",
       "        1.5009980e+01, 3.4413800e+07],\n",
       "       [1.5070000e+01, 1.5170000e+01, 1.4990000e+01, 1.5040000e+01,\n",
       "        1.5009980e+01, 4.7784700e+07],\n",
       "       [1.5020000e+01, 1.5190000e+01, 1.4980000e+01, 1.5040000e+01,\n",
       "        1.5009980e+01, 4.7601200e+07],\n",
       "       [1.5100000e+01, 1.5170000e+01, 1.4920000e+01, 1.5140000e+01,\n",
       "        1.5109781e+01, 3.5822100e+07],\n",
       "       [1.5250000e+01, 1.5880000e+01, 1.5070000e+01, 1.5870000e+01,\n",
       "        1.5838324e+01, 8.0267000e+07],\n",
       "       [1.5850000e+01, 1.5960000e+01, 1.5580000e+01, 1.5670000e+01,\n",
       "        1.5638723e+01, 4.6258800e+07],\n",
       "       [1.5600000e+01, 1.5800000e+01, 1.5430000e+01, 1.5690000e+01,\n",
       "        1.5658683e+01, 4.0928300e+07],\n",
       "       [1.5790000e+01, 1.5960000e+01, 1.5700000e+01, 1.5840000e+01,\n",
       "        1.5808384e+01, 3.6733200e+07],\n",
       "       [1.5860000e+01, 1.5900000e+01, 1.5560000e+01, 1.5560000e+01,\n",
       "        1.5528943e+01, 3.7874200e+07],\n",
       "       [1.5700000e+01, 1.5720000e+01, 1.5110000e+01, 1.5310000e+01,\n",
       "        1.5279442e+01, 4.1819300e+07],\n",
       "       [1.5370000e+01, 1.5500000e+01, 1.5220000e+01, 1.5340000e+01,\n",
       "        1.5309381e+01, 3.3829000e+07],\n",
       "       [1.5500000e+01, 1.5520000e+01, 1.5300000e+01, 1.5300000e+01,\n",
       "        1.5269462e+01, 2.8638300e+07],\n",
       "       [1.5190000e+01, 1.5400000e+01, 1.5060000e+01, 1.5400000e+01,\n",
       "        1.5369262e+01, 2.9826200e+07],\n",
       "       [1.5600000e+01, 1.5980000e+01, 1.5520000e+01, 1.5980000e+01,\n",
       "        1.5948104e+01, 5.0636700e+07],\n",
       "       [1.5900000e+01, 1.5940000e+01, 1.5650000e+01, 1.5660000e+01,\n",
       "        1.5628743e+01, 4.7798600e+07],\n",
       "       [1.5880000e+01, 1.6110001e+01, 1.5850000e+01, 1.5900000e+01,\n",
       "        1.5868263e+01, 5.5361300e+07],\n",
       "       [1.5660000e+01, 1.5770000e+01, 1.5540000e+01, 1.5690000e+01,\n",
       "        1.5658683e+01, 4.1741300e+07],\n",
       "       [1.5610000e+01, 1.5890000e+01, 1.5590000e+01, 1.5890000e+01,\n",
       "        1.5858284e+01, 2.7904700e+07],\n",
       "       [1.6129999e+01, 1.6190001e+01, 1.6010000e+01, 1.6190001e+01,\n",
       "        1.6157686e+01, 4.7066600e+07],\n",
       "       [1.6170000e+01, 1.6250000e+01, 1.6010000e+01, 1.6080000e+01,\n",
       "        1.6047905e+01, 4.0422100e+07],\n",
       "       [1.6080000e+01, 1.6080000e+01, 1.6080000e+01, 1.6080000e+01,\n",
       "        1.6047905e+01, 0.0000000e+00],\n",
       "       [1.6230000e+01, 1.6290001e+01, 1.6059999e+01, 1.6080000e+01,\n",
       "        1.6047905e+01, 2.4210000e+07],\n",
       "       [1.6160000e+01, 1.6260000e+01, 1.6000000e+01, 1.6120001e+01,\n",
       "        1.6087826e+01, 4.4699700e+07],\n",
       "       [1.6139999e+01, 1.6219999e+01, 1.6070000e+01, 1.6129999e+01,\n",
       "        1.6097803e+01, 2.5524800e+07],\n",
       "       [1.6219999e+01, 1.6280001e+01, 1.6129999e+01, 1.6160000e+01,\n",
       "        1.6127745e+01, 2.5706200e+07],\n",
       "       [1.6000000e+01, 1.6160000e+01, 1.5900000e+01, 1.6150000e+01,\n",
       "        1.6117765e+01, 2.4672800e+07],\n",
       "       [1.6190001e+01, 1.6389999e+01, 1.6170000e+01, 1.6219999e+01,\n",
       "        1.6187624e+01, 3.2417500e+07],\n",
       "       [1.6290001e+01, 1.6290001e+01, 1.6120001e+01, 1.6200001e+01,\n",
       "        1.6167665e+01, 2.9389900e+07],\n",
       "       [1.6290001e+01, 1.6510000e+01, 1.6120001e+01, 1.6510000e+01,\n",
       "        1.6477047e+01, 4.6249500e+07],\n",
       "       [1.6530001e+01, 1.6730000e+01, 1.6450001e+01, 1.6719999e+01,\n",
       "        1.6686626e+01, 3.7608200e+07],\n",
       "       [1.6780001e+01, 1.6889999e+01, 1.6660000e+01, 1.6730000e+01,\n",
       "        1.6696608e+01, 3.7848300e+07],\n",
       "       [1.6770000e+01, 1.7090000e+01, 1.6650000e+01, 1.7030001e+01,\n",
       "        1.6996010e+01, 4.5640100e+07],\n",
       "       [1.6969999e+01, 1.7170000e+01, 1.6740000e+01, 1.6780001e+01,\n",
       "        1.6746508e+01, 5.5355600e+07],\n",
       "       [1.6900000e+01, 1.6950001e+01, 1.6719999e+01, 1.6770000e+01,\n",
       "        1.6736528e+01, 3.2249000e+07],\n",
       "       [1.6990000e+01, 1.7100000e+01, 1.6879999e+01, 1.6900000e+01,\n",
       "        1.6866268e+01, 3.8876600e+07],\n",
       "       [1.6900000e+01, 1.6900000e+01, 1.6900000e+01, 1.6900000e+01,\n",
       "        1.6866268e+01, 0.0000000e+00],\n",
       "       [1.6959999e+01, 1.7010000e+01, 1.6680000e+01, 1.6940001e+01,\n",
       "        1.6906189e+01, 3.2605400e+07],\n",
       "       [1.7049999e+01, 1.7440001e+01, 1.6980000e+01, 1.7430000e+01,\n",
       "        1.7395210e+01, 4.6056100e+07],\n",
       "       [1.7309999e+01, 1.7350000e+01, 1.6500000e+01, 1.6500000e+01,\n",
       "        1.6467066e+01, 6.1098400e+07],\n",
       "       [1.6690001e+01, 1.6950001e+01, 1.6510000e+01, 1.6950001e+01,\n",
       "        1.6916168e+01, 4.1179600e+07],\n",
       "       [1.6889999e+01, 1.6940001e+01, 1.6719999e+01, 1.6719999e+01,\n",
       "        1.6686626e+01, 2.9399400e+07],\n",
       "       [1.6709999e+01, 1.6809999e+01, 1.6510000e+01, 1.6719999e+01,\n",
       "        1.6686626e+01, 3.5959400e+07],\n",
       "       [1.6690001e+01, 1.6770000e+01, 1.6389999e+01, 1.6639999e+01,\n",
       "        1.6606787e+01, 2.8697700e+07],\n",
       "       [1.6639999e+01, 1.6639999e+01, 1.5280000e+01, 1.5350000e+01,\n",
       "        1.5319362e+01, 8.8765600e+07],\n",
       "       [1.5350000e+01, 1.5350000e+01, 1.5350000e+01, 1.5350000e+01,\n",
       "        1.5319362e+01, 0.0000000e+00],\n",
       "       [1.5620000e+01, 1.6040001e+01, 1.5480000e+01, 1.5810000e+01,\n",
       "        1.5778444e+01, 4.2703800e+07],\n",
       "       [1.5920000e+01, 1.6120001e+01, 1.5810000e+01, 1.6020000e+01,\n",
       "        1.5988025e+01, 3.8376900e+07],\n",
       "       [1.6020000e+01, 1.6020000e+01, 1.6020000e+01, 1.6020000e+01,\n",
       "        1.5988025e+01, 0.0000000e+00],\n",
       "       [1.6150000e+01, 1.6309999e+01, 1.5850000e+01, 1.5900000e+01,\n",
       "        1.5868263e+01, 4.5817800e+07],\n",
       "       [1.6090000e+01, 1.6240000e+01, 1.5930000e+01, 1.6110001e+01,\n",
       "        1.6077845e+01, 3.7444900e+07],\n",
       "       [1.5980000e+01, 1.6260000e+01, 1.5940000e+01, 1.6190001e+01,\n",
       "        1.6157686e+01, 1.5403600e+07],\n",
       "       [1.6250000e+01, 1.6370001e+01, 1.6040001e+01, 1.6100000e+01,\n",
       "        1.6067865e+01, 1.8790700e+07],\n",
       "       [1.6010000e+01, 1.6020000e+01, 1.5780000e+01, 1.5870000e+01,\n",
       "        1.5838324e+01, 2.8445800e+07],\n",
       "       [1.5930000e+01, 1.6040001e+01, 1.5810000e+01, 1.5840000e+01,\n",
       "        1.5808384e+01, 3.0429600e+07],\n",
       "       [1.5870000e+01, 1.5920000e+01, 1.5320000e+01, 1.5330000e+01,\n",
       "        1.5299401e+01, 4.5973000e+07],\n",
       "       [1.5300000e+01, 1.5470000e+01, 1.4990000e+01, 1.5380000e+01,\n",
       "        1.5349302e+01, 5.2811400e+07],\n",
       "       [1.5340000e+01, 1.5770000e+01, 1.5260000e+01, 1.5610000e+01,\n",
       "        1.5578842e+01, 4.2703800e+07],\n",
       "       [1.5650000e+01, 1.5800000e+01, 1.5460000e+01, 1.5480000e+01,\n",
       "        1.5449101e+01, 4.3821500e+07],\n",
       "       [1.5500000e+01, 1.5830000e+01, 1.5210000e+01, 1.5310000e+01,\n",
       "        1.5279442e+01, 3.0228000e+07],\n",
       "       [1.5220000e+01, 1.5700000e+01, 1.5140000e+01, 1.5520000e+01,\n",
       "        1.5489023e+01, 3.9238500e+07],\n",
       "       [1.5300000e+01, 1.5490000e+01, 1.5070000e+01, 1.5260000e+01,\n",
       "        1.5229542e+01, 3.7281400e+07],\n",
       "       [1.5510000e+01, 1.5680000e+01, 1.5350000e+01, 1.5350000e+01,\n",
       "        1.5319362e+01, 3.9584500e+07],\n",
       "       [1.5480000e+01, 1.5570000e+01, 1.5370000e+01, 1.5380000e+01,\n",
       "        1.5349302e+01, 2.1281600e+07],\n",
       "       [1.5360000e+01, 1.5490000e+01, 1.5180000e+01, 1.5490000e+01,\n",
       "        1.5459082e+01, 3.6201200e+07],\n",
       "       [1.5650000e+01, 1.5680000e+01, 1.5110000e+01, 1.5180000e+01,\n",
       "        1.5149701e+01, 4.6828900e+07],\n",
       "       [1.5100000e+01, 1.5310000e+01, 1.5000000e+01, 1.5010000e+01,\n",
       "        1.4980041e+01, 3.7177300e+07],\n",
       "       [1.5050000e+01, 1.5240000e+01, 1.4950000e+01, 1.4950000e+01,\n",
       "        1.4920160e+01, 5.5668300e+07],\n",
       "       [1.5160000e+01, 1.5330000e+01, 1.5130000e+01, 1.5220000e+01,\n",
       "        1.5189621e+01, 4.2760400e+07],\n",
       "       [1.5180000e+01, 1.5250000e+01, 1.5060000e+01, 1.5140000e+01,\n",
       "        1.5109781e+01, 2.2639700e+07],\n",
       "       [1.5210000e+01, 1.5300000e+01, 1.5170000e+01, 1.5240000e+01,\n",
       "        1.5209581e+01, 2.0149700e+07],\n",
       "       [1.5310000e+01, 1.5870000e+01, 1.5300000e+01, 1.5860000e+01,\n",
       "        1.5828343e+01, 4.7219400e+07],\n",
       "       [1.5750000e+01, 1.5890000e+01, 1.5690000e+01, 1.5750000e+01,\n",
       "        1.5718563e+01, 1.8708500e+07],\n",
       "       [1.5750000e+01, 1.5750000e+01, 1.5750000e+01, 1.5750000e+01,\n",
       "        1.5718563e+01, 0.0000000e+00],\n",
       "       [1.5750000e+01, 1.5990000e+01, 1.5690000e+01, 1.5970000e+01,\n",
       "        1.5938125e+01, 2.2173100e+07],\n",
       "       [1.5990000e+01, 1.6139999e+01, 1.5980000e+01, 1.6049999e+01,\n",
       "        1.6017963e+01, 2.3552200e+07],\n",
       "       [1.6100000e+01, 1.6129999e+01, 1.6000000e+01, 1.6100000e+01,\n",
       "        1.6067865e+01, 1.9011500e+07],\n",
       "       [1.6100000e+01, 1.6100000e+01, 1.6100000e+01, 1.6100000e+01,\n",
       "        1.6067865e+01, 0.0000000e+00],\n",
       "       [1.6190001e+01, 1.6549999e+01, 1.6190001e+01, 1.6549999e+01,\n",
       "        1.6516966e+01, 3.3461800e+07],\n",
       "       [1.6490000e+01, 1.6719999e+01, 1.6370001e+01, 1.6700001e+01,\n",
       "        1.6666668e+01, 5.5940900e+07],\n",
       "       [1.6780001e+01, 1.6959999e+01, 1.6620001e+01, 1.6730000e+01,\n",
       "        1.6696608e+01, 3.7064900e+07],\n",
       "       [1.6700001e+01, 1.6860001e+01, 1.6570000e+01, 1.6830000e+01,\n",
       "        1.6796408e+01, 2.6958200e+07],\n",
       "       [1.6740000e+01, 1.7030001e+01, 1.6709999e+01, 1.7030001e+01,\n",
       "        1.6996010e+01, 2.8400000e+07],\n",
       "       [1.7030001e+01, 1.7160000e+01, 1.6959999e+01, 1.7030001e+01,\n",
       "        1.6996010e+01, 3.5070900e+07],\n",
       "       [1.6920000e+01, 1.7049999e+01, 1.6770000e+01, 1.6799999e+01,\n",
       "        1.6766466e+01, 2.8547700e+07],\n",
       "       [1.6879999e+01, 1.7299999e+01, 1.6840000e+01, 1.7250000e+01,\n",
       "        1.7215569e+01, 3.7921500e+07],\n",
       "       [1.7040001e+01, 1.7410000e+01, 1.7020000e+01, 1.7299999e+01,\n",
       "        1.7265469e+01, 4.5912100e+07],\n",
       "       [1.7320000e+01, 1.7440001e+01, 1.7150000e+01, 1.7350000e+01,\n",
       "        1.7315371e+01, 2.8945400e+07],\n",
       "       [1.7350000e+01, 1.7840000e+01, 1.7299999e+01, 1.7650000e+01,\n",
       "        1.7614771e+01, 5.8618300e+07],\n",
       "       [1.7920000e+01, 1.8360001e+01, 1.7809999e+01, 1.8360001e+01,\n",
       "        1.8323355e+01, 5.8488900e+07],\n",
       "       [1.8350000e+01, 1.8530001e+01, 1.7930000e+01, 1.8219999e+01,\n",
       "        1.8183632e+01, 4.8575800e+07],\n",
       "       [1.8309999e+01, 1.8420000e+01, 1.8030001e+01, 1.8260000e+01,\n",
       "        1.8223553e+01, 3.3470200e+07],\n",
       "       [1.8260000e+01, 1.8469999e+01, 1.8090000e+01, 1.8469999e+01,\n",
       "        1.8433134e+01, 3.3920000e+07],\n",
       "       [1.8400000e+01, 1.8459999e+01, 1.8000000e+01, 1.8240000e+01,\n",
       "        1.8203592e+01, 3.5567700e+07],\n",
       "       [1.8420000e+01, 1.9629999e+01, 1.8420000e+01, 1.9340000e+01,\n",
       "        1.9301397e+01, 8.9768200e+07],\n",
       "       [1.9340000e+01, 1.9340000e+01, 1.9340000e+01, 1.9340000e+01,\n",
       "        1.9301397e+01, 0.0000000e+00],\n",
       "       [1.9620001e+01, 1.9980000e+01, 1.9100000e+01, 1.9930000e+01,\n",
       "        1.9890221e+01, 8.1989500e+07],\n",
       "       [1.9670000e+01, 2.0049999e+01, 1.9570000e+01, 1.9850000e+01,\n",
       "        1.9810381e+01, 5.5726200e+07],\n",
       "       [1.9770000e+01, 1.9770000e+01, 1.9360001e+01, 1.9490000e+01,\n",
       "        1.9451097e+01, 4.6203000e+07],\n",
       "       [1.9740000e+01, 1.9930000e+01, 1.9680000e+01, 1.9700001e+01,\n",
       "        1.9660681e+01, 4.1576600e+07]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = base_complete[len(base_complete) - len(base_test_csv) - antecipator:].values\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47141473, 0.47309743, 0.49334698, 0.47495091, 0.47495089,\n",
       "        0.03892707],\n",
       "       [0.46317829, 0.46437227, 0.48925281, 0.47396859, 0.47396857,\n",
       "        0.03906771],\n",
       "       [0.46463178, 0.46679593, 0.47697032, 0.45432222, 0.45432219,\n",
       "        0.0842287 ],\n",
       "       [0.45203488, 0.46049443, 0.47850563, 0.46414541, 0.46414533,\n",
       "        0.11861983],\n",
       "       [0.46753876, 0.48085313, 0.4964176 , 0.48231829, 0.48231829,\n",
       "        0.08621539],\n",
       "       [0.47286822, 0.4803684 , 0.50255885, 0.48968568, 0.48968565,\n",
       "        0.02595219],\n",
       "       [0.50242248, 0.50315075, 0.5174002 , 0.5014735 , 0.50147347,\n",
       "        0.08080228],\n",
       "       [0.50629845, 0.5210858 , 0.53172979, 0.53143421, 0.53143421,\n",
       "        0.09788703],\n",
       "       [0.52422481, 0.5210858 , 0.55783009, 0.53143421, 0.53143421,\n",
       "        0.        ],\n",
       "       [0.52810078, 0.5273873 , 0.54094166, 0.51620828, 0.51620824,\n",
       "        0.05198851],\n",
       "       [0.51744186, 0.52253999, 0.54708291, 0.52996073, 0.52996068,\n",
       "        0.04995475],\n",
       "       [0.52228682, 0.52787203, 0.54964176, 0.52406682, 0.5240668 ,\n",
       "        0.0711106 ],\n",
       "       [0.52034884, 0.52496365, 0.54708291, 0.53192537, 0.53192531,\n",
       "        0.05295109],\n",
       "       [0.5247093 , 0.53271934, 0.55783009, 0.53241653, 0.53241647,\n",
       "        0.04923638],\n",
       "       [0.52664729, 0.52835676, 0.55629478, 0.53241653, 0.53241647,\n",
       "        0.06836635],\n",
       "       [0.52422481, 0.52932622, 0.55578301, 0.53241653, 0.53241647,\n",
       "        0.06810381],\n",
       "       [0.52810078, 0.52835676, 0.55271238, 0.53732812, 0.53732809,\n",
       "        0.05125126],\n",
       "       [0.53536822, 0.56277266, 0.56038895, 0.57318274, 0.57318271,\n",
       "        0.1148393 ],\n",
       "       [0.56443798, 0.56665051, 0.58648925, 0.56335956, 0.56335952,\n",
       "        0.06618322],\n",
       "       [0.55232558, 0.55889481, 0.57881269, 0.56434187, 0.56434183,\n",
       "        0.05855678],\n",
       "       [0.56153101, 0.56665051, 0.5926305 , 0.57170926, 0.57170924,\n",
       "        0.05255479],\n",
       "       [0.56492248, 0.56374212, 0.58546571, 0.55795681, 0.55795679,\n",
       "        0.05418723],\n",
       "       [0.55717054, 0.55501697, 0.56243603, 0.54567783, 0.54567781,\n",
       "        0.05983155],\n",
       "       [0.54118217, 0.54435288, 0.56806551, 0.5471513 , 0.54715123,\n",
       "        0.0483997 ],\n",
       "       [0.54748062, 0.54532235, 0.57215967, 0.54518667, 0.54518665,\n",
       "        0.04097328],\n",
       "       [0.53246124, 0.53950557, 0.55987718, 0.55009826, 0.55009823,\n",
       "        0.04267283],\n",
       "       [0.55232558, 0.56761997, 0.58341863, 0.57858549, 0.57858544,\n",
       "        0.07244675],\n",
       "       [0.56686047, 0.56568105, 0.59007165, 0.5628684 , 0.56286836,\n",
       "        0.06838623],\n",
       "       [0.56589147, 0.57392152, 0.60030706, 0.57465622, 0.57465613,\n",
       "        0.07920631],\n",
       "       [0.55523256, 0.55744062, 0.58444217, 0.56434187, 0.56434183,\n",
       "        0.05971996],\n",
       "       [0.55281008, 0.56325739, 0.58700102, 0.57416506, 0.57416503,\n",
       "        0.03992371],\n",
       "       [0.57800383, 0.57779937, 0.60849539, 0.58889988, 0.58889984,\n",
       "        0.06733895],\n",
       "       [0.57994186, 0.58070771, 0.60849539, 0.58349708, 0.58349706,\n",
       "        0.05783256],\n",
       "       [0.5755814 , 0.57246728, 0.61207779, 0.58349708, 0.58349706,\n",
       "        0.        ],\n",
       "       [0.58284884, 0.58264668, 0.6110542 , 0.58349708, 0.58349706,\n",
       "        0.03463764],\n",
       "       [0.57945736, 0.58119244, 0.60798362, 0.58546177, 0.58546174,\n",
       "        0.06395259],\n",
       "       [0.57848832, 0.57925347, 0.61156602, 0.58595283, 0.58595275,\n",
       "        0.03651875],\n",
       "       [0.58236429, 0.58216195, 0.61463659, 0.58742635, 0.58742632,\n",
       "        0.03677828],\n",
       "       [0.57170543, 0.57634513, 0.60286592, 0.5869352 , 0.58693516,\n",
       "        0.03529978],\n",
       "       [0.5809109 , 0.58749389, 0.61668373, 0.59037326, 0.59037321,\n",
       "        0.04638024],\n",
       "       [0.58575586, 0.58264668, 0.61412492, 0.58939104, 0.58939095,\n",
       "        0.04204861],\n",
       "       [0.58575586, 0.59331071, 0.61412492, 0.60461693, 0.60461692,\n",
       "        0.06616991],\n",
       "       [0.59738377, 0.60397479, 0.63101336, 0.61493122, 0.61493117,\n",
       "        0.05380666],\n",
       "       [0.60949617, 0.61173044, 0.64176049, 0.61542243, 0.61542242,\n",
       "        0.05415018],\n",
       "       [0.60901163, 0.62142511, 0.64124872, 0.63015725, 0.63015724,\n",
       "        0.06529803],\n",
       "       [0.6187015 , 0.62530296, 0.64585466, 0.61787827, 0.61787821,\n",
       "        0.07919816],\n",
       "       [0.61531008, 0.61463892, 0.64483106, 0.61738706, 0.61738705,\n",
       "        0.04613917],\n",
       "       [0.61967054, 0.62190984, 0.6530194 , 0.62377213, 0.62377209,\n",
       "        0.05562138],\n",
       "       [0.61531008, 0.61221522, 0.65404299, 0.62377213, 0.62377209,\n",
       "        0.        ],\n",
       "       [0.61821701, 0.61754726, 0.64278403, 0.62573682, 0.62573677,\n",
       "        0.04664908],\n",
       "       [0.62257747, 0.63839074, 0.65813715, 0.64980357, 0.64980352,\n",
       "        0.06589321],\n",
       "       [0.63517437, 0.63402811, 0.63357216, 0.60412577, 0.60412571,\n",
       "        0.08741447],\n",
       "       [0.60513571, 0.61463892, 0.63408393, 0.62622798, 0.62622788,\n",
       "        0.05891632],\n",
       "       [0.61482553, 0.61415419, 0.64483106, 0.61493122, 0.61493117,\n",
       "        0.0420622 ],\n",
       "       [0.6061046 , 0.60785259, 0.63408393, 0.61493122, 0.61493117,\n",
       "        0.0514477 ],\n",
       "       [0.60513571, 0.60591372, 0.62794263, 0.61100195, 0.61100196,\n",
       "        0.04105827],\n",
       "       [0.60271313, 0.59961217, 0.57113613, 0.54764246, 0.54764244,\n",
       "        0.12699839],\n",
       "       [0.54021318, 0.53708192, 0.57471853, 0.54764246, 0.54764244,\n",
       "        0.        ],\n",
       "       [0.55329457, 0.57052841, 0.58137155, 0.57023578, 0.57023577,\n",
       "        0.06109702],\n",
       "       [0.56782946, 0.57440625, 0.59825998, 0.58055013, 0.58055012,\n",
       "        0.05490645],\n",
       "       [0.57267442, 0.56955889, 0.60900716, 0.58055013, 0.58055012,\n",
       "        0.        ],\n",
       "       [0.57897287, 0.58361604, 0.60030706, 0.57465622, 0.57465613,\n",
       "        0.06555227],\n",
       "       [0.57606589, 0.58022298, 0.60440123, 0.58497061, 0.58497053,\n",
       "        0.05357303],\n",
       "       [0.57073643, 0.58119244, 0.604913  , 0.58889988, 0.58889984,\n",
       "        0.02203818],\n",
       "       [0.58381783, 0.58652453, 0.61003076, 0.5844794 , 0.58447937,\n",
       "        0.02688416],\n",
       "       [0.57218992, 0.56955889, 0.59672467, 0.57318274, 0.57318271,\n",
       "        0.04069787],\n",
       "       [0.56831395, 0.57052841, 0.59825998, 0.57170926, 0.57170924,\n",
       "        0.04353612],\n",
       "       [0.56540698, 0.56471159, 0.57318321, 0.54666014, 0.54666008,\n",
       "        0.06577432],\n",
       "       [0.5377907 , 0.54289869, 0.55629478, 0.54911594, 0.54911591,\n",
       "        0.07555813],\n",
       "       [0.53972868, 0.55744062, 0.57011259, 0.5604126 , 0.56041253,\n",
       "        0.06109702],\n",
       "       [0.55474806, 0.55889481, 0.580348  , 0.55402753, 0.55402743,\n",
       "        0.06269613],\n",
       "       [0.54748062, 0.56034901, 0.56755374, 0.54567783, 0.54567781,\n",
       "        0.04324769],\n",
       "       [0.53391473, 0.5540475 , 0.56397134, 0.55599217, 0.55599216,\n",
       "        0.05613916],\n",
       "       [0.5377907 , 0.54386815, 0.56038895, 0.54322203, 0.54322203,\n",
       "        0.0533391 ],\n",
       "       [0.54796512, 0.55307804, 0.57471853, 0.54764246, 0.54764244,\n",
       "        0.05663419],\n",
       "       [0.54651163, 0.547746  , 0.57574207, 0.54911594, 0.54911591,\n",
       "        0.03044793],\n",
       "       [0.54069767, 0.54386815, 0.56601842, 0.55451869, 0.55451864,\n",
       "        0.05179365],\n",
       "       [0.55474806, 0.55307804, 0.56243603, 0.53929276, 0.53929272,\n",
       "        0.06699887],\n",
       "       [0.52810078, 0.535143  , 0.55680655, 0.53094305, 0.53094305,\n",
       "        0.05319017],\n",
       "       [0.52567829, 0.53174988, 0.5542477 , 0.5279961 , 0.52799606,\n",
       "        0.07964554],\n",
       "       [0.53100775, 0.53611246, 0.56345957, 0.54125739, 0.54125735,\n",
       "        0.061178  ],\n",
       "       [0.53197674, 0.53223461, 0.55987718, 0.53732812, 0.53732809,\n",
       "        0.03239099],\n",
       "       [0.53343023, 0.53465826, 0.56550665, 0.54223971, 0.54223966,\n",
       "        0.0288285 ],\n",
       "       [0.53827519, 0.56228793, 0.57215967, 0.57269158, 0.5726915 ,\n",
       "        0.06755756],\n",
       "       [0.55959302, 0.56325739, 0.59211873, 0.56728883, 0.56728878,\n",
       "        0.02676656],\n",
       "       [0.55959302, 0.55647116, 0.59518936, 0.56728883, 0.56728878,\n",
       "        0.        ],\n",
       "       [0.55959302, 0.5681047 , 0.59211873, 0.57809433, 0.57809433,\n",
       "        0.03172341],\n",
       "       [0.57122093, 0.57537562, 0.60696008, 0.58202356, 0.58202349,\n",
       "        0.03369652],\n",
       "       [0.57655039, 0.57489089, 0.60798362, 0.5844794 , 0.58447937,\n",
       "        0.02720006],\n",
       "       [0.57655039, 0.57343674, 0.61310133, 0.5844794 , 0.58447937,\n",
       "        0.        ],\n",
       "       [0.5809109 , 0.59524959, 0.61770732, 0.60658151, 0.6065815 ,\n",
       "        0.04787434],\n",
       "       [0.59544574, 0.60349001, 0.62691919, 0.613949  , 0.61394895,\n",
       "        0.08003555],\n",
       "       [0.60949617, 0.61512356, 0.63971346, 0.61542243, 0.61542242,\n",
       "        0.05302935],\n",
       "       [0.6056202 , 0.61027635, 0.63715455, 0.62033402, 0.62033399,\n",
       "        0.03856953],\n",
       "       [0.60755814, 0.61851677, 0.64431929, 0.63015725, 0.63015724,\n",
       "        0.04063234],\n",
       "       [0.62160858, 0.62481823, 0.65711356, 0.63015725, 0.63015724,\n",
       "        0.05017651],\n",
       "       [0.61627907, 0.61948614, 0.64738997, 0.61886049, 0.61886042,\n",
       "        0.04084366],\n",
       "       [0.61434104, 0.63160441, 0.65097236, 0.6409627 , 0.64096264,\n",
       "        0.05425491],\n",
       "       [0.62209307, 0.6369365 , 0.66018424, 0.64341845, 0.64341843,\n",
       "        0.06568719],\n",
       "       [0.63565891, 0.63839074, 0.66683726, 0.64587429, 0.64587431,\n",
       "        0.04141265],\n",
       "       [0.6371124 , 0.65777993, 0.67451377, 0.66060907, 0.66060903,\n",
       "        0.08386615],\n",
       "       [0.66472868, 0.68298599, 0.70061407, 0.69548142, 0.69548138,\n",
       "        0.08368102],\n",
       "       [0.68556202, 0.69122642, 0.70675537, 0.68860509, 0.68860504,\n",
       "        0.06949819],\n",
       "       [0.68362398, 0.68589433, 0.71187313, 0.69056978, 0.69056971,\n",
       "        0.04788636],\n",
       "       [0.68120155, 0.68831794, 0.71494371, 0.70088407, 0.70088406,\n",
       "        0.0485299 ],\n",
       "       [0.6879845 , 0.6878332 , 0.71033777, 0.68958746, 0.68958735,\n",
       "        0.05088729],\n",
       "       [0.68895349, 0.74454673, 0.73183214, 0.74361497, 0.74361488,\n",
       "        0.12843282],\n",
       "       [0.73352713, 0.73048958, 0.77891505, 0.74361497, 0.74361488,\n",
       "        0.        ],\n",
       "       [0.74709307, 0.76151236, 0.76663255, 0.77259336, 0.77259335,\n",
       "        0.11730371],\n",
       "       [0.7495155 , 0.76490543, 0.79068577, 0.76866408, 0.76866409,\n",
       "        0.07972838],\n",
       "       [0.75436047, 0.75133301, 0.77993864, 0.75098236, 0.75098224,\n",
       "        0.06610338],\n",
       "       [0.75290698, 0.75908871, 0.79631525, 0.76129675, 0.76129674,\n",
       "        0.05948432]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = normalizer.transform(input)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.47141473, 0.47309743, 0.49334698, 0.47495091, 0.47495089,\n",
       "         0.03892707],\n",
       "        [0.46317829, 0.46437227, 0.48925281, 0.47396859, 0.47396857,\n",
       "         0.03906771],\n",
       "        [0.46463178, 0.46679593, 0.47697032, 0.45432222, 0.45432219,\n",
       "         0.0842287 ],\n",
       "        ...,\n",
       "        [0.57122093, 0.57537562, 0.60696008, 0.58202356, 0.58202349,\n",
       "         0.03369652],\n",
       "        [0.57655039, 0.57489089, 0.60798362, 0.5844794 , 0.58447937,\n",
       "         0.02720006],\n",
       "        [0.57655039, 0.57343674, 0.61310133, 0.5844794 , 0.58447937,\n",
       "         0.        ]],\n",
       "\n",
       "       [[0.46317829, 0.46437227, 0.48925281, 0.47396859, 0.47396857,\n",
       "         0.03906771],\n",
       "        [0.46463178, 0.46679593, 0.47697032, 0.45432222, 0.45432219,\n",
       "         0.0842287 ],\n",
       "        [0.45203488, 0.46049443, 0.47850563, 0.46414541, 0.46414533,\n",
       "         0.11861983],\n",
       "        ...,\n",
       "        [0.57655039, 0.57489089, 0.60798362, 0.5844794 , 0.58447937,\n",
       "         0.02720006],\n",
       "        [0.57655039, 0.57343674, 0.61310133, 0.5844794 , 0.58447937,\n",
       "         0.        ],\n",
       "        [0.5809109 , 0.59524959, 0.61770732, 0.60658151, 0.6065815 ,\n",
       "         0.04787434]],\n",
       "\n",
       "       [[0.46463178, 0.46679593, 0.47697032, 0.45432222, 0.45432219,\n",
       "         0.0842287 ],\n",
       "        [0.45203488, 0.46049443, 0.47850563, 0.46414541, 0.46414533,\n",
       "         0.11861983],\n",
       "        [0.46753876, 0.48085313, 0.4964176 , 0.48231829, 0.48231829,\n",
       "         0.08621539],\n",
       "        ...,\n",
       "        [0.57655039, 0.57343674, 0.61310133, 0.5844794 , 0.58447937,\n",
       "         0.        ],\n",
       "        [0.5809109 , 0.59524959, 0.61770732, 0.60658151, 0.6065815 ,\n",
       "         0.04787434],\n",
       "        [0.59544574, 0.60349001, 0.62691919, 0.613949  , 0.61394895,\n",
       "         0.08003555]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.55232558, 0.55889481, 0.57881269, 0.56434187, 0.56434183,\n",
       "         0.05855678],\n",
       "        [0.56153101, 0.56665051, 0.5926305 , 0.57170926, 0.57170924,\n",
       "         0.05255479],\n",
       "        [0.56492248, 0.56374212, 0.58546571, 0.55795681, 0.55795679,\n",
       "         0.05418723],\n",
       "        ...,\n",
       "        [0.68895349, 0.74454673, 0.73183214, 0.74361497, 0.74361488,\n",
       "         0.12843282],\n",
       "        [0.73352713, 0.73048958, 0.77891505, 0.74361497, 0.74361488,\n",
       "         0.        ],\n",
       "        [0.74709307, 0.76151236, 0.76663255, 0.77259336, 0.77259335,\n",
       "         0.11730371]],\n",
       "\n",
       "       [[0.56153101, 0.56665051, 0.5926305 , 0.57170926, 0.57170924,\n",
       "         0.05255479],\n",
       "        [0.56492248, 0.56374212, 0.58546571, 0.55795681, 0.55795679,\n",
       "         0.05418723],\n",
       "        [0.55717054, 0.55501697, 0.56243603, 0.54567783, 0.54567781,\n",
       "         0.05983155],\n",
       "        ...,\n",
       "        [0.73352713, 0.73048958, 0.77891505, 0.74361497, 0.74361488,\n",
       "         0.        ],\n",
       "        [0.74709307, 0.76151236, 0.76663255, 0.77259336, 0.77259335,\n",
       "         0.11730371],\n",
       "        [0.7495155 , 0.76490543, 0.79068577, 0.76866408, 0.76866409,\n",
       "         0.07972838]],\n",
       "\n",
       "       [[0.56492248, 0.56374212, 0.58546571, 0.55795681, 0.55795679,\n",
       "         0.05418723],\n",
       "        [0.55717054, 0.55501697, 0.56243603, 0.54567783, 0.54567781,\n",
       "         0.05983155],\n",
       "        [0.54118217, 0.54435288, 0.56806551, 0.5471513 , 0.54715123,\n",
       "         0.0483997 ],\n",
       "        ...,\n",
       "        [0.74709307, 0.76151236, 0.76663255, 0.77259336, 0.77259335,\n",
       "         0.11730371],\n",
       "        [0.7495155 , 0.76490543, 0.79068577, 0.76866408, 0.76866409,\n",
       "         0.07972838],\n",
       "        [0.75436047, 0.75133301, 0.77993864, 0.75098236, 0.75098224,\n",
       "         0.06610338]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = [input[i-antecipator:i, 0:6] for i in range(antecipator, input.shape[0])]\n",
    "x_test = np.array(x_test)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 90, 6)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 6 and 1 for '{{node sequential_1/lstm_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_1/lstm_1/strided_slice_1, sequential_1/lstm_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [22,6], [1,400].\u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(22, 6), dtype=float32)\n  • states=('tf.Tensor(shape=(22, 100), dtype=float32)', 'tf.Tensor(shape=(22, 100), dtype=float32)')\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prevs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m prevs\n",
      "File \u001b[0;32m~/anaconda3/envs/dlp/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/dlp/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling LSTMCell.call().\n\n\u001b[1mDimensions must be equal, but are 6 and 1 for '{{node sequential_1/lstm_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_1/lstm_1/strided_slice_1, sequential_1/lstm_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [22,6], [1,400].\u001b[0m\n\nArguments received by LSTMCell.call():\n  • inputs=tf.Tensor(shape=(22, 6), dtype=float32)\n  • states=('tf.Tensor(shape=(22, 100), dtype=float32)', 'tf.Tensor(shape=(22, 100), dtype=float32)')\n  • training=False"
     ]
    }
   ],
   "source": [
    "prevs = model.predict(x_test)\n",
    "prevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.06155 ],\n",
       "       [16.18891 ],\n",
       "       [16.309292],\n",
       "       [16.430826],\n",
       "       [16.551216],\n",
       "       [16.67031 ],\n",
       "       [16.786053],\n",
       "       [16.8803  ],\n",
       "       [16.957146],\n",
       "       [17.023739],\n",
       "       [17.091032],\n",
       "       [17.168617],\n",
       "       [17.291317],\n",
       "       [17.463486],\n",
       "       [17.663248],\n",
       "       [17.865534],\n",
       "       [18.038857],\n",
       "       [18.205372],\n",
       "       [18.404268],\n",
       "       [18.642569],\n",
       "       [18.900913],\n",
       "       [19.131927]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevs = prevs_normalizer.inverse_transform(prevs)\n",
    "prevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.351204, 17.87454563636364)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevs.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5233693890769264"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(prevs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test, color='red', label='Preço Real')\n",
    "plt.plot(prevs, color='blue', label='Previsões')\n",
    "plt.title('Previsão dos preços das ações')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Valor')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Multiplas Saídas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train = base_train_csv.iloc[:, 1:2].values\n",
    "base_value_max = base_train_csv.iloc[:, 2:3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.809999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.110001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>15.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>15.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>15.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>16.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>16.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1242 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0     19.990000\n",
       "1     19.809999\n",
       "2     20.330000\n",
       "3     20.480000\n",
       "4     20.110001\n",
       "...         ...\n",
       "1237  15.750000\n",
       "1238  15.750000\n",
       "1239  15.990000\n",
       "1240  16.100000\n",
       "1241  16.100000\n",
       "\n",
       "[1242 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(base_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.209999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.620001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>15.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>15.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>16.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>16.129999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>16.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1242 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0     20.209999\n",
       "1     20.400000\n",
       "2     20.620001\n",
       "3     20.670000\n",
       "4     20.230000\n",
       "...         ...\n",
       "1237  15.750000\n",
       "1238  15.990000\n",
       "1239  16.139999\n",
       "1240  16.129999\n",
       "1241  16.100000\n",
       "\n",
       "[1242 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(base_value_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler(feature_range=(0, 1))\n",
    "base_train = normalizer.fit_transform(base_train)\n",
    "base_value_max = normalizer.fit_transform(base_value_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.765019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.756298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.781492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.788760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.770833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0.559593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0.559593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>0.571221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>0.576550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>0.576550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1242 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.765019\n",
       "1     0.756298\n",
       "2     0.781492\n",
       "3     0.788760\n",
       "4     0.770833\n",
       "...        ...\n",
       "1237  0.559593\n",
       "1238  0.559593\n",
       "1239  0.571221\n",
       "1240  0.576550\n",
       "1241  0.576550\n",
       "\n",
       "[1242 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(base_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.772661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.781871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.794959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.773631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0.556471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0.568105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>0.575376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>0.574891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>0.573437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1242 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.772661\n",
       "1     0.781871\n",
       "2     0.792535\n",
       "3     0.794959\n",
       "4     0.773631\n",
       "...        ...\n",
       "1237  0.556471\n",
       "1238  0.568105\n",
       "1239  0.575376\n",
       "1240  0.574891\n",
       "1241  0.573437\n",
       "\n",
       "[1242 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(base_value_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "antec = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train1 = []\n",
    "y_train2 = []\n",
    "\n",
    "for i in range(antec, base_train.shape[0]):\n",
    "    x_train.append(base_train[i - antec:i, 0])\n",
    "    y_train1.append(base_train[i, 0])\n",
    "    y_train2.append(base_value_max[i, 0])\n",
    "\n",
    "x_train, y_train1, y_train2 = np.array(x_train), np.array(y_train1), np.array(y_train2)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 90, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76114341, 0.76490543],\n",
       "       [0.76114341, 0.7746001 ],\n",
       "       [0.77470935, 0.78090155],\n",
       "       ...,\n",
       "       [0.57122093, 0.57537562],\n",
       "       [0.57655039, 0.57489089],\n",
       "       [0.57655039, 0.57343674]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.column_stack((y_train1, y_train2))\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input((x_train.shape[1], x_train.shape[2])))\n",
    "\n",
    "model.add(LSTM(units=100, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "          \n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "          \n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=2, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='checkpoints/weights_prev_multiple.keras',\n",
    "    monitor='loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_plateau = ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=1e-10,\n",
    "    patience=10,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0810 - mean_absolute_error: 0.2143\n",
      "Epoch 1: loss improved from inf to 0.04027, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 185ms/step - loss: 0.0799 - mean_absolute_error: 0.2125 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0169 - mean_absolute_error: 0.1003\n",
      "Epoch 2: loss improved from 0.04027 to 0.01734, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 172ms/step - loss: 0.0169 - mean_absolute_error: 0.1003 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0137 - mean_absolute_error: 0.0918\n",
      "Epoch 3: loss improved from 0.01734 to 0.01418, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - loss: 0.0137 - mean_absolute_error: 0.0919 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0157 - mean_absolute_error: 0.0956\n",
      "Epoch 4: loss improved from 0.01418 to 0.01316, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - loss: 0.0156 - mean_absolute_error: 0.0954 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0116 - mean_absolute_error: 0.0837\n",
      "Epoch 5: loss improved from 0.01316 to 0.01140, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - loss: 0.0116 - mean_absolute_error: 0.0837 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0118 - mean_absolute_error: 0.0825\n",
      "Epoch 6: loss improved from 0.01140 to 0.01062, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - loss: 0.0118 - mean_absolute_error: 0.0824 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0101 - mean_absolute_error: 0.0767\n",
      "Epoch 7: loss improved from 0.01062 to 0.01012, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - loss: 0.0101 - mean_absolute_error: 0.0767 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0089 - mean_absolute_error: 0.0726\n",
      "Epoch 8: loss improved from 0.01012 to 0.00896, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 166ms/step - loss: 0.0089 - mean_absolute_error: 0.0726 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0088 - mean_absolute_error: 0.0707\n",
      "Epoch 9: loss did not improve from 0.00896\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.0088 - mean_absolute_error: 0.0707 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0085 - mean_absolute_error: 0.0712\n",
      "Epoch 10: loss improved from 0.00896 to 0.00866, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - loss: 0.0085 - mean_absolute_error: 0.0712 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0076 - mean_absolute_error: 0.0654\n",
      "Epoch 11: loss improved from 0.00866 to 0.00745, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0076 - mean_absolute_error: 0.0654 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0066 - mean_absolute_error: 0.0612\n",
      "Epoch 12: loss improved from 0.00745 to 0.00708, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0066 - mean_absolute_error: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0064 - mean_absolute_error: 0.0613\n",
      "Epoch 13: loss improved from 0.00708 to 0.00702, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - loss: 0.0064 - mean_absolute_error: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0062 - mean_absolute_error: 0.0595\n",
      "Epoch 14: loss improved from 0.00702 to 0.00668, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - loss: 0.0062 - mean_absolute_error: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0061 - mean_absolute_error: 0.0607\n",
      "Epoch 15: loss improved from 0.00668 to 0.00653, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0061 - mean_absolute_error: 0.0607 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0064 - mean_absolute_error: 0.0605\n",
      "Epoch 16: loss improved from 0.00653 to 0.00591, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - loss: 0.0064 - mean_absolute_error: 0.0605 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0062 - mean_absolute_error: 0.0606\n",
      "Epoch 17: loss improved from 0.00591 to 0.00564, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0062 - mean_absolute_error: 0.0605 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0058 - mean_absolute_error: 0.0579\n",
      "Epoch 18: loss improved from 0.00564 to 0.00563, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - loss: 0.0058 - mean_absolute_error: 0.0579 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0052 - mean_absolute_error: 0.0553\n",
      "Epoch 19: loss improved from 0.00563 to 0.00540, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 162ms/step - loss: 0.0052 - mean_absolute_error: 0.0553 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0059 - mean_absolute_error: 0.0577\n",
      "Epoch 20: loss did not improve from 0.00540\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - loss: 0.0059 - mean_absolute_error: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0055 - mean_absolute_error: 0.0552\n",
      "Epoch 21: loss did not improve from 0.00540\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - loss: 0.0055 - mean_absolute_error: 0.0551 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.0042 - mean_absolute_error: 0.0493\n",
      "Epoch 22: loss improved from 0.00540 to 0.00458, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - loss: 0.0042 - mean_absolute_error: 0.0494 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0046 - mean_absolute_error: 0.0513\n",
      "Epoch 23: loss improved from 0.00458 to 0.00434, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 168ms/step - loss: 0.0046 - mean_absolute_error: 0.0513 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0050 - mean_absolute_error: 0.0523\n",
      "Epoch 24: loss did not improve from 0.00434\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.0050 - mean_absolute_error: 0.0523 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.0043 - mean_absolute_error: 0.0507\n",
      "Epoch 25: loss improved from 0.00434 to 0.00430, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - loss: 0.0043 - mean_absolute_error: 0.0506 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0047 - mean_absolute_error: 0.0524\n",
      "Epoch 26: loss improved from 0.00430 to 0.00425, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - loss: 0.0047 - mean_absolute_error: 0.0523 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0044 - mean_absolute_error: 0.0501\n",
      "Epoch 27: loss did not improve from 0.00425\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.0044 - mean_absolute_error: 0.0501 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0041 - mean_absolute_error: 0.0483\n",
      "Epoch 28: loss improved from 0.00425 to 0.00392, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 166ms/step - loss: 0.0041 - mean_absolute_error: 0.0483 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0041 - mean_absolute_error: 0.0489\n",
      "Epoch 29: loss did not improve from 0.00392\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - loss: 0.0041 - mean_absolute_error: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.0037 - mean_absolute_error: 0.0455\n",
      "Epoch 30: loss improved from 0.00392 to 0.00370, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - loss: 0.0037 - mean_absolute_error: 0.0455 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0033 - mean_absolute_error: 0.0451\n",
      "Epoch 31: loss improved from 0.00370 to 0.00354, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - loss: 0.0033 - mean_absolute_error: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0039 - mean_absolute_error: 0.0466\n",
      "Epoch 32: loss did not improve from 0.00354\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - loss: 0.0039 - mean_absolute_error: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0034 - mean_absolute_error: 0.0448\n",
      "Epoch 33: loss did not improve from 0.00354\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.0034 - mean_absolute_error: 0.0448 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0036 - mean_absolute_error: 0.0462\n",
      "Epoch 34: loss improved from 0.00354 to 0.00339, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.0036 - mean_absolute_error: 0.0461 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0029 - mean_absolute_error: 0.0421\n",
      "Epoch 35: loss improved from 0.00339 to 0.00337, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - loss: 0.0030 - mean_absolute_error: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0032 - mean_absolute_error: 0.0429\n",
      "Epoch 36: loss improved from 0.00337 to 0.00320, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 162ms/step - loss: 0.0032 - mean_absolute_error: 0.0429 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0037 - mean_absolute_error: 0.0447\n",
      "Epoch 37: loss did not improve from 0.00320\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 166ms/step - loss: 0.0037 - mean_absolute_error: 0.0447 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 0.0035 - mean_absolute_error: 0.0451\n",
      "Epoch 38: loss did not improve from 0.00320\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 191ms/step - loss: 0.0035 - mean_absolute_error: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 0.0032 - mean_absolute_error: 0.0431\n",
      "Epoch 39: loss did not improve from 0.00320\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 274ms/step - loss: 0.0032 - mean_absolute_error: 0.0431 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.0031 - mean_absolute_error: 0.0421\n",
      "Epoch 40: loss did not improve from 0.00320\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 247ms/step - loss: 0.0031 - mean_absolute_error: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - loss: 0.0031 - mean_absolute_error: 0.0419\n",
      "Epoch 41: loss improved from 0.00320 to 0.00306, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 316ms/step - loss: 0.0031 - mean_absolute_error: 0.0419 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 0.0030 - mean_absolute_error: 0.0428\n",
      "Epoch 42: loss did not improve from 0.00306\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 238ms/step - loss: 0.0030 - mean_absolute_error: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0031 - mean_absolute_error: 0.0422\n",
      "Epoch 43: loss improved from 0.00306 to 0.00303, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 175ms/step - loss: 0.0031 - mean_absolute_error: 0.0422 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0030 - mean_absolute_error: 0.0424\n",
      "Epoch 44: loss improved from 0.00303 to 0.00288, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - loss: 0.0030 - mean_absolute_error: 0.0424 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0034 - mean_absolute_error: 0.0444\n",
      "Epoch 45: loss did not improve from 0.00288\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - loss: 0.0034 - mean_absolute_error: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0029 - mean_absolute_error: 0.0411\n",
      "Epoch 46: loss did not improve from 0.00288\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0029 - mean_absolute_error: 0.0411 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.0030 - mean_absolute_error: 0.0420\n",
      "Epoch 47: loss did not improve from 0.00288\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - loss: 0.0030 - mean_absolute_error: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0028 - mean_absolute_error: 0.0399\n",
      "Epoch 48: loss improved from 0.00288 to 0.00282, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0028 - mean_absolute_error: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0029 - mean_absolute_error: 0.0411\n",
      "Epoch 49: loss improved from 0.00282 to 0.00275, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0029 - mean_absolute_error: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0031 - mean_absolute_error: 0.0413\n",
      "Epoch 50: loss did not improve from 0.00275\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - loss: 0.0031 - mean_absolute_error: 0.0413 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0027 - mean_absolute_error: 0.0398\n",
      "Epoch 51: loss improved from 0.00275 to 0.00264, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0027 - mean_absolute_error: 0.0398 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0028 - mean_absolute_error: 0.0402\n",
      "Epoch 52: loss did not improve from 0.00264\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 172ms/step - loss: 0.0028 - mean_absolute_error: 0.0402 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0025 - mean_absolute_error: 0.0387\n",
      "Epoch 53: loss improved from 0.00264 to 0.00261, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 173ms/step - loss: 0.0025 - mean_absolute_error: 0.0387 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0028 - mean_absolute_error: 0.0399\n",
      "Epoch 54: loss did not improve from 0.00261\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - loss: 0.0028 - mean_absolute_error: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0028 - mean_absolute_error: 0.0410\n",
      "Epoch 55: loss did not improve from 0.00261\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - loss: 0.0028 - mean_absolute_error: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.0022 - mean_absolute_error: 0.0359\n",
      "Epoch 56: loss improved from 0.00261 to 0.00239, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - loss: 0.0022 - mean_absolute_error: 0.0359 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0025 - mean_absolute_error: 0.0375\n",
      "Epoch 57: loss did not improve from 0.00239\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - loss: 0.0025 - mean_absolute_error: 0.0375 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0029 - mean_absolute_error: 0.0397\n",
      "Epoch 58: loss did not improve from 0.00239\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - loss: 0.0029 - mean_absolute_error: 0.0396 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0027 - mean_absolute_error: 0.0387\n",
      "Epoch 59: loss did not improve from 0.00239\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0027 - mean_absolute_error: 0.0387 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0025 - mean_absolute_error: 0.0381\n",
      "Epoch 60: loss did not improve from 0.00239\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 166ms/step - loss: 0.0025 - mean_absolute_error: 0.0381 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0024 - mean_absolute_error: 0.0379\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00239\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 168ms/step - loss: 0.0024 - mean_absolute_error: 0.0379 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0022 - mean_absolute_error: 0.0360\n",
      "Epoch 62: loss improved from 0.00239 to 0.00221, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 173ms/step - loss: 0.0022 - mean_absolute_error: 0.0360 - learning_rate: 2.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0025 - mean_absolute_error: 0.0370\n",
      "Epoch 63: loss did not improve from 0.00221\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.0025 - mean_absolute_error: 0.0369 - learning_rate: 2.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.0021 - mean_absolute_error: 0.0335\n",
      "Epoch 64: loss improved from 0.00221 to 0.00206, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 162ms/step - loss: 0.0021 - mean_absolute_error: 0.0335 - learning_rate: 2.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0020 - mean_absolute_error: 0.0342\n",
      "Epoch 65: loss improved from 0.00206 to 0.00201, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0020 - mean_absolute_error: 0.0342 - learning_rate: 2.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.0021 - mean_absolute_error: 0.0348\n",
      "Epoch 66: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - loss: 0.0021 - mean_absolute_error: 0.0348 - learning_rate: 2.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0020 - mean_absolute_error: 0.0342\n",
      "Epoch 67: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0020 - mean_absolute_error: 0.0342 - learning_rate: 2.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0022 - mean_absolute_error: 0.0357\n",
      "Epoch 68: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0022 - mean_absolute_error: 0.0357 - learning_rate: 2.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0019 - mean_absolute_error: 0.0321\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 69: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - loss: 0.0019 - mean_absolute_error: 0.0322 - learning_rate: 2.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0022 - mean_absolute_error: 0.0351\n",
      "Epoch 70: loss did not improve from 0.00201\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - loss: 0.0022 - mean_absolute_error: 0.0351 - learning_rate: 4.0000e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.0019 - mean_absolute_error: 0.0328\n",
      "Epoch 71: loss improved from 0.00201 to 0.00195, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 172ms/step - loss: 0.0019 - mean_absolute_error: 0.0328 - learning_rate: 4.0000e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0021 - mean_absolute_error: 0.0345\n",
      "Epoch 72: loss did not improve from 0.00195\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - loss: 0.0021 - mean_absolute_error: 0.0345 - learning_rate: 4.0000e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0019 - mean_absolute_error: 0.0328\n",
      "Epoch 73: loss improved from 0.00195 to 0.00187, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 168ms/step - loss: 0.0019 - mean_absolute_error: 0.0328 - learning_rate: 4.0000e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0022 - mean_absolute_error: 0.0348\n",
      "Epoch 74: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - loss: 0.0022 - mean_absolute_error: 0.0347 - learning_rate: 4.0000e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.0020 - mean_absolute_error: 0.0331\n",
      "Epoch 75: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 166ms/step - loss: 0.0020 - mean_absolute_error: 0.0331 - learning_rate: 4.0000e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0020 - mean_absolute_error: 0.0348\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 76: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 168ms/step - loss: 0.0020 - mean_absolute_error: 0.0348 - learning_rate: 4.0000e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0021 - mean_absolute_error: 0.0348\n",
      "Epoch 77: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - loss: 0.0021 - mean_absolute_error: 0.0347 - learning_rate: 8.0000e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.0018 - mean_absolute_error: 0.0320\n",
      "Epoch 78: loss improved from 0.00187 to 0.00187, saving model to checkpoints/weights_prev_multiple.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 173ms/step - loss: 0.0018 - mean_absolute_error: 0.0320 - learning_rate: 8.0000e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.0019 - mean_absolute_error: 0.0326\n",
      "Epoch 79: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - loss: 0.0019 - mean_absolute_error: 0.0327 - learning_rate: 8.0000e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0019 - mean_absolute_error: 0.0332\n",
      "Epoch 80: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 173ms/step - loss: 0.0019 - mean_absolute_error: 0.0332 - learning_rate: 8.0000e-06\n",
      "Epoch 81/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0019 - mean_absolute_error: 0.0318\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 81: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - loss: 0.0019 - mean_absolute_error: 0.0318 - learning_rate: 8.0000e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0019 - mean_absolute_error: 0.0331\n",
      "Epoch 82: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 174ms/step - loss: 0.0019 - mean_absolute_error: 0.0331 - learning_rate: 1.6000e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.0022 - mean_absolute_error: 0.0344\n",
      "Epoch 83: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - loss: 0.0022 - mean_absolute_error: 0.0344 - learning_rate: 1.6000e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0020 - mean_absolute_error: 0.0329\n",
      "Epoch 84: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - loss: 0.0020 - mean_absolute_error: 0.0330 - learning_rate: 1.6000e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.0022 - mean_absolute_error: 0.0348\n",
      "Epoch 85: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 173ms/step - loss: 0.0022 - mean_absolute_error: 0.0348 - learning_rate: 1.6000e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0022 - mean_absolute_error: 0.0348\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 86: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - loss: 0.0022 - mean_absolute_error: 0.0349 - learning_rate: 1.6000e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0021 - mean_absolute_error: 0.0351\n",
      "Epoch 87: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - loss: 0.0021 - mean_absolute_error: 0.0351 - learning_rate: 3.2000e-07\n",
      "Epoch 88/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.0020 - mean_absolute_error: 0.0330\n",
      "Epoch 88: loss did not improve from 0.00187\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0020 - mean_absolute_error: 0.0331 - learning_rate: 3.2000e-07\n",
      "Epoch 88: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7aad289a5420>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=32, callbacks=[reduce_plateau, model_checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_open = base_test_csv.iloc[:, 1:2].values\n",
    "x_high = base_test_csv.iloc[:, 2:3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_complete = pd.concat((base_train_csv['Open'], base_test_csv['Open']), axis=0)\n",
    "inputs = base_complete[len(base_complete) - len(base_test_csv) - antec:].values\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "inputs = normalizer.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [inputs[i-antec:i, 0:6] for i in range(antec, inputs.shape[0])]\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[15.8793125, 16.070995 ],\n",
       "       [16.00492  , 16.197744 ],\n",
       "       [16.117283 , 16.310972 ],\n",
       "       [16.24108  , 16.435808 ],\n",
       "       [16.37166  , 16.567486 ],\n",
       "       [16.493843 , 16.69055  ],\n",
       "       [16.61201  , 16.809502 ],\n",
       "       [16.715235 , 16.91325  ],\n",
       "       [16.788988 , 16.987055 ],\n",
       "       [16.838255 , 17.036053 ],\n",
       "       [16.889557 , 17.087248 ],\n",
       "       [16.956    , 17.15394  ],\n",
       "       [17.073359 , 17.272453 ],\n",
       "       [17.271421 , 17.472958 ],\n",
       "       [17.527246 , 17.731974 ],\n",
       "       [17.787088 , 17.994802 ],\n",
       "       [18.011505 , 18.221422 ],\n",
       "       [18.177176 , 18.388266 ],\n",
       "       [18.341078 , 18.553375 ],\n",
       "       [18.548101 , 18.762356 ],\n",
       "       [18.794794 , 19.01157  ],\n",
       "       [19.051588 , 19.270897 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevs = model.predict(x_test)\n",
    "prevs = normalizer.inverse_transform(prevs)\n",
    "prevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_open = base_test_csv.iloc[:, 1:2].values\n",
    "y_high = base_test_csv.iloc[:, 2:3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open: 0.6703866800093219\n",
      "High: 0.7417872847511986\n"
     ]
    }
   ],
   "source": [
    "print('Open:', mean_absolute_error(y_open.ravel(), prevs[:, 0]))\n",
    "print('High:', mean_absolute_error(y_high.ravel(), prevs[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHHCAYAAABKudlQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADVzUlEQVR4nOzdd1RUx9vA8S8dpEpRaYoNxIYl9oIFxRp7bySWqBh7/GmKYotJjMYSexQSNaKJLW9sKIq9YhdiBUVFRRSQDrvz/rFh4wooSBOdzzl72L13dmbupezDVC0hhECSJEmSJKmY0i7qCkiSJEmSJOWFDGYkSZIkSSrWZDAjSZIkSVKxJoMZSZIkSZKKNRnMSJIkSZJUrMlgRpIkSZKkYk0GM5IkSZIkFWsymJEkSZIkqViTwYwkSZIkScWaDGYkqQA5OTnh5eWV6/ctXrwYU1NTOnbsSGRkJJ6enuzYsSPf6/eq8PBwtLS08PPzK/CypMy0tLTw8fEp6mrkSd++fTE1NWXy5Mk8f/4cCwsLYmJiirpa0ntOBjPSe8PPzw8tLS31w9DQEGdnZ8aMGcPjx4+Lunq5MnfuXL788ktSUlKwt7fnxo0btG7duqirJUmvFRISQlBQEDNnzuSvv/7CysoKDw8PLCwsirpq0ntOt6grIEn5bdasWZQvX57k5GSOHTvGihUr2L17N1evXqVEiRKFWpfr16+jrZ37/xlOnjxJxYoVmTZtGo8ePcLKygo9Pb0CqKEk5Z8KFSoQHByMvb0948eP59GjR9ja2hZ1taQPgAxmpPdO+/bt+eijjwAYNmwYVlZWLFy4kJ07d9KvX78s35OQkICxsXG+18XAwOCt3lexYkX18zJlyuRXdd47SqWS1NRUDA0Ni7oqEmBoaIi9vT0A2tra2NnZFXGNpA+F7GaS3nutWrUCICwsDAAvLy9MTEy4ffs2HTp0wNTUlAEDBgCqD8dFixZRrVo1DA0NKV26NJ999hnPnz9X59epUycqVKiQZVmNGjVSB1KQecxMWloaM2fOpHLlyhgaGmJlZUXTpk3Zv3+/Os3FixcZPHgw5cuXx9DQkDJlyvDpp58SHR2dqbwLFy7Qvn17zMzMMDExoXXr1pw6dSpH9yUmJgYvLy/Mzc2xsLBgyJAh2Y5tOHjwIM2aNcPY2BgLCwu6dOlCaGioRpoXL14wfvx4nJycMDAwoFSpUrRp04bz58+/th4+Pj5oaWnxzz//0Lt3b8zMzLCysmLcuHEkJydrpNXS0mLMmDFs3LiRatWqYWBgwN69ewF48OABn376KaVLl8bAwIBq1aqxbt26TOUlJyfj4+ODs7MzhoaG2Nra0r17d27fvq1Ok5CQwKRJk3B0dMTAwAAXFxd+/PFHhBAaee3fv5+mTZtiYWGBiYkJLi4ufPnll6+9XoCUlBQmTJiAjY0NpqamfPzxx9y/fz9Turt37zJ69GhcXFwwMjLCysqKXr16ER4erpEuJz9XWXn27BmTJ0+mRo0amJiYYGZmRvv27bl06VKB3jeADRs2ULduXYyMjLC0tKRv375ERERopLl58yY9evSgTJkyGBoa4uDgQN++fYmNjX3tdUkfHtkyI733Mv7YWllZqY+lp6fj6elJ06ZN+fHHH9XdT5999hl+fn588sknjB07lrCwMH7++WcuXLjA8ePH0dPTo0+fPgwePJizZ89Sr149dZ53797l1KlTzJ8/P9u6+Pj4MG/ePIYNG0b9+vWJi4vj3LlznD9/njZt2gCwb98+wsPD+fTTTylTpgzXrl1j9erVXLt2jVOnTqGlpQXAtWvXaNasGWZmZkyZMgU9PT1WrVpFixYtOHz4MA0aNMi2HkIIunTpwrFjxxg5ciSurq5s376dIUOGZEp74MAB2rdvT4UKFfDx8SEpKYmlS5fSpEkTzp8/j5OTEwAjR47kzz//ZMyYMVStWpXo6GiOHTtGaGgoderUeeP3qXfv3jg5OTFv3jxOnTrFkiVLeP78Ob/99ptGuoMHD7JlyxbGjBmDtbU1Tk5OPH78mIYNG6qDHRsbG/bs2cPQoUOJi4tj/PjxACgUCjp16kRgYCB9+/Zl3LhxvHjxgv3793P16lUqVqyIEIKPP/6YQ4cOMXToUGrVqsW+ffv44osvePDgAT/99JP6/nfq1ImaNWsya9YsDAwMuHXrFsePH3/jtQ4bNowNGzbQv39/GjduzMGDB+nYsWOmdGfPnuXEiRP07dsXBwcHwsPDWbFiBS1atCAkJET9c5uTn6us3Llzhx07dtCrVy/Kly/P48ePWbVqFe7u7oSEhKhbVvLzvoFqTNg333xD7969GTZsGFFRUSxdupTmzZtz4cIFLCwsSE1NxdPTk5SUFD7//HPKlCnDgwcP+Pvvv4mJicHc3PyN91n6gAhJek/4+voKQBw4cEBERUWJiIgI4e/vL6ysrISRkZG4f/++EEKIIUOGCEBMnTpV4/1Hjx4VgNi4caPG8b1792ocj42NFQYGBmLSpEka6X744QehpaUl7t69qz5Wrlw5MWTIEPVrNzc30bFjx9deR0JCQqZjmzZtEoA4cuSI+ljXrl2Fvr6+uH37tvrYw4cPhampqWjevPlry9ixY4cAxA8//KA+lp6eLpo1ayYA4evrqz5eq1YtUapUKREdHa0+dunSJaGtrS0GDx6sPmZubi68vb1fW25WZsyYIQDx8ccfaxwfPXq0AMSlS5fUxwChra0trl27ppF26NChwtbWVjx9+lTjeN++fYW5ublITEwUQgixbt06AYiFCxdmqodSqRRC/Hdv5syZo3G+Z8+eQktLS9y6dUsIIcRPP/0kABEVFZWr67148aIAxOjRozWO9+/fXwBixowZ6mMZ9X7ZyZMnBSB+++039bGc/FxlJTk5WSgUCo1jYWFhwsDAQMyaNUt9LD/vW3h4uNDR0RFz587VSHflyhWhq6urPn7hwgUBiD/++CPX1yV9eGQ3k/Te8fDwwMbGBkdHR/r27YuJiQnbt29X9+VnGDVqlMbrP/74A3Nzc9q0acPTp0/Vj7p162JiYsKhQ4cA1E3xW7Zs0Wg+37x5Mw0bNqRs2bLZ1s3CwoJr165x8+bNbNO8PEg5OTmZp0+f0rBhQwB1l41CoSAgIICuXbtqdHnZ2trSv39/jh07RlxcXLZl7N69G11dXY17oKOjw+eff66RLjIykosXL+Ll5YWlpaX6eM2aNWnTpg27d+/WuLbTp0/z8OHDbMt9HW9vb43XGXV5uQwAd3d3qlatqn4thGDr1q107twZIYTG987T05PY2Fj1fdu6dSvW1taZrhNQt3jt3r0bHR0dxo4dq3F+0qRJCCHYs2eP+noBdu7ciVKpzPF1ZlzPq/lntB69zMjISP08LS2N6OhoKlWqhIWFhUb3XU5+rrJiYGCgHqCuUCiIjo5Wd5e9nH9+3rdt27ahVCrp3bu3xveqTJkyVK5cWf17ltHysm/fPhITE3N1XdKHRwYz0ntn2bJl7N+/n0OHDhESEsKdO3fw9PTUSKOrq4uDg4PGsZs3bxIbG0upUqWwsbHReMTHx/PkyRN12j59+hAREcHJkycBVVdWcHAwffr0eW3dZs2aRUxMDM7OztSoUYMvvviCy5cva6R59uwZ48aNo3Tp0hgZGWFjY0P58uUB1GMFoqKiSExMxMXFJVMZrq6uKJXKTOMPXnb37l1sbW0xMTHROP5qfnfv3s3yeEY5T58+JSEhAYAffviBq1ev4ujoSP369fHx8eHOnTuvvR8vq1y5ssbrihUroq2tnWl8SMa9yBAVFUVMTAyrV6/O9H375JNPANTfu9u3b+Pi4oKubvY97Hfv3sXOzg5TU9NM15txHlQ/A02aNGHYsGGULl2avn37smXLljcGNnfv3kVbW1tjkDdkfY+TkpKYPn26egyKtbU1NjY2xMTEaIwbycnPVVaUSiU//fQTlStX1sj/8uXLGvnn5327efMmQggqV66c6fsVGhqq/l6VL1+eiRMn8ssvv2BtbY2npyfLli2T42WkLMkxM9J7p379+hqDcLPy8n+kGZRKJaVKlWLjxo1ZvsfGxkb9vHPnzpQoUYItW7bQuHFjtmzZgra2Nr169Xptuc2bN+f27dvs3LmTgIAAfvnlF3766SdWrlzJsGHDANXYkRMnTvDFF19Qq1YtTExMUCqVtGvXLlctAIWtd+/eNGvWjO3btxMQEMD8+fP5/vvv2bZtG+3bt891fhn/8b/q5dYKQH1PBg4cmOWYH1C1JOU3IyMjjhw5wqFDh9i1axd79+5l8+bNtGrVioCAAHR0dPJcxueff46vry/jx4+nUaNGmJubo6WlRd++fTV+FnLyc5WVb7/9lm+++YZPP/2U2bNnY2lpiba2NuPHjy+wnzWlUomWlhZ79uzJ8h69HGAvWLAALy8v9XWNHTtWPabq1X9GpA9cUfZxSVJ+yhgzc/bs2demGzJkiDA2Ns50fPTo0UJHRyfLcQpZ6d27t7CzsxMKhUK4ubkJd3f3TGleHTPzqhcvXojatWsLe3t7IYQQz549E4CYOXOmRrobN25ojKdIT08XJUqUEL17986U58iRI4W2traIjY3NttwRI0YIXV1d8eLFC43jW7Zs0Rgz8/DhQwGIKVOmZMqjXbt2wtraOtsyHj9+LOzt7UWTJk2yTSPEf2Nm9u3bp3E8NDRUAGLevHnqY0CmcTnp6enC1NRU9OvX77XlCCFEx44dhbW1tUhNTc02zYgRI4SOjo6Ii4vTOH7q1CkBiKVLl2b73rlz5wpA7N+/P9s03377rQDEP//8o3H8zJkzmcbMmJubi08++UQjXVJSktDR0cnVz1V23NzcRMuWLTMdt7e31/h5zs/79sMPPwhAXL9+/bV1y8rx48cFIL766qtcv1d6v8luJkn6V+/evVEoFMyePTvTufT09EzTlvv06cPDhw/55ZdfuHTp0hu7mIBM06tNTEyoVKkSKSkpAOr/VMUrU1kXLVqk8VpHR4e2bduyc+dOjW6Yx48f8/vvv9O0aVPMzMyyrUeHDh1IT09nxYoV6mMKhYKlS5dqpLO1taVWrVr8+uuvGtd/9epVAgIC6NChg/q9rzb/lypVCjs7O/W1vcmyZcs0XmfU5U2tOjo6OvTo0YOtW7dy9erVTOejoqLUz3v06MHTp0/5+eefM6XLuOcdOnRAoVBkSvPTTz+hpaWlrs+zZ88y5VGrVi2A115zxvuXLFmicfzV73HGtb36s7B06VIUCoXGsTf9XGUnq/z/+OMPHjx4oHEsP+9b9+7d0dHRYebMmZnKFkKoryUuLo709HSN8zVq1EBbWzvHP1PSh0N2M0nSv9zd3fnss8+YN28eFy9epG3btujp6XHz5k3++OMPFi9eTM+ePdXpM9aomTx5svoD9U2qVq1KixYtqFu3LpaWlpw7d049nRlUg4ubN2/ODz/8QFpaGvb29gQEBKjXyHnZnDlz1OucjB49Gl1dXVatWkVKSgo//PDDa+vRuXNnmjRpwtSpUwkPD6dq1aps27Yty/EI8+fPp3379jRq1IihQ4eqp2abm5ur9xF68eIFDg4O9OzZEzc3N0xMTDhw4ABnz55lwYIFb7wvoFoH6OOPP6Zdu3acPHlSPXXZzc3tje/97rvvOHToEA0aNGD48OFUrVqVZ8+ecf78eQ4cOKAOPAYPHsxvv/3GxIkTOXPmDM2aNSMhIYEDBw4wevRounTpQufOnWnZsiVfffUV4eHhuLm5ERAQwM6dOxk/frx6rMusWbM4cuQIHTt2pFy5cjx58oTly5fj4OBA06ZNs61rrVq16NevH8uXLyc2NpbGjRsTGBjIrVu3MqXt1KkT69evx9zcnKpVq3Ly5EkOHDigscwAvPnnKjudOnVi1qxZfPLJJzRu3JgrV66wcePGTOso5ed9q1ixInPmzGHatGmEh4fTtWtXTE1NCQsLY/v27YwYMYLJkydz8OBBxowZQ69evXB2diY9PZ3169fn+HdN+sAUYauQJOWrvHYzZVi9erWoW7euMDIyEqampqJGjRpiypQp4uHDh5nSDhgwQADCw8Mjy7xe7WaaM2eOqF+/vrCwsBBGRkaiSpUqYu7cuRrN9/fv3xfdunUTFhYWwtzcXPTq1Uvd3fNyF4QQQpw/f154enoKExMTUaJECdGyZUtx4sSJ115/hujoaDFo0CBhZmYmzM3NxaBBg9TTYV+emi2EEAcOHBBNmjQRRkZGwszMTHTu3FmEhISoz6ekpIgvvvhCuLm5CVNTU2FsbCzc3NzE8uXL31iPjG6mkJAQ0bNnT2FqaipKliwpxowZI5KSkjTSkkU3U4bHjx8Lb29v4ejoKPT09ESZMmVE69atxerVqzXSJSYmiq+++kqUL19eAEJXV1f07NlTY4r7ixcvxIQJE4SdnZ3Q09MTlStXFvPnz1dPQxZCiMDAQNGlSxdhZ2cn9PX1hZ2dnejXr5+4cePGG685KSlJjB07VlhZWQljY2PRuXNnERERkel7/Pz5c/HJJ58Ia2trYWJiIjw9PcU///zzVj9XWUlOThaTJk0Stra2wsjISDRp0kScPHlSuLu7Z+o2za/7lmHr1q2iadOmwtjYWBgbG4sqVaoIb29vdffTnTt3xKeffioqVqwoDA0NhaWlpWjZsqU4cODAG++v9OHREiKLpRklSZIKiY+PDzNnziQqKgpra+tCLXvDhg3s3r2b33//vVDLLe7kfZPeNXLMjCRJH6zOnTvz559/yjEYuSTvm/SukWNmJEn64ISGhhIQEMDDhw9JS0sjOTn5rTcF/ZDI+ya9q2QwI0nSByc5OZk5c+aQnJzMl19+Kff5ySF536R3lRwzI0mSJElSsSbHzEiSJEmSVKzJYEaSJEmSpGLtvR8zo1QqefjwIaamptnu9SJJkiRJ0rtFCMGLFy+ws7PLtJfeq977YObhw4c4OjoWdTUkSZIkSXoLERERb9xY9L0PZjK2o4+IiHjtXjWSJEmSJL074uLicHR0VH+Ov857H8xkdC2ZmZnJYEaSJEmSipmcDBGRA4AlSZIkSSrWZDAjSZIkSVKxJoMZSZIkSZKKtfd+zExOKRQK0tLSiroaklSs6OnpoaOjU9TVkCTpA/fBBzNCCB49ekRMTExRV0WSiiULCwvKlCkj13GSJKnIfPDBTEYgU6pUKUqUKCH/IEtSDgkhSExM5MmTJwDY2toWcY0kSfpQfdDBjEKhUAcyVlZWRV0dSSp2jIyMAHjy5AmlSpWSXU6SJBWJD3oAcMYYmRIlShRxTSSp+Mr4/ZFjziRJKiofdDCTQXYtSdLbk78/kiQVNRnMSJIkSZJUrMlgRipU4eHhaGlpcfHixQIvy8nJiUWLFhV4Oe87Ly8vunbtWtTVkCRJypYMZoohLy8vtLS00NLSQl9fn0qVKjFr1izS09OLumqFrkqVKhgYGPDo0aNCLbdFixaMHz++UMt81cs/B3p6epQvX54pU6aQnJxcpPWSJEkqbDKYKabatWtHZGQkN2/eZNKkSfj4+DB//vws06amphZy7QrHsWPHSEpKomfPnvz666+FUmZ+38u85pfxc3Dnzh1++uknVq1axYwZM/KpdpIkFQUhBM+fPy/qahQrMpgppgwMDChTpgzlypVj1KhReHh48NdffwH/dQvMnTsXOzs7XFxcAIiIiKB3795YWFhgaWlJly5dCA8P18h33bp1VKtWDQMDA2xtbRkzZoz63L179+jSpQsmJiaYmZnRu3dvHj9+/Np6njlzhtq1a2NoaMhHH33EhQsXMqW5evUq7du3x8TEhNKlSzNo0CCePn36xnuwdu1a+vfvz6BBg1i3bl2WaV68eEG/fv0wNjbG3t6eZcuWaZyPiYlh2LBh2NjYYGZmRqtWrbh06ZL6vI+PD7Vq1eKXX36hfPnyGBoa4uXlxeHDh1m8eLG6ZSQ8PBw/Pz8sLCw08t+xY4fGANms8gPYu3cvTZs2xcLCAisrKzp16sTt27ffeA8yfg4cHR3p2rUrHh4e7N+/X31eqVQyb948ypcvj5GREW5ubvz555/q8wqFgqFDh6rPu7i4sHjx4jeWK0lS/nr48CHr16/Hy8uLsmXLYmlpyfjx4xFCFHXVioUiDWbmzZtHvXr1MDU1pVSpUnTt2pXr169rpElOTsbb2xsrKytMTEzo0aPHGz9A80QISEgo/Ecef2CNjIw0/ssPDAzk+vXr7N+/n7///pu0tDQ8PT0xNTXl6NGjHD9+HBMTE9q1a6d+34oVK/D29mbEiBFcuXKFv/76i0qVKgGqD8UuXbrw7NkzDh8+zP79+7lz5w59+vTJtk7x8fF06tSJqlWrEhwcjI+PD5MnT9ZIExMTQ6tWrahduzbnzp1j7969PH78mN69e7/2el+8eMEff/zBwIEDadOmDbGxsRw9ejRTuvnz5+Pm5saFCxeYOnUq48aN0/iw79WrF0+ePGHPnj0EBwdTp04dWrduzbNnz9Rpbt26xdatW9m2bRsXL15k8eLFNGrUiOHDhxMZGUlkZCSOjo6vre/LXs0PICEhgYkTJ3Lu3DkCAwPR1tamW7duKJXKHOd79epVTpw4gb6+vvrYvHnz+O2331i5ciXXrl1jwoQJDBw4kMOHDwOq76uDgwN//PEHISEhTJ8+nS+//JItW7bkuFxJknIvJiaGnTt38vnnn1O1alXs7e0ZPHgwv/76K/fv3wdg8eLFfPnll0Vc02JCFCFPT0/h6+srrl69Ki5evCg6dOggypYtK+Lj49VpRo4cKRwdHUVgYKA4d+6caNiwoWjcuHGOy4iNjRWAiI2NzXQuKSlJhISEiKSkpP8OxscLoQotCvfx0jW/yZAhQ0SXLl2EEEIolUqxf/9+YWBgICZPnqw+X7p0aZGSkqJ+z/r164WLi4tQKpXqYykpKcLIyEjs27dPCCGEnZ2d+Oqrr7IsMyAgQOjo6Ih79+6pj127dk0A4syZM1m+Z9WqVcLKykrj/q5YsUIA4sKFC0IIIWbPni3atm2r8b6IiAgBiOvXr2d7D1avXi1q1aqlfj1u3DgxZMgQjTTlypUT7dq10zjWp08f0b59eyGEEEePHhVmZmYiOTlZI03FihXFqlWrhBBCzJgxQ+jp6YknT55opHF3dxfjxo3TOObr6yvMzc01jm3fvl28/GuWXX6vioqKEoC4cuVKtmmGDBkidHR0hLGxsTAwMBCA0NbWFn/++acQQojk5GRRokQJceLECY33DR06VPTr1y/bfL29vUWPHj00ysn4ectKlr9HkiRpSEpKEgcOHBDTpk0T9evXF9ra2gJQP7S0tETdunXFlClTREBAgFi6dKn63Ny5c4u6+kXidZ/fryrSFYD37t2r8drPz49SpUoRHBxM8+bNiY2NZe3atfz++++0atUKAF9fX1xdXTl16hQNGzYsimq/E/7++29MTExIS0tDqVTSv39/fHx81Odr1Kih8R/6pUuXuHXrFqamphr5JCcnc/v2bZ48ecLDhw9p3bp1luWFhobi6Oio0QJRtWpVLCwsCA0NpV69elm+p2bNmuquFIBGjRpppLl06RKHDh3CxMQk0/tv376Ns7NzlvVZt24dAwcOVL8eOHAg7u7uLF26VOMaXy2vUaNG6hlOly5dIj4+PtPqz0lJSRpdPOXKlcPGxibLeryNrPK7efMm06dP5/Tp0zx9+lTdInPv3j2qV6+ebV4tW7ZkxYoVJCQk8NNPP6Grq0uPHj0AVQtQYmIibdq00XhPamoqtWvXVr9etmwZ69at4969eyQlJZGamkqtWrXy6Wol6cOkUCg4f/48Bw4cIDAwkOPHj2canO/s7Ezr1q3x8PCgRYsWWFpaqs+1adOGlJQUJk+ezFdffYWxsTHjxo0r7MsoNt6p7QxiY2MB1N/Q4OBg0tLS8PDwUKepUqUKZcuW5eTJk1kGMykpKaSkpKhfx8XF5a4SJUpAfPxb1D6PcrkKccaHmL6+PnZ2dujqan4rjY2NNV7Hx8dTt25dNm7cmCkvGxsbtLWLpscxPj6ezp078/3332c6l91ePyEhIZw6dYozZ87wv//9T31coVDg7+/P8OHDc1y2ra0tQUFBmc69PPbl1XuZHW1t7Uz921mtiptVfp07d6ZcuXKsWbMGOzs7lEol1atXf+MAYWNjY3VX4Lp163Bzc2Pt2rUMHTqU+H9/jnft2oW9vb3G+wwMDADw9/dn8uTJLFiwgEaNGmFqasr8+fM5ffp0jq5ZkiQVIQT//PMPgYGBBAYGEhQUlGkDY1tbWzw8PGjdujWtW7fGwcHhtXlOmjSJ+Ph4fHx8GD9+PMbGxgwbNqwAr6L4emeCGaVSyfjx42nSpIn6P9FHjx6hr6+faVBl6dKls52KO2/ePGbOnPn2FdHSghx+eBWllz/EcqJOnTps3ryZUqVKYWZmlmUaJycnAgMDadmyZaZzrq6uREREEBERoW6dCQkJISYmhqpVq2aZn6urK+vXryc5OVndOnPq1KlM9dq6dStOTk6ZArLsrF27lubNm2cazOvr68vatWs1gplXyzt16hSurq7qsh89eoSuri5OTk45KjuDvr4+CoVC45iNjQ0vXrwgISFBHbDkZD2d6Ohorl+/zpo1a2jWrBmgmqmVW9ra2nz55ZdMnDiR/v37U7VqVQwMDLh37x7u7u5Zvuf48eM0btyY0aNHq4/lZOCxJEkqZ86c4eeffyYwMJCHDx9qnDM3N6dly5bq4KVKlSq5XjF7+vTpvHjxggULFjBixAiMjY3p169ffl7C+6HAO71yaOTIkaJcuXIiIiJCfWzjxo1CX18/U9p69eqJKVOmZJlPcnKyiI2NVT8yxl/keMxMMfCmMQxZnU9ISBCVK1cWLVq0EEeOHBF37twRhw4dEp9//rn6nvv5+QlDQ0OxePFicePGDREcHCyWLFkihFCNzalVq5Zo1qyZCA4OFqdPnxZ169YV7u7u2dbjxYsXwtraWgwcOFBcu3ZN7Nq1S1SqVEljzMyDBw+EjY2N6Nmzpzhz5oy4deuW2Lt3r/Dy8hLp6emZ8kxNTRU2NjZixYoVmc6FhIQIQFy9elUIoRozY2ZmJr7//ntx/fp18fPPPwsdHR2xd+9e9TU1bdpUuLm5iX379omwsDBx/Phx8eWXX4qzZ88KIVRjXNzc3DKVNXz4cFGvXj0RFhYmoqKihEKhENHR0cLY2FiMHTtW3Lp1S2zcuFHY2dllGjPzan4KhUJYWVmJgQMHips3b4rAwEBRr149AYjt27dne3+z+j6npaUJe3t7MX/+fCGEEF999ZWwsrISfn5+4tatW+rvqZ+fnxBCiMWLFwszMzOxd+9ecf36dfH1118LMzMzjTrKMTOSlLWnT5+KEiVKqMe2GBgYiNatW4tvv/1WnD59WqSlpeVLOUqlUowcOVIAQkdHR+zYsSNf8n3X5WbMzDsRzHh7ewsHBwdx584djeOBgYECEM+fP9c4XrZsWbFw4cIc5Z3rAcDFwNsEM0IIERkZKQYPHiysra2FgYGBqFChghg+fLjGvVm5cqVwcXERgLCwsBCff/65+tzdu3fFxx9/LIyNjYWpqano1auXePTo0WvrevLkSeHm5ib09fVFrVq1xNatWzWCGSGEuHHjhujWrZuwsLAQRkZGokqVKmL8+PEag5Uz/Pnnn0JbWzvbcl1dXcWECROEEKpgZubMmaJXr16iRIkSokyZMmLx4sUa6ePi4sTnn38u7OzshJ6ennB0dBQDBgxQD3TOLpi5fv26aNiwoTAyMhKACAsLE0KoBvxWqlRJGBkZiU6dOonVq1e/MZgRQoj9+/cLV1dXYWBgIGrWrCmCgoLeKpgRQoh58+YJGxsbER8fL5RKpVi0aJFwcXERenp6wsbGRnh6eorDhw8LIVTBv5eXlzA3NxcWFhZi1KhRYurUqTKYkaQc+OGHHwQgXF1dxYEDB0RiYmKBlaVQKMSgQYMEIPT19UVAQECBlfWuKDbBjFKpFN7e3sLOzk7cuHEj0/mYmBihp6ennp0hhBD//POPAMTJkydzVMb7GMwUht9//118/fXXRV0NqRiQv0fSh0ihUIjy5csLQKxZs6ZQykxLSxPdu3cXgDAyMhJHjx4tlHKLSm6CmSJdZ8bb25sNGzbw+++/Y2pqyqNHj3j06BFJSUmAqr9x6NChTJw4kUOHDhEcHMwnn3xCo0aNPuiZTAXt2rVrCCHUi/BJkiRJmvbu3UtYWBgWFhb079+/UMrU1dXl999/p127diQlJdGxY0fOnTtXKGVnJzIykmHDhhEZGVmk9SjSYGbFihXExsbSokULbG1t1Y/Nmzer0/z000906tSJHj160Lx5c8qUKcO2bduKsNbvvy5dujBs2LDXLognSZL0IcuYgPDJJ59QIpezUfPCwMCArVu34u7uTlxcHJ6enly9erXQys+Qnp7OokWLcHFxYe3atXzxxReFXoeXaQnxfq+VHBcXh7m5ObGxsZlm8SQnJxMWFqaxrLwkSbkjf4+kD82dO3eoVKkSQghu3LhB5cqVC70OL168oE2bNpw+fZrSpUtz9OjRQqvHkSNH8Pb2VgdR9evXZ9myZXz00Uf5Ws7rPr9fJfdmkiRJkqRcWLlyJUII2rZtWySBDICpqSl79uyhZs2aPH78mNatW3P37t0CLTMyMpJBgwbh7u7O1atXsbKyYs2aNZw8eTLfA5ncksGMJEmSJOVQUlISa9euBVTjPotSyZIlCQgIwMXFhYiICDw8PApk7MrLXUobNmxAS0uLkSNHcuPGDYYNG1Zki66+rOhrIEmSJEnFxJYtW3j27Blly5alY8eORV0dSpcuzYEDB3BycuLWrVu0adOGp0+f5lv+R44coU6dOkyYMIEXL15Qr149zpw5w4oVKzS2XyhqMpiRJEmSpBzKGPg7cuRIdHR0irg2Kg4ODgQGBmJnZ8e1a9fw9PRUbw/0th49eqTuUrpy5Yq6S+nUqVNF3qWUFRnMSJIkSVIOnD17lrNnz6Kvr8/QoUOLujoaKlSowIEDB7C2tub8+fN07NiRhISEXOeTVZfSZ599xvXr19+ZLqWsvJu1kiRJkqR3zPLlywHo1asXpUqVKuLaZObq6sr+/fuxsLDg+PHjdO3aNdNO3a9z9OhRdZdSXFycuktp5cqVWFlZFWDN804GM1KR8/LyomvXrkVdjbcWHh6OlpZWjjaVlCSpeIqOjsbf3x8o+oG/r1OrVi327NmDsbExBw4coHfv3qSlpb32PRldSs2bN1d3Ka1evfqd7VLKigxmiiEvLy+0tLTQ0tJCX1+fSpUqMWvWLNLT04u6atn67LPP0NHR4Y8//nhj2hYtWjB+/Pg8l5kRZGQ8LC0tcXd35+jRo3nOW5KkD4uvry/JycnUqlXrnV+BvmHDhvzf//0fhoaG/N///R+DBw9GoVBkSpeens7ixYuz7FIaPnz4O9ullJXiU1NJQ7t27YiMjOTmzZtMmjQJHx8f5s+fn2Xa1NTUQq6dpsTERPz9/ZkyZQrr1q0r9PIPHDhAZGQkR44cwc7Ojk6dOvH48eNCr4ckScWTUqlkxYoVgKpVRktLq4hr9GYtW7Zk69at6Onp4e/vz4gRI1AqlerzGV1K48ePL3ZdSlmRwUwxZWBgQJkyZShXrhyjRo3Cw8NDvZdSRrfN3LlzsbOzw8XFBYCIiAh69+6NhYUFlpaWdOnShfDwcI18161bR7Vq1TAwMMDW1pYxY8aoz927d48uXbpgYmKCmZkZvXv3zlFQ8Mcff1C1alWmTp3KkSNHiIiIyDatl5cXhw8fZvHixeoWlfDwcBQKBUOHDqV8+fIYGRnh4uLC4sWLc3SvrKysKFOmDNWrV+fLL78kLi6O06dPq89fvXqV9u3bY2JiQunSpRk0aJDG1Ma9e/fStGlTLCwssLKyolOnTty+fTtHZUuSVPzt27ePO3fuYG5uXmj7MOWHDh068Pvvv6Otrc26deuYMGECjx49YvDgweouJUtLy2LXpZQVGcy8QghBQkJCoT/yuquEkZGRRgtMYGAg169fZ//+/fz999+kpaXh6emJqakpR48e5fjx45iYmNCuXTv1+1asWIG3tzcjRozgypUr/PXXX1SqVAlQ/WfSpUsXnj17xuHDh9m/fz937tzJ0f5Na9euZeDAgZibm9O+fXv8/PyyTbt48WIaNWrE8OHDiYyMJDIyEkdHR5RKJQ4ODvzxxx+EhIQwffp0vvzyS7Zs2ZLje5SUlMRvv/0GgL6+PgAxMTG0atWK2rVrc+7cOfbu3cvjx4/p3bu3+n0JCQlMnDiRc+fOERgYiLa2Nt26ddP4L0eSpPdXUe3DlB969uypbhFfsmQJTg4OrF+/Hi0tLUb06MGNM2cY/g7PUsqxgty++13wui3Ek5KSREhIiEhKSlIfi4+PF0ChP+Lj43N8TUOGDBFdunQRQgihVCrF/v37hYGBgZg8ebL6fOnSpUVKSor6PevXrxcuLi5CqVSqj6WkpAgjIyOxb98+IYQQdnZ24quvvsqyzICAAKGjoyPu3bunPnbt2jUBiDNnzmRb1xs3bgg9PT0RFRUlhBBi+/btonz58hr1ePl6hBDC3d1djBs37o33wdvbW/To0SPb82FhYQIQRkZGwtjYWGhpaQlA1K1bV6SmpgohhJg9e7Zo27atxvsiIiIEIK5fv55lvlFRUQIQV65c0SjnwoULb6zz+yir3yNJel/cuXNH/bcju78J76yUFCG2bhWic2ex7N9rAMRHIM6AEBkPY2MhqlQRwsNDiE8+EWL6dCHWrBFi714hrl4VIovPz8Lwus/vV+kWXJgkFaS///4bExMT0tLSUCqV9O/fHx8fH/X5GjVqqFsfAC5dusStW7cwNTXVyCc5OZnbt2/z5MkTHj58SOvWrbMsLzQ0FEdHRxwdHdXHqlatioWFBaGhodSrVy/L961btw5PT0+sra0BVbPn0KFDOXjwYLZlZWfZsmWsW7eOe/fukZSURGpqKrVq1Xrj+zZv3kyVKlW4evUqU6ZMwc/PDz09PUB1Xw4dOoSJiUmm992+fRtnZ2du3rzJ9OnTOX36NE+fPlW3yNy7d4/q1avn6hokSSpeMvZhatOmDc7OzkVdnTcTAi5cAD8/+P13iI4GYDTg4OxMYtmy9DI0ROf+fYiIUJ1PSIB//lE9smNmBo6OqoeDw3/PM16XLQtF2Golg5lXlChRgvj4+CIpNzdatmzJihUr0NfXx87ODl1dzW+lsbGxxuv4+Hjq1q3Lxo0bM+VlY2NTIE2MCoWCX3/9lUePHmnUT6FQsG7dulwFM/7+/kyePJkFCxbQqFEjTE1NmT9/vsbYl+w4OjpSuXJlKleuTHp6Ot26dePq1asYGBgQHx9P586d+f777zO9z9bWFoDOnTtTrlw51qxZg52dHUqlkurVqxf5wGpJkgpWcnLyO7MP0xs9eQIbNqiCmCtX/jtuawuDB8OQIXzs6pr5fUlJkBHYZDxefR0TA3FxcO2a6pGVMWNg6dKCuLIckcHMK7S0tDIFAu8iY2Nj9XiWnKhTpw6bN2+mVKlS2W6l7uTkRGBgIC1btsx0ztXVlYiICCIiItStMyEhIcTExFC1atUs89u9ezcvXrzgwoULGst+X716lU8++YSYmBgsLCwyvU9fXz/TNMLjx4/TuHFjRo8erT72NoNwe/bsyfTp01m+fDkTJkygTp06bN26FScnp0wBIajWlrh+/Tpr1qyhWbNmABw7dizX5UqSVPxs2bKF6OhoypYtS6dOnYq6OpmlpsKuXaoAZvduyFiew8AAunYFLy/w8IAs/rapGRlB5cqqR3bi4zMHOK8GPS+12hcFGcx8IAYMGMD8+fPp0qULs2bNwsHBgbt377Jt2zamTJmCg4MDPj4+jBw5klKlStG+fXtevHjB8ePH+fzzz/Hw8KBGjRoMGDCARYsWkZ6ezujRo3F3d892BPzatWvp2LEjbm5uGserVq3KhAkT2LhxY5b/7Tg5OXH69GnCw8MxMTHB0tKSypUr89tvv7Fv3z7Kly/P+vXrOXv2LOXLl8/VfdDS0mLs2LH4+Pjw2Wef4e3tzZo1a+jXrx9TpkzB0tKSW7du4e/vzy+//ELJkiXVC0jZ2tpy7949pk6dmqsyJUkqnjIG/mask/VOEAIuXlQFMBs3qruRAGjQQBXA9OkDJUvmX5kmJlCliuqRnSzWsSlMxXz4spRTJUqU4MiRI5QtW5bu3bvj6urK0KFDSU5OVrfUDBkyhEWLFrF8+XKcnZ1p3bo1N2/eBFRBwM6dOylZsiTNmzfHw8ODChUqsHnz5izLe/z4Mbt27aJHjx6ZzmXMBspovn3V5MmT0dHRoWrVqtjY2HDv3j0+++wzunfvTp8+fWjQoAHR0dEarTS5MWTIENLS0vj555+xs7Pj+PHjKBQK2rZtS40aNRg/fjwWFhZoa2ujra2Nv78/wcHBVK9enQkTJmS7no8kSe+Pc+fOcebMGfT19Rk2bFhRV0fVjfTTT1CrFtSpA0uWqAIZW1uYMgVCQuDUKRg5Mn8DmZwq4mBPS4g8zgl+x8XFxWFubk5sbGym7pXk5GTCwsIoX748hoaGRVTDd9OmTZsICQlh9uzZRV0V6R0nf4+k99Gnn36Kr68vAwYMYMOGDUVTiey6kfT1/+tGatPm9d1IxdjrPr9f9X7eASlPrl27hhCCv/76SwYzkiR9cKKjo9m0aRPAW7cAvxWlEm7fVnUjHTkCmzZpdiPVr/9fN5KlZeHVqxiQwYyUSZcuXXj48CFff/11UVdFkiSp0Pn5+an3YWrUqFHBFJKUBFevqgKXjMelS6pp0i8rU0Y9G4lsJltIMpiRsnDr1q2iroIkSVKReHkfptGjR+fPPkxRUZpBy8WLqjVdslpF3NAQatRQjY3p1u297kbKT/IOSZIkSe+Up0+fEhsbS8WKFQu97H379nH79u2324fp5W6ilx8PH2ad3toaatdWBS4ZD2dnGby8BXnHJEmSpHeGEAJ3d3f++ecf/vzzT7p161ao5S9fvhxQ7cOUozXHDh+GLVtUQcvly6o1WbJSubJm0FKrlmomUjHYgbs4kMGMJEmS9M6IiIggJCQEgH79+rF3715atGhRKGWHhYWxa9cuAEaNGvXmN/zxB/Ttq9ldZGCg6iZ6ucWlRg14ZSsZKX/JYEaSJEl6Zxw/flz9PCUlhY8//pigoCDq1KlT4GWvWrUq5/sw7doF/furApmuXaFnT1Xg4uIiu4mKgLzjkiRJ0jvjxIkTAIwYMYKbN29y6NAh2rVrx7Fjxwp0o8fk5GR++eUXIAf7MB08CD16qNZ96dtXtSfSu7JC8AdKrgAsSZIkvTMygplWrVqxY8cO6tSpQ1RUFG3btuXBgwcFVm7GPkyOjo507Ngx+4QnT8LHH0NKCnTuDL/9JgOZd4AMZqQc8/Pzy3JjyOycPHkSKysrBg8eTHh4OO7u7gVXuRzK7TVIklR44uPjuXTpEgBNmjTBzMyMPXv2ULlyZe7evYunpyfPnj0rkLIzBv6OHDkyy01nAbhwAdq3V60F4+GhGvirp1cg9ZFyRwYzxZCXlxdaWlpoaWmhr69PpUqVmDVrFukZS10XkD59+nDjxo0cp9+xYwc//vgj9vb2tGjRotBW0ty0aRM6OjpvbirOZ0FBQWhpaRETE1Oo5UrS++LMmTMoFAocHR1xcHAAoFSpUuzfvx87OzuuXbtGp06dSHh1Ybk8Cg4O5vTp0+jp6TF06NCsE4WGQtu2EBsLTZrAjh2qNWGkd4IMZoqpdu3aERkZyc2bN5k0aRI+Pj7ZboCYmpqaL2UaGRlRqlSpHKf//vvv+eSTT5g3bx7h4eH06dMnX+rxJmvXrmXKlCls2rSJ5OTkQikzLS3tnc5PkoqDjC6mxo0baxwvV64cAQEBlCxZkpMnT9KzZ898+7sG/+2O3atXL0qXLp05wZ07qpaYp0+hbl3V4N+cTNuWCo0MZoopAwMDypQpQ7ly5Rg1ahQeHh789ddfgKrlpmvXrsydOxc7OztcXFwA1ZTH3r17Y2FhgaWlJV26dCE8PByAgIAADA0NM7UqjBs3jlatWgGZu2guXbpEy5YtMTU1xczMjLp163Lu3Dn1+a1bt1KtWjUMDAxwcnJiwYIFGnmnpKQwefJk7O3tMTY2pkGDBgQFBanP3717l86dO1OyZEmMjY2pVq0au3fvfu19CQsL48SJE0ydOhVnZ2e2bduWZbodO3ZQuXJlDA0N8fT0JCIiQuP8zp07qVOnDoaGhlSoUIGZM2dqtHxpaWmxYsUKPv74Y4yNjRk+fDgtW7YEoGTJkmhpaeHl5QWAk5MTixYt0si/Vq1a+Pj4ZJvf3LlzUSgUDB06lPLly2NkZISLiwuLFy9+7fVLUnGWMZOpSZMmmc5Vq1aNXbt2UaJECfbu3YuXlxfKrFbQzaVnz56p92HKsjX3/n1o3Vq18F21arB3L5ib57lcKX/J2UyvEAISEwu/3BIl8rZ2kpGREdEvbUgWGBiImZkZ+/fvB1T/6Xt6etKoUSOOHj2Krq4uc+bMoV27dly+fJnWrVtjYWHB1q1b1c2sCoWCzZs3M3fu3CzLHDBgALVr12bFihXo6Ohw8eJF9P7tPw4ODqZ37974+PjQp08fTpw4wejRo7GyslJ/yI8ZM4aQkBD8/f2xs7Nj+/bttGvXjitXrlC5cmW8vb1JTU3lyJEjGBsbExISgomJyWvvg6+vLx07dsTc3JyBAweydu3aTKt4JiYmMnfuXH777Tf09fUZPXo0ffv2Vf8hPXr0KIMHD2bJkiU0a9aM27dvM2LECABmzJihzsfHx4fvvvuORYsWoaOjw8cff0yPHj24fv06ZmZmGBkZ5fTblyk/XV1dlEolDg4O/PHHH1hZWXHixAlGjBiBra0tvXv3zlXekvSuUyqVnDx5EsjcMpOhUaNGbN26lc6dO7Np0yasra1ZvHhxnrYc8PX1JTk5GTc3t8z7MD1+rApkwsOhUiXYv1+1aq/07hHvudjYWAGI2NjYTOeSkpJESEiISEpKUh+LjxdCFdIU7iM+PufXNGTIENGlSxchhBBKpVLs379fGBgYiMmTJ6vPly5dWqSkpKjfs379euHi4iKUSqX6WEpKijAyMhL79u0TQggxbtw40apVK/X5ffv2CQMDA/H8+XMhhBC+vr7C3Nxcfd7U1FT4+fllWcf+/fuLNm3aaBz74osvRNWqVYUQQty9e1fo6OiIBw8eaKRp3bq1mDZtmhBCiBo1aggfH5+c3hahUCiEo6Oj2LFjhxBCiKioKKGvry/u3LmjTuPr6ysAcerUKfWx0NBQAYjTp0+r6/Dtt99q5L1+/Xpha2urfg2I8ePHa6Q5dOiQANT3K0O5cuXETz/9pHHMzc1NzJgx47X5ZcXb21v06NHjjekKU1a/R5KUW1evXhWAKFGihEhNTX1t2t9//11oaWkJQMyaNeuty1QoFKJixYoCEKtXr9Y8GR0tRM2aqj/Qjo5ChIe/dTnS23nd5/erZDdTMfX3339jYmKCoaEh7du3p0+fPhrdFjVq1EBfX1/9+tKlS9y6dQtTU1NMTEwwMTHB0tKS5ORkbt++DahaWoKCgnj47z4iGzdupGPHjtnO/pk4cSLDhg3Dw8OD7777Tp0PQGhoaKam4iZNmnDz5k0UCgVXrlxBoVDg7Oysro+JiQmHDx9W5zN27FjmzJlDkyZNmDFjBpcvX37tPdm/fz8JCQl06NABAGtra9q0acO6des00unq6lKvXj316ypVqmBhYUFoaKj6Xs2aNUujXsOHDycyMpLEl5rtPvroo9fWJ7eyym/ZsmXUrVsXGxsbTExMWL16Nffu3cvXciXpXZAxXqZBgwbqFt7s9OvXjyVLlgAwffp09caQuRUQEJD1PkwvXqhmLV2+DKVLQ2AglCv3VmVIhUN2M72iRInst9Yo6HJzo2XLlqxYsQJ9fX3s7OwyTSV8dU+R+Ph46taty8aNGzPlZWNjA0C9evWoWLEi/v7+jBo1iu3bt+Pn55dtHXx8fOjfvz+7du1iz549zJgxA39//xztpRIfH4+Ojg7BwcHovLJGQ0ZX0rBhw/D09GTXrl0EBAQwb948FixYwOeff55lnmvXruXZs2ca3TtKpZLLly8zc+ZMtLVzFrvHx8czc+ZMunfvnumc4UuzF3K0bwugra2NEELjWFYDfF/Nz9/fn8mTJ7NgwQIaNWqEqakp8+fP5/Tp0zkqV5KKk4xu3uy6mF41ZswYoqKimDVrFt7e3lhZWeW6+zVj4K+Xl9d/v3+JidCpE5w5A5aWcOCAal8l6Z0mg5lXaGkVj0HqxsbGVKpUKcfp69Spw+bNmylVqhRmZmbZphswYAAbN27EwcEBbW3t1y8eBTg7O+Ps7MyECRPo168fvr6+dOvWDVdXV41lyUH1x8rZ2RkdHR1q166NQqHgyZMnNGvWLNv8HR0dGTlyJCNHjmTatGmsWbMmy2AmOjqanTt34u/vT7Vq1dTHFQoFTZs2JSAggHbt2gGQnp7OuXPnqF+/PgDXr18nJiYGV1dX9b26fv16ru4voG4JUygUGsdtbGyIjIxUv46LiyMsLOyN+R0/fpzGjRtrTGl/ufVLkt4n2c1keh0fHx+ePn3K8uXLGThwIBYWFrRt2zZH7w0PD8+8D1NKimpl3yNHVHsp7dsH1avn7kKkIiG7mT4QAwYMwNrami5dunD06FHCwsIICgpi7Nix3L9/XyPd+fPnmTt3Lj179sTAwCDL/JKSkhgzZgxBQUHcvXuX48ePc/bsWXVAMGnSJAIDA5k9ezY3btzg119/5eeff2by5MmAKggaMGAAgwcPZtu2bYSFhXHmzBnmzZun/gMzfvx49u3bR1hYGOfPn+fQoUPq/F+1fv169X9m1atXVz/c3Nzo0KEDa9euVafV09Pj888/5/Tp0wQHB+Pl5UXDhg3Vwc306dP57bffmDlzJteuXSM0NBR/f3++/vrr197jcuXKoaWlxd9//01UVBTx/zbxtWrVivXr13P06FGuXLnCkCFDMrVGZaVy5cqcO3eOffv2cePGDb755hvOnj37xvdJUnETFRXFzZs3ATIPwn0NLS0tlixZQp8+fUhLS6N79+45brlcuXIlQgg8PDxUMz7T01V7Le3dC0ZGsHs35HNXslSACnwETxHL7QDg4uDlAcC5OR8ZGSkGDx4srK2thYGBgahQoYIYPnx4pntTv359AYiDBw9qHH95AHBKSoro27evcHR0FPr6+sLOzk6MGTNG417++eefomrVqkJPT0+ULVtWzJ8/XyO/1NRUMX36dOHk5CT09PSEra2t6Natm7h8+bIQQogxY8aIihUrCgMDA2FjYyMGDRoknj59muU116hRQ4wePTrLc5s3bxb6+voiKipKfQ1bt24VFSpUEAYGBsLDw0PcvXtX4z179+4VjRs3FkZGRsLMzEzUr19fY4AgILZv356prFmzZokyZcoILS0tMWTIECGE6mewT58+wszMTDg6Ogo/P78sBwC/ml9ycrLw8vIS5ubmwsLCQowaNUpMnTpVuLm5ZXmdRaW4/h5J744dO3YIQD1BILdSUlJE27ZtBSAsLS1FSEjIa9MnJSUJa2vr/37vFAohBg5UDfbV1xciIOCt6iHlr9wMANYS4pXO/PdMXFwc5ubmxMbGZupeSU5OJiwsjPLly2uMhZAkKefk75GUV//73//44YcfGDZsGGvWrHmrPOLj4/Hw8OD06dM4ODhw/PhxypYtm2Xa9evXM3jwYBwdHblz+za6Y8fCypWqPZa2bVPtvSQVudd9fr9KdjNJkiRJReptxsu8ysTEhF27duHq6sr9+/dp27YtUVFRWabNGPj72YgR6E6bpgpktLRg/XoZyBRTMpiRJEmSikxKSop6LFhWK//mhpWVFQEBAZQtW5br16/ToUMHXrx4oZHm5X2YhsXGQsbK5GvWQL9+eSpfKjoymJEkSZKKzIULF0hJScHKyorK+TAF2sHBgYCAAKytrTl37hzdunUjJSVFfT5jd+xe1atT+scfVQcXLYLsNpiUigUZzEiSJElF5uUuprxsS/AyFxcX9uzZg4mJCYGBgQwYMACFQsGzZ8/4/fffARh94YIq8Zw5MG5cvpQrFR0ZzEiSJElF5nWbS+bFRx99xI4dO9DX12fr1q2MHj36v32YgMYAU6fCl1/ma7lS0ZCL5kmSJElFQgiRL4N/s9O6dWs2btxI7969Wb16NQb/bpMwGtAaMwa+/TZvO/xK7wzZMiNJkiQVifDwcB49eoSenl6+73WWoWfPnqxcuRKAlLQ0zIEBAwfC4sUykHmPyGBGkiRJKhIZXUx16tTR2FMtv40YMYJ5/24u+3nlyhj7+UEO92qTigfZzSRJkiQViYLsYtIgBFMfPmQYYLl4sWpxPOm9IkNTKcf8/PywsLDIcfqTJ09iZWXF4MGDCQ8Px93dveAql0O5vQZJkgpOoQUzV67AgwdYGxmh3bJlwZYlFQkZzBRDXl5eaGlpoaWlhb6+PpUqVWLWrFmkp6cXaLl9+vThxo0bOU6/Y8cOfvzxR+zt7WnRooXG7s8FadOmTejo6ODt7V0o5WUICgpCS0uLmJiYQi1XkoqjuLg4rly5AhRCMPPv5rW0bg1yy433kuxmKqbatWuHr68vKSkp7N69G29vb/T09Jg2bVqmtKmpqejr6+e5TCMjo1z1a3///ffq5/Pmzctz+Tm1du1apkyZwqpVq1iwYEGh7BeUlpaW7/np/TvzQpLeR6dPn0apVOLk5ISdnV3BFrZ7t+prhw4FW84HKD4mnnO+s6g/1IcSZiWKrB6yZaaYMjAwoEyZMpQrV45Ro0bh4eHBX3/9Bahabrp27crcuXOxs7NTbW8PRERE0Lt3bywsLLC0tKRLly6Eh4cDEBAQgKGhYaZWhXHjxtGqVSsgcxfNpUuXaNmyJaamppiZmVG3bl3OnTunPr9161aqVauGgYEBTk5OLMhYNvxfKSkpTJ48GXt7e4yNjWnQoAFBQUHq83fv3qVz586ULFkSY2NjqlWrxu6MP0rZCAsL48SJE0ydOhVnZ2e2bduWZbodO3ZQuXJlDA0N8fT0JCIiQuP8zp07qVOnDoaGhlSoUIGZM2dqtHxpaWmxYsUKPv74Y4yNjRk+fDgt/22+LlmyJFpaWnh5eQHg5OTEokWLNPKvVasWPj4+2eY3d+5cFAoFQ4cOpXz58hgZGeHi4sLixYtfe/2SVFwUWhfT8+fwb1kymMlfcdFx3Fnbjhal53Np1eAirYtsmXmFEJCYWPjlliiRt1mCRkZGREdHq18HBgZiZmbG/v37AdV/+p6enjRq1IijR4+iq6vLnDlzaNeuHZcvX6Z169ZYWFiwdetWhv67rLdCoWDz5s3MnTs3yzIHDBhA7dq1WbFiBTo6Oly8eFHdmhAcHEzv3r3x8fGhT58+nDhxgtGjR2NlZaX+kB8zZgwhISH4+/tjZ2fH9u3badeuHVeuXKFy5cp4e3uTmprKkSNHMDY2JiQkBBMTk9feB19fXzp27Ii5uTkDBw5k7dq19O/fXyNNYmIic+fO5bfffkNfX5/Ro0fTt29f9cyKo0ePMnjwYJYsWUKzZs24ffs2I0aMAGDGjBnqfHx8fPjuu+9YtGgROjo6fPzxx/To0YPr169jZmaW69kZL+enq6uLUqnEwcGBP/74AysrK06cOMGIESOwtbWld+/eucpbkt41GcFMfi+Wl0lAACiVUK0alCtXsGV9QGKePOf+hnbUtD1DTKIF5g3/V7QVEu+52NhYAYjY2NhM55KSkkRISIhISkpSH4uPF0IV0hTuIz4+59c0ZMgQ0aVLFyGEEEqlUuzfv18YGBiIyZMnq8+XLl1apKSkqN+zfv164eLiIpRKpfpYSkqKMDIyEvv27RNCCDFu3DjRqlUr9fl9+/YJAwMD8fz5cyGEEL6+vsLc3Fx93tTUVPj5+WVZx/79+4s2bdpoHPviiy9E1apVhRBC3L17V+jo6IgHDx5opGndurWYNm2aEEKIGjVqCB8fn5zeFqFQKISjo6PYsWOHEEKIqKgooa+vL+7cuaNO4+vrKwBx6tQp9bHQ0FABiNOnT6vr8O2332rkvX79emFra6t+DYjx48drpDl06JAA1PcrQ7ly5cRPP/2kcczNzU3MmDHjtfllxdvbW/To0eON6QpTVr9HkvQ66enpwtTUVADiwoULBVvY4MGqP7JffFGw5XxAoh8+FSELawuxEfF0lZUIPXG+QMp53ef3q2Q3UzH1999/Y2JigqGhIe3bt6dPnz4a3RY1atTQGCdz6dIlbt26hampKSYmJpiYmGBpaUlycjK3b98GVC0tQUFBPHz4EICNGzfSsWPHbGf/TJw4kWHDhuHh4cF3332nzgcgNDQ0039cTZo04ebNmygUCq5cuYJCocDZ2VldHxMTEw4fPqzOZ+zYscyZM4cmTZowY8YMLl++/Np7sn//fhISEujwb1OytbU1bdq0Yd26dRrpdHV1qffvmhMAVapUwcLCgtDQUPW9mjVrlka9hg8fTmRkJIkvNdvl9yJfWeW3bNky6tati42NDSYmJqxevZp79+7la7mSVNiuXbvGixcvMDExoXr16gVXkFIJe/aonssupnwRdf8JTze3xLX0BaJelCK69iGqNKpd1NWS3UyvKlEC4uOLptzcaNmyJStWrEBfXx87Ozt0dTW/lcbGxhqv4+PjqVu3Lhs3bsyUl42NDQD16tWjYsWK+Pv7M2rUKLZv346fn1+2dfDx8aF///7s2rWLPXv2MGPGDPz9/enWrdsb6x8fH4+Ojg7BwcHovLLmQ0ZX0rBhw/D09GTXrl0EBAQwb948FixYwOeff55lnmvXruXZs2ca3TtKpZLLly8zc+ZMtHO4SFZ8fDwzZ86ke/fumc69PJj41XucHW1tbYQQGseyGjD8an7+/v5MnjyZBQsW0KhRI0xNTZk/fz6nT5/OUbmS9K7K6GJq2LBhpr9d+ercOYiKAlNTKOjurA/A4/BI4ne2xrlUKI9ibUloGIhzbdeirhYgg5lMtLQgh59RRcrY2JhKlSrlOH2dOnXYvHkzpUqVwszMLNt0AwYMYOPGjTg4OKCtrU3Hjh1fm6+zszPOzs5MmDCBfv364evrS7du3XB1dVWPQclw/PhxnJ2d0dHRoXbt2igUCp48eUKzZs2yzd/R0ZGRI0cycuRIpk2bxpo1a7IMZqKjo9m5cyf+/v5Uq1ZNfVyhUNC0aVMCAgJo164dAOnp6Zw7d4769esDcP36dWJiYnB1dVXfq+vXr+fq/gLqljCFQqFx3MbGhsjISPXruLg4wsLC3pjf8ePHady4scaU9pdbvySpuMr421Dgg38zJgy0bQtydmCeRN6+T/LuVlS0ucnDGAdSmx2kYo3KRV0tNdnN9IEYMGAA1tbWdOnShaNHjxIWFkZQUBBjx47l/v37GunOnz/P3Llz6dmzJwYGBlnml5SUxJgxYwgKCuLu3bscP36cs2fPqgOCSZMmERgYyOzZs7lx4wa//vorP//8M5MnTwZUQdCAAQMYPHgw27ZtIywsjDNnzjBv3jx2/bsmxPjx49m3bx9hYWGcP3+eQ4cOqfN/1fr167GysqJ3795Ur15d/XBzc6NDhw6sXbtWnVZPT4/PP/+c06dPExwcjJeXFw0bNlQHN9OnT+e3335j5syZXLt2jdDQUPz9/fn6669fe4/LlSuHlpYWf//9N1FRUcT/28TXqlUr1q9fz9GjR7ly5QpDhgzJ1BqVlcqVK3Pu3Dn27dvHjRs3+Oabbzh79uwb3ydJ77pCm8mUEcy84Z8y6fXu/xNO2p7mlLe6yf3n5VC0PILTOxTIAHIAcHEcuPjyAODcnI+MjBSDBw8W1tbWwsDAQFSoUEEMHz48072pX7++AMTBgwc1jr88ADglJUX07dtXODo6Cn19fWFnZyfGjBmjcS///PNPUbVqVaGnpyfKli0r5s+fr5FfamqqmD59unBychJ6enrC1tZWdOvWTVy+fFkIIcSYMWNExYoVhYGBgbCxsRGDBg0ST58+zfKaa9SoIUaPHp3luc2bNwt9fX0RFRWlvoatW7eKChUqCAMDA+Hh4SHu3r2r8Z69e/eKxo0bCyMjI2FmZibq168vVq9erT4PiO3bt2cqa9asWaJMmTJCS0tLDBkyRAih+hns06ePMDMzE46OjsLPzy/LAcCv5pecnCy8vLyEubm5sLCwEKNGjRJTp04Vbm5uWV5nUSmuv0dS0YiMjBSA0NLSEjExMQVX0KNH/82wePiw4Mp5z4VfvSUifi4rxEZE+JKK4v71u29+Uz7JzQBgLSFe6cx/z8TFxWFubk5sbGym7pXk5GTCwsIoX758oSysJknvI/l7JOXGtm3b6NGjBzVq1HjjoP48+e03GDIE6tSB4OCCK+c9dufSdYxOtMLW/CF3nrpg1CkQ2wr2hVb+6z6/XyXHzEiSJEmFptC7mOQsprdyK/gaZmdbU8r8MbeiqmLWNZBS5coUdbWyJYMZSZIkqdAUSjCTng779qmey2Am166fvoTVJQ+szZ5y/bEbVr33Y21vU9TVei0ZzEiSJEmFIjk5meB/u3wKdOXfkychJgYsLeHfgf1SzoQeD6ZMSBtKmjwn5FFdbPsHULKMZVFX643kbCZJkiSpUAQHB5OamkqpUqWoUKFCwRWU0cXUrh3kYOagpHI16BR2oa0pafycK5ENsR90oFgEMiBbZiRJkqRC8nIXk1ZeNqN7EzklO9cuHzhG+XvtMS0Rz6WHzagwdBemJU2Lulo5JltmJEmSpEJRKJtL3r8Ply+rVkD19Cy4ct4jF/YeomKEJ6aG8Zx/2IpKw/cUq0AGZDAjSZIkFQIhROGs/JuxF1PDhmBlVXDlvCeC/w6gyqMOGBskcu6BJ64j/8bYvBgsg/8KGcxIkiRJBe727dtERUWhr69PnTp1Cq4gOSU7x87u2EX16M4Y6Sdz5kEnqo/egZGJ0Zvf+Ir01PQCqF3uyGBGkiRJKnAZXUwfffRRwS2umJIC+/ernstg5rVO/bkdt7huGOilcupBd2p9vhVD49x/X0KOnuX+KldunCnABRBzoEiDmSNHjtC5c2fs7OzQ0tJix44dGucfP36Ml5cXdnZ2lChRgnbt2nHz5s2iqayEn58fFhYWOU5/8uRJrKysGDx4MOHh4bi7uxdc5XIot9cgSVL+KJQupqNHISEBypSBWrUKrpxi7sSmzXyU1At93TROPOhL3bH+6Bvq5zqfyweO4XCjNU5Wt3h++JsCqGnOFWkwk5CQgJubG8uWLct0TghB165duXPnDjt37uTChQuUK1cODw8PEhISiqC27w4vLy+0tLTQ0tJCX1+fSpUqMWvWLNLTC7apr0+fPty4cSPH6Xfs2MGPP/6Ivb09LVq00Nj9uSBt2rQJHR0dvL2935jWx8eHWvKPniQVuEJZLO/lLiZt2fGQlWMb1tNA0R9dHQXHHgyiwfgN6BnkfkfxC3sOUjHCEzOjF1x86E7VYRsKoLY5V6RTs9u3b0/79u2zPHfz5k1OnTrF1atXqVatGgArVqygTJkybNq0iWHDhhVmVd857dq1w9fXl5SUFHbv3o23tzd6enpMmzYtU9rU1FT09XMfdb/KyMgII6Oc96d+//336ufz5s3Lc/k5tXbtWqZMmcKqVatYsGCB3C9IkopYTEwM165dAwoxmJEyOfrrOproDENbW3D04VAaj1+Fjl7u1+E5+9ceajzvhqFBCucetKXqZ9spYVaiAGqcc+9s6JqSkgKg8UGkra2NgYEBx44dK6pqvTMMDAwoU6YM5cqVY9SoUXh4ePDXX38Bqpabrl27MnfuXOzs7HBxcQEgIiKC3r17Y2FhgaWlJV26dCE8PByAgIAADA0NiYmJ0Shn3LhxtGrVCsjcRXPp0iVatmyJqakpZmZm1K1bl3PnzqnPb926lWrVqmFgYICTkxMLFizQyDslJYXJkydjb2+PsbExDRo0ICgoSH3+7t27dO7cmZIlS2JsbEy1atXYnfHHKhthYWGcOHGCqVOn4uzszLZt27JN6+fnx8yZM7l06ZK6pcvPzw+AhQsXUqNGDYyNjXF0dGT06NHEx8e/tmxJkrJ26tQphBBUrFiR0qVLF0wht2/D9eugqwseHgVTRjF2ePVimukNRVtbcCRyFE0mrH6rQObUn9txi+mCoV4Kpx98TA3vv4o8kIF3OJipUqUKZcuWZdq0aTx//pzU1FS+//577t+/T2RkZLbvS0lJIS4uTuORK0JAekLhP/K4ebmRkRGpqanq14GBgVy/fp39+/fz999/k5aWhqenJ6amphw9epTjx49jYmJCu3btSE1NpXXr1lhYWLB161Z1HgqFgs2bNzNgwIAsyxwwYAAODg6cPXuW4OBgpk6dip6eqrkyODiY3r1707dvX65cuYKPjw/ffPONOlgAGDNmDCdPnsTf35/Lly/Tq1cvjXFR3t7epKSkcOTIEa5cucL333+PiYnJa++Dr68vHTt2xNzcnIEDB7J27dps0/bp04dJkyZRrVo1IiMjiYyMpE+fPoAqcF6yZAnXrl3j119/5eDBg0yZMuX13wRJkrJUKF1MGVOymzYFc/OCK6eYEUpB0FIf3E3GAxD0eCLNJixDWyf3H/8nNvmrx9qcfNCLOmP/xKCEQT7X+O28sysA6+npsW3bNoYOHYqlpSU6Ojp4eHjQvn17xGs++OfNm8fMmTPfvmBFImx5/QdmgegdD7q5n9svhCAwMJB9+/bx+eefq48bGxvzyy+/qLuXNmzYgFKp5JdfflGvvOnr64uFhQVBQUG0bduWvn378vvvvzN06FBAFRDFxMTQo0ePLMu+d+8eX3zxBVWqVAGgcuXK6nMLFy6kdevWfPONalCYs7MzISEhzJ8/Hy8vL+7du4evry/37t3Dzs4OgMmTJ7N37158fX359ttvuXfvHj169KBGjRoAb1z+XKlU4ufnx9KlSwHo27cvkyZNIiwsjPLly2dKb2RkhImJCbq6upQpo7kb7Pjx49XPnZycmDNnDiNHjmT58uWvrYMkSZkVymJ5u3apvsouJjWlQsnRxRNoUWYJAEHPZuM+7iu0tHO/+vKx3/xorP0p2jqCYw8G0XDcOnT1350Q4p1tmQGoW7cuFy9eJCYmhsjISPbu3Ut0dPRrP9SmTZtGbGys+hEREVGINS48f//9NyYmJhgaGtK+fXv69OmDj4+P+nyNGjU0xslcunSJW7duYWpqiomJCSYmJlhaWpKcnMzt27cBVUtLUFAQDx8+BGDjxo107Ngx29k/EydOZNiwYXh4ePDdd9+p8wEIDQ3N9IerSZMm3Lx5E4VCwZUrV1AoFDg7O6vrY2JiwuHDh9X5jB07ljlz5tCkSRNmzJjB5cuvn/q3f/9+EhIS6PDvHzNra2vatGnDunXrcnZTX3LgwAFat26Nvb09pqamDBo0iOjoaBITE3OdlyR9yNLT0zl16hRQgC0ziYlw6JDquQxmANXaLycWfor7v4HM4YSltBjz9VsFMkfWrqCp7ieqLqqHI2g80e+dCmTgHW6ZeZn5v02GN2/e5Ny5c8yePTvbtAYGBhgY5KHZS6eEqpWksOnkrs+xZcuWrFixAn19fezs7NDV1fxWGhtrtvLEx8dTt25dNm7cmCkvGxvV1u716tWjYsWK+Pv7M2rUKLZv367RLfQqHx8f+vfvz65du9izZw8zZszA39+fbt26vbH+8fHx6OjoEBwcjM4rG8FldCUNGzYMT09Pdu3aRUBAAPPmzWPBggUaLVAvW7t2Lc+ePdMYpKxUKrl8+TIzZ85EO4ezG8LDw+nUqROjRo1i7ty5WFpacuzYMYYOHUpqaiolShR9/7AkFRdXrlwhISEBMzMzqlatWjCFHDqkWmOmXDkoqDKKkeSEZC4u70dT+x2kK3Q4peWL+/BBb5VX0KqfaGE6EYDDj8bSfOKitwqIClqRBjPx8fHcunVL/TosLIyLFy9iaWlJ2bJl+eOPP7CxsaFs2bJcuXKFcePG0bVrV9q2bVtwldLSeqvunsJmbGxMpUqVcpy+Tp06bN68mVKlSmFmZpZtugEDBrBx40YcHBzQ1tam4xs2anN2dsbZ2ZkJEybQr18/fH196datG66urup1JTIcP34cZ2dndHR0qF27NgqFgidPntCsWbNs83d0dGTkyJGMHDmSadOmsWbNmiyDmejoaHbu3Im/v7969huoxv00bdqUgIAA2rVrl+l9+vr6KBQKjWPBwcEolUoWLFigDoC2bNny2vsgSVLWMrqYGjZsmOkfl3zz8iymgtzAshiIj4nnxi9daWgfSHKaAZdMNtO0R5e3yivo57m0sPxa9fzJ/3AfP++dDGSgiLuZzp07R+3atalduzag6raoXbs206dPByAyMpJBgwZRpUoVxo4dy6BBg9i0aVNRVrnYGjBgANbW1nTp0oWjR48SFhZGUFAQY8eO5f79+xrpzp8/z9y5c+nZs2e2rVxJSUmMGTOGoKAg7t69y/Hjxzl79iyurq4ATJo0icDAQGbPns2NGzf49ddf+fnnn5k8eTKgCoIGDBjA4MGD2bZtG2FhYZw5c4Z58+ax69++7/Hjx7Nv3z7CwsI4f/48hw4dUuf/qvXr12NlZUXv3r2pXr26+uHm5kaHDh2yHQjs5OSkDqKfPn1KSkoKlSpVIi0tjaVLl3Lnzh3Wr1/PypUr3/reS9KHrMDHywghp2T/6/mjZ4StbUMdu0Dik40JLbWbBm8RyAilIGjx1/8FMtEzcR/77gYyAIj3XGxsrABEbGxspnNJSUkiJCREJCUlFUHN3t6QIUNEly5dcn0+MjJSDB48WFhbWwsDAwNRoUIFMXz48Ez3pn79+gIQBw8e1Dju6+srzM3NhRBCpKSkiL59+wpHR0ehr68v7OzsxJgxYzTu5Z9//imqVq0q9PT0RNmyZcX8+fM18ktNTRXTp08XTk5OQk9PT9ja2opu3bqJy5cvCyGEGDNmjKhYsaIwMDAQNjY2YtCgQeLp06dZXnONGjXE6NGjszy3efNmoa+vL6KiojSuQQghkpOTRY8ePYSFhYUAhK+vrxBCiIULFwpbW1thZGQkPD09xW+//SYA8fz58yzL+JAV198jqXCUK1dOAGL//v0FU0BIiBAghIGBEPHxBVNGMfAo7KG48VN1ITYioldbiquHT79VPkqFUhxaOFGIjQixEXFo+Q/5XNOce93n96u0hMjjnOB3XFxcHObm5sTGxmbqXklOTlbPdJELq0nS25G/R1J2Hjx4oO6yjomJwdTUNP8L+fFH+OIL8PSEvXvzP/9iICI0DOWBNpSzus2jWFte1Aug8kfVc52PUqHk2KIxNLddAagGDbsPH5Pf1c2x131+v6pYDACWJEmSip+TJ08CULNmzYIJZOCD72K6dT4E49NtsLV6yL1n5aHVASpXff0yFllRpCk4sXg4ze18USq1OJ62GvfhxWelfRnMSJIkSQWiwDeXjItTbS4JH2QwE3L0LKVD22NlHs3NqGqYfhxAmfJ2uc4nLSWNs0sG08zen3SFDqe1f6XZJ1kvlvquksGMJEmSVCAKfOXfAwcgPR2cnSEXszvfBxf3BVHxQWdMTeK5+qg+dv12Y2lrlet8UhJTuLCsH43tt5OWrss5Q3+a9M56odR3mQxmJEmSpHyXlJTE+fPngQKcyfSBdjGd2f5/1IzrhaFhChcetqTS0J2Ylsx9N15SfBJXV/Skof1uUtL0uWS2lUbdOhVAjQueDGYkSZKkfHf27FnS09OxtbWlXLly+V/ABzol+/jGjTRQDkFXT8HpB11wG+2PoXHuB94nxCZwfc3H1LM/SGKKEaGldlK/Y5sCqHHheKe3M5AkSZKKp5e7mLQKYiG7ixchMhJKlIDmzfM//3fQ4V+W00gMQldHwbEHg6g77s+3CmTiouO4/YsndewO8iLZhJsOe6lbjAMZkMGMJEmSVAAKfLG8jFYZDw/IyxY2xYBQCoKWfYt7CW+0tQWHI8e89f5Izx89I+JXD2raHic20Zy7Ffbj1qb4B4Oym0mSJEnKV0KIgh/8+4F0MQml4PDi/9Gi9HwAgp5+g/uEmW+1Gu/TB1FEb2lDtTKXiI634kn1AKo3rpPfVS4SMpiRJEmS8tWNGzeIjo7G0NBQvV1NvoqOhn934n6fgxlFmoLji0fRwm4NAEFxC2gxduJb5RV55wGJ/9cGl9KhPIkrTexHB3B9i4X13lWym0nKMT8/PywsLHKc/uTJk1hZWTF48GDCw8Nxd3cvuMrlUG6vQZKk3MtolalXrx76+vr5X0BAACiVUKMGODrmf/7vgNTkVE4v6k9zuzUolNocTVtLi5FvF8iEXb6BYk8TKtqEEhljT0LjI2+1QvC7TAYzxZCXlxdaWlpoaWmhr69PpUqVmDVrFunp6QVabp8+fbhx40aO0+/YsYMff/wRe3t7WrRowejRowuwdv/ZtGkTOjo6eHt7vzGtj48PtWrVKvhKSdIHRHYx5U1CbAKXlnahsf0WUtP1OKO/mWZDPn2rvP45eQGTk01xKHmXsOjKKFofp3xN53yucdGT3UzFVLt27fD19SUlJYXdu3fj7e2Nnp4e06ZNy5Q2NTU1X/47MjIywsjIKMfpv//+e/XzefPm5bn8nFq7di1Tpkxh1apVLFiwQO4XJEmFrEBX/lUo/tuD6T0MZu5eu03y/u7Us79MQkoJQq230aiz51vldWn/EZzudcbcNI7Qx7Wx7rUXG4dS+Vzjd4NsmXmVEJCeUPiPXO73aWBgQJkyZShXrhyjRo3Cw8ODv/76C1C13HTt2pW5c+diZ2eHi4sLABEREfTu3RsLCwssLS3p0qUL4eHhAAQEBGBoaEhMTIxGOePGjaNVq1ZA5i6aS5cu0bJlS0xNTTEzM6Nu3bqcO3dOfX7r1q1Uq1YNAwMDnJycWLBggUbeKSkpTJ48GXt7e4yNjWnQoAFBQUHq83fv3qVz586ULFkSY2NjqlWrxu6M/8iyERYWxokTJ5g6dSrOzs5s27Yt27R+fn7MnDmTS5cuqVu6/Pz8AFi4cCE1atTA2NgYR0dHRo8eTXx8/GvLliQJnj17RmhoKFBAwczZs/D0KZibQ6NG+Z9/ETqz/W8sTtbFpdRlol6U4k65/Xz0loHMme1/4/zAE3OjOC4+bI7doEPvbSADsmUmM0UibDEp/HJ7x4Ou8Vu/3cjIiOjoaPXrwMBAzMzM2L9/PwBpaWl4enrSqFEjjh49iq6uLnPmzKFdu3ZcvnyZ1q1bY2FhwdatWxk6dCgACoWCzZs3M3fu3CzLHDBgALVr12bFihXo6Ohw8eJF9PT0AAgODqZ37974+PjQp08fTpw4wejRo7GyssLLywuAMWPGEBISgr+/P3Z2dmzfvp127dpx5coVKleujLe3N6mpqRw5cgRjY2NCQkIwMXn998bX15eOHTtibm7OwIEDWbt2Lf37988ybZ8+fbh69Sp79+7lwIEDAJibmwOgra3NkiVLKF++PHfu3GH06NFMmTKF5cuX5/A7IkkfplP/Dsx1dnbG2to6/wvI+IembVv49+9NcadIU3B0xSxaWM+CEnAlshHW3f6gRgX7t8rv+IYNNBBe6OorOP2gMzVHbcbIJOet6sWRDGaKOSEEgYGB7Nu3j88//1x93NjYmF9++UXdvbRhwwaUSiW//PKLegErX19fLCwsCAoKom3btvTt25fff/9dHcwEBgYSExNDjx5Z79Nx7949vvjiC6pUqQJA5cqV1ecWLlxI69at+eabbwDVH7aQkBDmz5+Pl5cX9+7dw9fXl3v37mFnp9oYbfLkyezduxdfX1++/fZb7t27R48ePahRowYAFSq8fidYpVKJn58fS5cuBaBv375MmjSJsLAwypcvnym9kZERJiYm6OrqUqZMGY1z48ePVz93cnJizpw5jBw5UgYzkvQGBb655Hs2Xub5o2fcWj+AFvaqrrPDkd408l6IvuHbDQ04vHoJ7ibjADj2YBANxq5Fz+D9CPpeRwYzr9IpoWolKYpyc+Hvv//GxMSEtLQ0lEol/fv3x8fHR32+Ro0aGuNkLl26xK1btzA11dy/Izk5mdu3bwOqlpaGDRvy8OFD7Ozs2LhxIx07dsx29s/EiRMZNmwY69evx8PDg169elGxYkUAQkND6dKli0b6Jk2asGjRIhQKBVeuXEGhUODsrDkQLSUlBSsr1WZpY8eOZdSoUQQEBODh4UGPHj2oWbNmtvdk//79JCQk0OHfP3LW1ta0adOGdevWMXv27NfczcwOHDjAvHnz+Oeff4iLiyM9PZ3k5GQSExMpUSJ33ytJ+pAU6GJ5jx5BcLDqefv2+Z9/Ifvn5AVKBPegnn0YSamGBOuswn3S4LfKSygFh3/2UbXuAIcfjaPZxIVo63wYo0lkMPMqLa08dfcUlpYtW7JixQr09fWxs7NDV1fzW2lsrHkN8fHx1K1bl40bN2bKy8bGBlBNo6xYsSL+/v6MGjWK7du3q8eQZMXHx4f+/fuza9cu9uzZw4wZM/D396dbt25vrH98fDw6OjoEBwejo6OjcS6jK2nYsGF4enqya9cuAgICmDdvHgsWLNBogXrZ2rVrefbsmcYgZaVSyeXLl5k5cyba2jn7pQ4PD6dTp06MGjWKuXPnYmlpybFjxxg6dCipqakymJGkbKSlpXHmzBmggFpmMgb+fvQRlC6d//kXomPrf6Ou4jOMLJO596w8SR9to2nDWm+Vl1Kh5OiicbSw/RmAoGezcB//9VstrFdcyWCmmDI2NqZSLra8r1OnDps3b6ZUqVKYmZllm27AgAFs3LgRBwcHtLW16dix42vzdXZ2xtnZmQkTJtCvXz98fX3p1q0brq6u6ubmDMePH8fZ2RkdHR1q166NQqHgyZMnNGvWLNv8HR0dGTlyJCNHjmTatGmsWbMmy2AmOjqanTt34u/vT7Vq1dTHFQoFTZs2JSAggHbt2mV6n76+PgqFQuNYcHAwSqWSBQsWqAOgLVu2vPY+SJKkagFOTEzEwsJC3f2cr96DLqbU5FROLpuAu+1y0IGzDzpQecgGypYq+Vb5paWkcWaJF+72v6NUanE0eSktxrx5WYr3zYfR/iQxYMAArK2t6dKlC0ePHiUsLIygoCDGjh3L/fv3NdKdP3+euXPn0rNnTwyy2fMkKSmJMWPGEBQUxN27dzl+/Dhnz57F1dUVgEmTJhEYGMjs2bO5ceMGv/76Kz///DOTJ08GVEHQgAEDGDx4MNu2bSMsLIwzZ84wb948du3aBajGrezbt4+wsDDOnz/PoUOH1Pm/av369VhZWdG7d2+qV6+ufri5udGhQwfWrl2b5fucnJwICwvj4sWLPH36lJSUFCpVqkRaWhpLly7lzp07rF+/npUrV771vZekD0VGF1OjRo1y3BKaY2lpsG+f6nkxDWYi7zzg+jJ3VSADBEXPoO7E/8PiLQOZxLhELi7pShP730lL1+WU9kbch314gQzIYOaDUaJECY4cOULZsmXp3r07rq6uDB06lOTkZI2WmkqVKlG/fn0uX77MgAEDss1PR0eH6OhoBg8ejLOzM71796Z9+/bMnDkTULUEbdmyBX9/f6pXr8706dOZNWuWeiYTqAYgDx48mEmTJuHi4kLXrl05e/YsZcuWBVStKt7e3ri6utKuXTucnZ2zHYC7bt06unXrluXuvD169OCvv/7i6dOnWZ5r164dLVu2xMbGhk2bNuHm5sbChQv5/vvvqV69Ohs3bizUdXIkqbgq0PEyJ05AXBxYW6u6mYqZi/uC0N1fhxq2p4hJtOBsib9p8bnPW49piY2K4eYaT+rZ7yYxxYiL5jtp3L9fPte6+NASIpcLnBQzcXFxmJubExsbm6l7JTk5WT3TRS6sJklvR/4eSRkcHR25f/8+Bw8epGXLlvmb+f/+Bz/8AAMHwvr1+Zt3ARJKweHVC2lq/D90dRRcf1ITwzbbKFet4lvn+eTuI55va4dL6Uuqna+d/qamR9N8rPW74XWf36+SY2YkSZKkPIuIiOD+/fvo6OhQv379/C8gY7zMG8bxvUviY+K5vGYoLexVY+6OPRhInc9WUcLs7ScRRISGoTzQBpfSt3kSV5rntfdRs4FbflW52JLBjCRJkpRnGV1MtWrVyjSbMs/u3YOrV0FbW7VYXjFw59J1RFA3GtuHkpauy4mUn2g+yTtPM4xunruK6dm2lLGKJOKZE8oW+3GpnvOJIO8zGcxIkiRJeVagi+Xt2aP62qgRWFrmf/757NSf26kaOwQzmxc8irUlyuVP3Fvl7b5cDTqF/c0OlDR/zs2oaph+HECZ8nb5VOPiTw4AliRJkvKsQHfK/neG47s+i0mRpiBo0TQapnbHzOgFlx42Q7vDeWrkMZAJ3rWf8mGtKWn8nCuRDbHuc0QGMq+QLTOotgSQJOntyN8fKSEhgYsXLwIFMJMpORkCA1XP3+Fg5umDKO7+3p8W9qp93oIeTaDJ59/neSuBk5v/oG7KAPQN0jj3oC2uI7ZhbP7uL+xa2D7oYCZjU8TExESNVWMlScq5xMRE4L/fJ+nDc/bsWRQKBQ4ODjg6OuZv5keOQGIi2NmB27s50DXk6FnMr/Sgrn0ECSkluGS4lhYT++Y53yO+a2iq9xnauoKTD3pRx3s9BiWyXvvrQ/dBBzM6OjpYWFjw5MkTQLUWS1brlEiSlJkQgsTERJ48eYKFhUWmbSmkD0eBjpd5edXfd+zvs1Kh5JjfKhrojsfAIpWw6MqkN9pG44+q5ylfoRQcXvk9LSymAXDk4QiajF+Ojp78HcvOBx3MAOrdkjMCGkmScsfCwiLTruPSh6VAF8t7R7cwuBV8jYSgkTS3PQbA6QddqPLJr5hbm+cp3+SEZM6sGEcLu9UABEVNw33i3A9qn6W38cEHM1paWtja2lKqVCnS0tKKujqSVKzo6el9sC0yQgh+/fVXzpw5w4ABA2jcuPEH2bKrVCo5efIkUAAtMzdvqh56etC6df7m/ZYS4xI5s242TSx/RM82nYSUEpxNnUPziePyvEP1/et3idvVk+Z251AqtTgSP58W4yblU83fbx98MJNBR0fng/2jLElS7ty4cYMRI0Zw+PBhAFasWEHNmjUZPXo0AwYMUO/8/iH4559/eP78OSVKlMAtv8e0ZLTKNGsGb1gBtjCc3bmbMhHetCgVDsDpBx/j0GUpLZzL5jnvc/+3jwqP+uNQ5hnPEiy5U3ojLQZm3hxXypqcmi1JkpRDqampzJ07l5o1a3L48GFKlChB9+7dMTQ05PLly4wcORI7OzvGjBnDtWvXirq6hSKji6l+/fr5Pwj8HeliirzzgJPze1EvoSOOluE8iHHktMEOGnyxE/s8BjJKhZKgpbOoE9seS+NnhDz6iMTm5/noYxnI5IYMZiRJknLg9OnTfPTRR3z99dekpKTg6enJ1atX2bp1Kw8fPuSnn37C2dmZFy9esGzZMqpXr467uzubN28mNTW1qKtfYApsfZmEBAgKUj0vomBGkabg8OrFmARVoZH9n6QrdAh6PAnz/iE06NElz/k/f/SM4IWdaWE1A21twZGHI6jw2VEcXMrlQ+0/LDKYkSRJeo0XL14wbtw4GjVqxJUrV7C2tmbDhg3s2bOH8uXLA1CyZEnGjx/PP//8w4EDB+jevTs6OjocOXKEvn37UrZsWb7++mvu3btXxFeT/wpsJtPBg5CaCk5OUKVK/uadAyHHznHj5/q4m4zH1DCeq48acNs5mBYTfsTEIu/diKEnzhP/Z13q2e8mKdWQY+m+NJ+8CkNjuVnr2/igd82WJEl6nV27djFq1CgiIiIAGDRoEAsXLsTa2vqN733w4AFr1qxh9erVREZGAqCtrU2nTp0YPXo0bdq0QVu74P6fVCgU3Lhxg4sXL6ofkZGRGBkZYWRkRIkSJdRfX36e1bHszicnJ1O5cmUAoqOjsczPrQZGjYKVK8HbG37+Of/yfYPYp7Fc/PVrmpVehra2IDbRnEta39HUa0SeB/hmOOq3lnpa3hjqpXD3WQWSP9qKS8Na+ZL3+yQ3n98ymJEkSXrFkydPGDduHP7+/gCUL1+elStX0vYtNjlMS0tj586dLF++nEOHDqmPV6xYkZEjR/LJJ59gZWWVp/rGx8dz5coVjcDlypUrJCUl5SnfnHJ1dSUkJCT/MhRC1SJz755qK4NC6GYSSsGpP/6k/LNxlDFXBZ/HH/THuc9CbMqWzpcykhOSObtiDM3s1gJw5kEnnIf8hkWpkvmS//tGBjMvkcGMJEk5JYTAz8+PSZMm8fz5c7S1tZk4cSI+Pj75shN0aGgoK1euxM/Pj7i4OAAMDAzo06cPo0ePpn79+q+d3i2E4NGjRxpBy8WLF7l582aW20pkzDCqVasWtWrVoly5cqSkpJCUlERiYqL668vPc3MsYzmLefPmMXXq1DzfH7WrV6FGDTA0hOhoKFEi//LOwr2QOzzeNYZ69qoNLcOjK/Gs4grqdPDItzIiQsOI39sT19LnVdOuY2bTfNS0fGvteR/JYOYlMpiRJCknbt++zWeffUbgv/sA1a5dmzVr1lC3bt18LyshIYFNmzaxbNky9Z5GGWWOHj2afv36YWhomKmb6OLFi9ku8Glra6sOWjIeFStWLNAlJ9LS0khPT8//7WB++AH+9z9o3/6/GU0FIDU5lRNrf6SB8WyM9JNJSdPnZOxUGg6dlq9jV87+tYdKjwdQ0vg50fFWhNtvom7HNvmW//tKBjMvkcGMJEmvk5aWxsKFC/Hx8SE5ORlDQ0NmzZrFhAkT0NUt2KW4hBCcPn2a5cuXs2XLFlJSUgAwMTFBoVBk2U2kra2Ni4uLRtDi5uZG6dL50xVSoNLT4dkzVWvL06eqrxmPl1+fOgWPH8PSpTBmTIFU5dKBoxhfG0klG1X32PmHrbBos5wKbi75VoZSoeTI8lk0LzkLbW3BtUf1sOj0Z56nc38oZDDzEhnMSJKUneDgYIYNG6ZuHWndujWrVq2iYsWKhV6Xp0+f4uvry8qVK7lz5w4AxsbG1KxZUyNwqV69OiUKuNslV27cgIiI7AOTl1/HxuY8X319Vd7l8neacvTDp4T8PoVmdr4ARL2w4YbxQhr3H5CvWwY8i4zm9oaB1LPfC8CRyFE0GPWT3CgyF2Qw8xIZzEiS9KqEhASmT5/OokWLUCqVWFpasnDhQgYPHlzkWxIolUqCg4MxNzcv8G6iPDl7Fr76Cvbvz/17S5YEKyuwtlZ9ffVhba0aM+OSf60kQik4vuFXXJMnY2USDcCRh8OpMfA7SpbJx1lYqKZ1m13qiUPJuySmGHFebxVNBw7K1zI+BLn5/JbbGUiS9EEJCAjgs88+Izw8HIB+/fqxaNEiSpUqVbQV+5e2tjb16tUr6mpkLyQEvvkGtm1TvdbVVQUdrwYjWQUoVlaqQKaQA7Q7F/8h7sBImtodBhO48aQGKTVX0rx//q6NI5SCo7/+QgPtMRiUTOVudEVSGmyjaf2a+VqOlJkMZiRJ+iA8ffqUCRMmsGHDBgDKli3LypUrad++fRHXrJgIDwcfH1i/HpRK0NKCQYNUx/5dPPBdk5yQzKl139HIbB4V7FJVm0Im+9Bk1Hj0DPJ364Wk+CTOrfSm+b/dV6cffEwVr18xt7HI13KkrMlgRpKk9154eDgNGjTgyZMnaGtrM3bsWGbPnp33DSHT0iAyEuzsVC0U76NHj2DuXFi1SnW9AN26wezZUK1a0dbtNS7sPYTFjZG0sL4BwNkHHbDtvIwWVZzyvax7IXdI3NeDZnYXUSi1ORo7h+YT/yenXRei9/S3T5Ik6T8zZszgyZMnVKlShV9//ZX69evnPVMhoGNH1ZgRPT2oWFHV3eLsrPnVxkbVilHcPH8O8+fD4sWQmKg65uEB334L73A3WPTDp4RunExT+1/BGh7HleFOySU0nNQzXwf4Zji97S9cng2hbOkYol7YEOG4iRYDW+d7OdLryQHAkiS91/755x+qVauGUqnkzJkz+TcexdcXPv30zenMzf8Lbl4OdCpXhnxYiC/fJSTAkiWqtV5iYlTHGjRQBTGtWhVp1V5HNcD3N1yTJ2FlEo1SqcXRx6OoNeRbzK3N8728yDsPCN86nkb2fwJwJbIh1l3/wLaiQ76X9aGSA4AlSZL+5ePjg1KppEuXLvkXyDx9Cl98oXr+3XfQty9cv66aSnzjxn/P795VTUc+c0b1eJWDQ9aBjpNToQ+SJTUVVq+GOXNUa7wAVK+u6mLq3Pmdbl0Ku3yDmICRNLU7pB7gm1prNe4DG+Z7Wemp6Rz3/Zk6et/QyD6edIUOx56Op7H3t+gb6ud7eVLOyJYZSZLeW1euXKFmTdVMkkuXLqmf59mnn6paZmrUgOBgVTdTVpKS4PbtrAOd6Ojs89fXB1dXqFXrv4ebm2omUH5TKGDDBtVA3n9neFGhAsyapQrS3tWp4UBKYgon135PI7O5GOilkphixJkkH5oMnZDvA3wBrh4+je75kVQpfRFQtcboN12JSwO3fC9LkuvMaJDBjCR9uLp378727dvp1asXW7ZsyZ9MjxwBd3dVS8Xx49Co0dvlEx2dOcC5fh1u3oR/VwLOxMlJM8CpVQvKln27VhMhYPt2+PprCA1VHbO1henTVcGa/rvdynBp/xFMQj+jovU/AJx90I4ynZbj6Jr/M6tinjzn8m/TaFpmNdragucJJbmi8x1NhwyTg3wLkAxmXiKDGUn6MAUHB/PRRx+hpaXF1atXqVq1at4zTU1VBRChofDZZ7ByZd7zfJVSqeqeunwZLl7875HRavIqC4vMAY6ra/bBiBBw4AB8+SWcO6c6ZmkJU6eCt3eBb+qYV88io7m2cQrN7NYB8CSuNLfMF9OoT+98H+ArlILjv2/AJWESNqZRABx7MASXfj9g4/BurEv0PpPBzEtkMCNJH6aOHTuye/duBgwYoF5bJs++/Va16m2pUvDPPwXT7ZOdmBi4dEkzwLl27b/p0i/T01NNm361m+qff2DaNAgKUqUzNoaJE2HSJNVA5XdYRmBRJXEi1iZPATgSORK3wfMKZC2XOxf/IfbAKGrbBQFwO8qVF64rqNXWPd/LkrImg5mXyGBGkj48J0+epHHjxujo6BAaGkrlypXznunt26oBscnJqjEmAwbkPc+8Sk1VtRK9HOBcvPjfLKTs6OvD6NGqwOYdWfn4dcKv3OTZvlHUsVPtaH7zSXWSa66iRqv8XcEXIDEukTO+c2lccj76umkkpRpyOmE6jYdOkgN8C5mczSRJ0gdt+vTpAAwZMiR/AhkhVLs3JydD69bQv3/e88wP+vqqFhc3NxgyRHVMCLh3L3OAEx4O2trwySeqcTFl3/2dm1OTUznxy3wams7GyS5FFVgkzqDJqEkFMsD37M7dlI4YQwubMADOPOiIbaeltCiAcThS/pItM5IkvVeOHDmCu7s7enp63LhxAycnp7xnumUL9OmjCh6uXFFNny5unj9XBTqW+bupYkG5fOAYxtdGUNFGNTj53IO2lOq4grJVK+R7WZG37xO+bTyN7LcC8DDGgXulltCge9cCWWhPyhnZMiNJ0gdJCMHXX38NwNChQ/MnkImNhXHjVM+//LJ4BjJQuON78iAtJY0TP0/A3XYZ2EDUi1LcNFtMo0l98j2wSE9N55jvUurqTddYM+ajT3xoaJHHrS6kQiWDGUmS3hsHDhzg6NGjGBgY8NVXX+VPpl9/rdqfyNlZNeNHKjAxT55z57eeuNsdBODIwxHUHPwdjUvlfyB25dBJ9C+OokXpS6rXkY0waLaSFoPkDtfFkQxmJEl6Lwgh+OabbwAYOXIkDg75sKz82bOwbJnq+YoVYGCQ9zylLN29dhtFYEfq2F3nRbIJoSU30Xxyp3wv5/mjZ1zZMI3mdquhNDxPKMlV3R9oMv5TuWZMMSaDGUmS3gu7d+/m9OnTGBkZMTU/WlDS01VryQgBAwe+0/sSFXeXDxzD/k5XrKyjeRjjwIu6f1M/n1fVFUrB8Y3rcUmcTHM71ZoxRx944dr/B5rZ2+RrWVLhk8GMJEnF3sutMmPGjKFMmTJ5z3TZMrhwQTXWZMGCvOcnZen4hg18pBiKgUkqIY8+wqr7X7g42eZrGRlrxjS1CwJTuBVVlYSqK2jWv3m+liMVHRnMSJJU7G3fvp0LFy5gYmLClClT8p7h/fuqsTIA339fLNZiKW6EUnD4Zx9aWM8CbTj1oDs1P1tPCbP8W4E4OSGZU2u/pbHFd1SwS/t376bpNP5solwz5j2Tq2BGCEFERASlSpXC0NCwoOokSZKUY0qlkhkzZgAwbtw4rK2t857puHEQHw+NG8PQoXnPT9KQnJBM8PJPaWG/CYCgJ/+j+cRv83XMyvndB7C8PYoW1rcAOPugA2U6/SzXjHlP5TqYqVSpEteuXcufhagkSZLyaMuWLVy9ehVzc3MmTZqU9wz//hu2bQNdXdXeS9pyUGh+irr/hEebu9LE/iRp6bqcEqtoMf7T/Mv/3mNubJ5EE/uNYAWPYm0Js1pCw0k95Jox77FcBTPa2tpUrlyZ6OhoGcxIklTk0tPT8fHxAWDSpEmUzOtaKgkJqpV+QbVnUY0aectP0nDrfAgGJzpSwzacmEQLwhy20axdy3zJW6lQcuzXX6ip/B9N7GNQKrU4+tibWkPm0Mj63d53Ssq7XP/L8d133/HFF19w9erVgqiPJElSjv3+++9cv34dS0tLxmUsbJcXs2apdqwuV0615L+Ub4J37cfmQiMcLcO5G12RZ/VOUTufApkbZ69wdVEzmht+hkWJGEIf1+afcqdxn7QUcxnIfBByPQB48ODBJCYm4ubmhr6+PkZGRhrnnz17lm+VkyRJyk5aWhozZ84EYMqUKXnfruTKFVi4UPX8559VO0pL+eLIulU01vNG10jBpYfNcOi/DSu7vI9tSohN4KzvLJpYLkTPNp0XySacT5tNE+8x6OrL+S0fklx/txctWlQA1ZAkScodPz8/7ty5Q6lSpRiT0TX0tpRKGDlStbZM9+7QKf8Xa/sQKdIUHP15Ci1Kq4LEYw8GUc97DQYl8r744Nkdu7B94E2LUncBOPWgG+W6L8G9Yj4sligVO7kOZoZk7MwqSZJURFJSUpg9ezYA06ZNwzivrShr18KJE2BiAosX50MNpfiYeK6tGUAL+78ACHo2G/dJX+V5EO6jsIeE/TmORvZ/Qkm4/7wsD+1+puEXnfOj2lIx9VbtcAqFgh07dhAaqtrNtFq1anz88cfo6Ojka+UkSZKy8ssvvxAREYGdnR0jR47MW2ZPnsD//qd6Pns25Mc2CB+4yNv3if2rMw3sL5KcZsB5/V9pMaZPnvJUpCk45rec2tpf0cj+hcamkA5yU8gPXq6DmVu3btGhQwcePHiAi4sLAPPmzcPR0ZFdu3ZRsWLFfK+kJElShqSkJObOnQvAV199lfc1ryZPhufPoXbt/2YySW8t9HgwFpc/pkrph0S9KMVjl500btEwb3meOI849RnuZc4BcPVRA/SarKLFoPzd8kAqvnI9m2ns2LFUrFiRiIgIzp8/z/nz57l37x7ly5dn7NixucrryJEjdO7cGTs7O7S0tNixY4fG+fj4eMaMGYODgwNGRkZUrVqVlStX5rbKkiS9R1asWEFkZCRly5ZlaF4XtDt4ENavBy0t1ZoyunLQaF6c/nMHZW80x9b8ITejqpHifprqeQhkXjx/weGF43G+U4+qZc4Rm2jOkaTluH5+HJd83rtJKt5y/Zt7+PBhTp06haWlpfqYlZUV3333HU2aNMlVXgkJCbi5ufHpp5/SvXv3TOcnTpzIwYMH2bBhA05OTgQEBDB69Gjs7Oz4+OOPc1t1SZKKufj4eL777jsAvvnmGwzysot1SgqMGqV6Pno01K+fDzX8MAml4PDqhTQ3+QJtA8G5B22p/MmWt54WLZSC01u3Uy5qLO5lHgBw4kFfKvX+iebl8mHfLem9k+tgxsDAgBcvXmQ6Hh8fj75+7va6aN++Pe3bt8/2/IkTJxgyZAgtWrQAYMSIEaxatYozZ87IYEaSPkA///wzUVFRVKxYMe+TEb7/Hm7cAFtb+LfbSsq9tJQ0Ti71poXdGgCORI6i8bglbz01Oj4mnitrPqWR/R9gAXefVSCq3HIaf+GZj7WW3je57mbq1KkTI0aM4PTp0wghEEJw6tQpRo4cme8BRuPGjfnrr7948OABQggOHTrEjRs3aNu2bbbvSUlJIS4uTuMhSVLxFxsbyw8//ADAjBkz0NPTe/vMbt6Eb79VPV+0CMzlwmpvIy46jstLOtDcbg1KpRaH4xfRbMKytw5kIm/f575vMxrZ/0Fquh5BUV9RyusqH3WWgYz0erkOZpYsWULFihVp1KgRhoaGGBoa0qRJEypVqsTifJ7SuHTpUqpWrYqDgwP6+vq0a9eOZcuW0bx59tu2z5s3D3Nzc/XD0dExX+skSVLRWLRoEc+fP6dKlSr079//7TMSQtWtlJICnp7Qq1f+VfIDEhsVw71f21LX/gDxycacM96J+4hxbz31OuToWbQC6lOl9EWiXpTiuuNhWoybg5GJ0ZvfLH3wch0+W1hYsHPnTm7evMk///wDgKurK5UqVcr3yi1dupRTp07x119/Ua5cOY4cOYK3tzd2dnZ4eHhk+Z5p06YxceJE9eu4uDgZ0EhSMffs2TMW/rs6r4+PT96Wgdi0CQ4cAENDWL5cNfhXypWYJ895uKEt1cuc41mCJY+r7ad+4zpvnd/JzX9QK2kwRubJ3HxSHaN2/0eNKk75V2HpvffWQ/crV65coJtNJiUl8eWXX7J9+3Y6duwIQM2aNbl48SI//vhjtsGMgYFB3gYFSpL0zlmwYAFxcXHUqFGDXnlpSXn+HCZMUD3/5huoUCF/KvgBef7oGY82taFqmfM8jbcm2u0Arm85s0goBYeXz6WF5TegD2cfdMDl002YWeVxawrpg5OjYObllo43yfjvKa/S0tJIS0tDW1uzJ0xHRwelUpkvZUiS9O6LiopSd2HPmjUr09+EXJk2TbVInquran0ZKVeiHz4lanMbXEtfJOqFDTF1D+LyUfW3yis5IZng5cNoYb8RgMOPxtN0/I/o6MnFV6Xcy1Ewc+HChRxlppXL5tr4+Hhu3bqlfh0WFsbFixextLSkbNmyuLu788UXX2BkZES5cuU4fPgwv/32W74FTJIkvft++OEHEhISqFu3Ll26dHn7jE6ehFWrVM9XroRczr780D19EMWzP1pTpfQVnsSVJq7+QSrXqfpWeUXdf0Lk5m40sT9BukKHE2nLcJ/4WT7XWPqQaAkhRFEVHhQURMuWmbeAHzJkCH5+fjx69Ihp06YREBDAs2fPKFeuHCNGjGDChAk5Dpzi4uIwNzcnNjY277vqSpJUqCIjI6lQoQLJycns2rWLDh06vF1G6elQty5cvgyffALr1uVvRd9zUfceE7O9NZVtrvEo1pbERgepUKvKW+V189xVDE91xtEynJhEC+7Y/UGdDlkPG5A+bLn5/C7SYKYwyGBGkoqvsWPHsnTpUho2bMiJEydy3fqr5usLn34KVlbwzz9gbZ2/FX2PPbn7iBc7WlHRJpTIWDuSmxyifE3nt8rr7F97cInqg5nRC8KjK6Fs/jcV3FzyucbS+yI3n99vNQD43LlzbNmyhXv37pGamqpxbtu2bW+TpSRJkoaIiAhW/dstNGfOnLcPZJRK1QJ5AFOnykAmFx6FPSTx/1pR0eY6D2McSGt+iPLVcz9zVSgFR35ZStMSE9AxUnLxoTtlB2zF0taqAGotfYhyPZLO39+fxo0bExoayvbt20lLS+PatWscPHgQc7nwlCRJ+WTu3Lmkpqbi7u5Oq1at3j6j/2/vvuOqLt8/jr8A2SiCyBbcW3EhmgP8qqmlZZojKzVX7tSfo2GZ30pN+2Zpbk3N0hw5M0da4MgtYC4UxMEGEZA9zuf3xydJs0zgDA5cz8eDR4dzDve5EI+8+9z3fd27dkFYGFSuDKNGaa2+si72RjRZPwZQ0ymMqHte5AcE4V2MIJOXk8fRhWPxt3sLM1MNR2OG0XD8QQkyQquKHGbmzJnDwoUL2bNnDxYWFnz55ZdcvXqV/v374+XlpYsahRDlTGRkJGvWrAHgo48+Kv5VGUWBP85yYtw4kKnmpxITfofcvf7UqHKdqHve0DkIr4ZF38aempiidgh2W45GY0Jg6gLaT1mNhZUsvhbaVeQwExERUdj3xcLCgoyMDExMTJg8eTIrV67UeoFCiPLnv//9L/n5+XTt2pUOHToUf6CgIDh9Wm2QN3Gi9gosw6LCbpG/3x/vKhHcTq4BXYLwLEYDu1sXw0na1LawQ/AZm50EjJla7A7BQjxJkcOMg4ND4UGTHh4eXLx4EYCUlBQyMzO1W50Qoty5du0a33zzDaBelSmRB1dlhg0DZ+cSVlb23bkSCYf88XKM5NbdWlToHoRnPe8ijxNyMIiKJ/yo5XSVmBRPohsew6+PHA4sdOepw8yD0NKxY0d+/vlnAPr168dbb73FyJEjeeWVV+jcubNuqhRClBvvvfceGo2Gnj174ufnV/yBQkLgwAEwM5MGeU/h1qUITH4JwNPhFpF362DxfBDutYt+FMzR9WtpGNcVR9tkLsX5Yvbcaeq1aab9goV4yFPvZmratCm+vr707t27sJ34e++9h7m5Ob/99ht9+/Zl5syZOitUCFH2bd++nW3btmFmZlbyqzIPdjD17w81apS8uDLs1sVwzI90wt0hihtJ9bDp9QuuNdyLNIamQMORxe8Q4KyebP5bdH+aj1knB0UKvXjqPjNHjx5l7dq1bNu2DY1GQ9++fRkxYkTJ5rP1QPrMCGEckpKSaNSoEQkJCbzzzjvMmTOn+INFREDduuq27JAQ8Cne2UHlQeSFa1gd74SbfQwRiQ2o2PsXnL1dizRGeko6l1a9hp/HLgACkz6g47hZmJqV4OgJUe4V5ff3U/9N69ChA19//TWxsbEsXryYmzdv4u/vT926dfn000+Ji4srceFCiPJrwoQJJCQk0KhRI2bNmlWywT77TA0yPXpIkHmCGyFXsfnNHzf7GK4nNqJS38AiB5nYiCii1nbAz2MX2XmWHFe+JWDibAkyQq9K1AE4PDyctWvXsmHDBuLi4ujevTu7d+/WZn0lJldmhCj9tm/fTt++fTEzM+PkyZO0atWq+IPFx4O3N+TkqLuZOnbUXqFlSPj5y1Q6/R+cK8VzLaEJjv0O4+RRtUhjXDt9gUrnuuNqH0vifWfi6u6kSae2OqpYlDc6uTLzd2rXrs27777LzJkzqVixInv37i3JcEKIcigpKYkxY8YAMH369JIFGYAvv1SDTJs2UMqnwQ3l+tmL2J8JwLlSPFfjm1Gl/y9FDjJXfjuPU2gnXO1juZ7QmBz/UxJkhMEU6zgDgCNHjvD111/zww8/YGpqSv/+/Rk+fLg2axNClAMPppcaNmxY8umltDRYulS9/fbbUNxme2VY2KlQqoR2waliElfiW+D6ys84uDoWaYyLQaeodr0b9rap/B7bBq/B+7CvWlk3BQvxFIoUZmJiYli3bh3r1q0jPDycZ555hkWLFtG/f39sbW11VaMQoozavn0733//PWZmZqxbtw5LS8uSDbhiBaSmQoMG0KuXdoosQ66eCMb5Yhcc7ZK5HNcK99cOUtnZoUhjXDh8nOo3e1DJ5j6hse2pOewnKjpU1FHFQjydpw4zPXr04NChQzg5OTF48GCGDRtGvXpy2qkQonj+Or3k6+tbsgGzs+Hzz/ljQDCVBagPu3L8HK6Xu+Jge4+LcX5Ue31/ka+mhBwIpHZ0T+ysMwiO6UTdkXuwtZf/kRWG99RhxtzcnG3bttGzZ0/MzMx0WZMQohzQ6vQSwIYNEBcHnp4waFDJxytDHp0WaovXkH3YOxXtYODzPx2ifvwL2FhlcS66Kw3e3IlNJRsdVSxE0Tx1mCltu5SEEMZL69NLBQUwX23Wxv/9H1jIQYYPXDh0jOq3nivRtNCZ3ftocu8lrCxzOBP9HE3G/oCVrZWOKhai6OQ6rBBCr7Q+vQSwYweEh4ODA4wYUfLxyojg/b9S6043KlnfJzimE7VH7C9ykDm1fTdN7/XGyjyHU9Ev0nTcdgkyotSRMCOE0KuJEydqd3pJUf48UHLCBLCzK/mYZcDZPQeoH/cctpaZnI3uRv3Re4u8vuXElh9okd4XS/NcTkT3o8XErVjalPAqmhA6IGFGCKE3O3bsYNOmTdqbXgI4fBjOnQNrazXMCE7v+JEmyS9gbZHN6eieNB67s8hnJP22cRO+OQMwr5DP8ehB+L61EXNLcx1VLETJSJgRQujF3bt3GT16NKDF6SX480DJESPAyUk7Yxqxk9t20Ox+HyzNczkZ3YdmE4q+vuXYhm/w07xGBbMCjkYPpc2kb6hgUey2ZELonIQZIYReaH33EsDZs3DoEJiZqQt/y7nfNm2mVVY/LCrk8Vv0QFpO/B4Lq6Ithj66bg3PmAzFzFTDkZiRtJuyBjNz2cEqSjcJM0IInXswvWRqaqq96SX486rMoEHqeUzl2LEN3+BXMIgKZgUcix6M36RvizwtFLR6KR0sRmBqqhAUO472k5fLgZHCKMjfUiGETulseunaNfjhB/4YWDtjGqmja1c/dDVlBM9MWVvkqylBK77A32YcAIHxU+g4ebEEGWE05G+qEEKnHp5e+vDDD7U38GefqTuZevaExo21N66RCVq9hA6WIx+6mrKiyCEkcOl8/CtOVm8nvI3/W59hYirnWgnjIWFGCKEzOpteiomB9evV22+/rZ0xjVDgioX424xXbxfzakrgVx8RUHmGevvuLPwnzpEgI4yOhBkhhE7cvXtX+83xHvjiC8jNhfbtoV077Y1rRAKXziOg4hT1duI7Rb6aomgUAhe9T4DjB+oYyR8TMOFDCTLCKMleOyGETkycOJH4+HjtTy+lpMDy5ertGTO0N66RUDQKQUv+S0CVDwEIvDsb/wnvFznIBC16mwBn9QiIwNQFBIyfqotyhdALCTNCCK3buXMnGzduxNTUlLVr12pveglg2TK4f19dJ/Pcc9ob1wgoGoWgxe8RUHUuAIEpcwmYULRpNkWjcOSLKQS4fgFAUPqXBIyZqO1ShdArCTNCCK366+6l1q1ba2/wrCx1ignUqzKm5WemXNEoBH3xfwS4LgQg8P7nBIydXKQxNAUajn4xAX+3pQAcyVqG/6jRWq9VCH2TMCOE0CqdTS8BrFsHCQng5QUDBmh37FJMDSETCXBbAkBQ5hIC3hxb5DGOLXwTf/fVaDQmHC9YTcfhw3RRrhB6J2FGCKE1Op1eys9Xt2MDTJ0K5uXjnKDHQkjeSvyLeDJ4fm4+J78cTkePbyjQmHKS9XQY8pqOKhZC/yTMCCG0QqfTSwDbtsGNG+r5S8OHa3fsUqogr4ATXwwrDCEnWEeHN14v0hh5OXmcXfQq7T22kl9gxukK39HulfJzVUuUDxJmhBBa8fD0ktbOXnpAUWDevAcvBDY22h2/FMrLyePMosG09/i+MIS0L2IIyc7IJnRpf9p67CE335zzNpt55uWXdFSxEIYjYUYIUWJ/nV6ysiraKc3/6sABCA0FW1sYN067Y5dCudm5nF88kGc8dhQ7hGSmZXJlRW/8PH4mK9eKS447aPNCdx1VLIRhSZgRQpSIzqeX4M8DJUeNAkdH7Y9fimSmZXJxxQDaePxITp4FoZV+oM1LPYs0RtrdNCLX9qSlx1HSs2257r6HVt076ahiIQxPwowQokR0Or0EcPIkBAaqC36nTNH++KVIRPAVNEf60drjElm5Vlx22kXrns8WaYyUhHtEfdsdH/fTpGZV4naNfTT/zzM6qliI0kHCjBCi2HQ+vQR/XpV59VXw9NT++KXEsW830DxvNLZVM4lPcyWu9hZadulQpDGSohNJ2vIsjV1DSM5wJL7hQZq0a6mjioUoPSTMCCGeKDMzkzt37hR+REVFFd4+ceIEANOmTdPN9NKVK7Bzp3p7+nTtj18KZKVncXb5BDq4rwFLOB/TmWr9v8PHy6VI48RFxpCxuwv1Xa6QkOZCaqtDNGhVfk8TF+WLhBkhyrHs7OzCcPJwSHk4uCQnJz9xjGbNmmm/Od4DCxao/+3dGxo00M1rGNCN0DDyf+1HB/ff0WhMOHJvFh3emomZuVmRxokKu0XBwc7UqhpBbIoHWe0OU8enno6qFqL0kTAjRDnw+++/s2/fPm7fvv1IaElMTHyqr7ezs6NatWp4enpSrVq1Rz46duyom+mlO3fg22/V22XwQMnjGzfikz0KO+cMEtJciPL6joDXOhd5nFsXwzEL6ox3ldvcTq6BSefD1GxQQwcVC1F6SZgRoozKyclh+/btLF26lGPHjv3j86ytrf82qDz8ub29PSYmT38qs1YsXAh5eeDvD23a6Pe1dSgrPYszy9+io/sqsILgmE549NtIC2/XIo8Vfv4ydqe64OoQS2RSXayeP4xbrbK7rkiIfyJhRogy5tatW6xYsYI1a9aQkJAAgJmZGc899xyNGzd+LKg4OjrqP6j8m+RkWLlSvf120U6FLs0iL1wj93B/OrqHqtNKye/T4a0PijytBBB2MoQqF7riZJ/EtYQmOPT5mapFXGcjRFkhYUaIMkCj0XDgwAGWLl3K3r17URQFAHd3d958801GjBiBu7u7gassgiVLICMDfHygWzdDV6MVv23aTJOsEVR0SSfxflVue35HwGtdizXWpSOn8bjWjcp2KVyOa4nrKwdwdKui5YqFMB4SZoQwYklJSaxdu5bly5dz48aNwvs7d+7M2LFj6dWrF+bGdiBjZiYsWqTenjEDSttVoyLKzsjm9PLJdHRbDlYQEuOPa9+NtKxRvHAZeugoNW49TyWb+1yIfQbvIT9h72Sv5aqFMC4SZoQwMoqicPLkSZYtW8aWLVvIyckBoHLlygwdOpTRo0dTr56R7GRRFHVK6c4d9SMqCo4cgaQkqFED+vUzdIUlcutiOFk/96OjW4g6rXT3XdpP/JAKFsX7p/fc3p9pkPAiNtZZBMd0os6I3dhVttNy1UIYHwkzQhiJjIwMNm7cyNKlSwkJCSm8v2XLlowdO5aBAwdiU5oOYFQUSE1VA8qDsPLwx4P7s7L+/uunTYMKxvtP1InNW2mUPhxvl/skpTtx0+1bAl4r/pTZ6R178El7GUvLXM5E96DxmB+wtrPWYsVCGC/j/ZdCiHLiypUrLFu2jPXr15OWlgaAlZUVAwcOZOzYsfj6+hquuLg4uHDh8YDy4CM9/enGcXKCatX+/GjYUD2HyQhlZ2RzavlU/N2WgDWExnTAuc8mWtX0KPaYJzZvpVXOIMzN8zkZ/RLNx23C0sZSi1ULYdwkzAhRCuXl5bFz506WLl1KYGBg4f21a9dmzJgxDB06FEdDH7i4Zw+8/DLk5j75eQ4OjwYVT8/HP9dFnxoDuHUpgsyD/fF3Ow9AYOI7tJ/432JPKwEc2/ANbU3ewKyChuPRg/B7a32JxhOiLJJ3hBClSEFBAZ9++imLFy8mLi4OAFNTU3r16sXYsWPp0qULpqamBq4SOHRIXc+Smws1a0KdOo8GlIdDi62toavVixNbfqDh/WF4u6RxN70KN1w3EDCoR4nGPPL1CjpaqSeSH40ZzjOTVhRrG7cQZZ2EGSFKidzcXF577TW2bt0KgIuLCyNHjmTUqFFUq1bNwNU95PhxePFFyMmBl16CLVuMem1LSeVk5nBy2TT83RaDNVyIbUfV3t/jW8LmdUErvsC/4mT1duwEOkz+AlOzUhBkhSiFyu+/QEKUIpmZmfTt25f9+/djbm7O0qVLGTx4MBYWFoYu7VHnz8Nzz6nbp7t1g02bynWQuREaRvbh1/B3OwtAYMJ02o3/GHPL4m+HVzQKQcvmEuDwXuGY/pPnYWJq3FvUhdCl8vuvkBClRGpqKj179uTYsWNYW1uzY8cOupXGRnGXLsGzz0JaGnTsCNu3g2X5W4SqaBQu/HKMrODPae22C1NXheQMRyKqfkPApOdLNHZ6Sjohq8YS4LEBgMC7s/Gf+L4EGSH+hYQZIQwoMTGRbt26ERwcjL29PXv37qVdu3aGLutx4eHQpQvcvQu+vuri39K0DVwP8nLyOPPDNirHfY6P61n4Y3PS6ejn8XhxKb51vUo0ftipUMxPDaC9RxgFGlOOZnxGwITJWqhciLJPwowQBhIVFUXXrl25evUqVatW5eDBgzRr1szQZT3u9m3o3Fndht2kCezfD5UqGboqvUlJuEfItlXUZTHPVI4CV8jKteJM0mA8Ok+i9aAGJRpf0SgcXbuC1hUmYeWUQ2yKBwl1NxHQpYOWvgMhyj4JM0IYwPXr1+natSu3bt2iWrVq/Pzzz6Wza29cnHpF5vZtqFsXfv4ZDL0lXE9uXYrg5v4vaenwNQGVMwBIvO/MpbzxNH5pNB09qpb4NVKTUrm0dhQdPbYA6lWeWq+uw8fdqcRjC1GeSJgRQs8uXLjAs88+S3x8PHXq1OHQoUN4eZVsikIn7t6Frl3h+nWoXh0OHwaXsn0q81/Xw3i7qQd2XktoQrzDZHxfe4UAW+30xLl87Cy2IQN4xuMGefkVOJ45j45TJsuOJSGKQcKMEHp08uRJevToQUpKCj4+Phw4cACX0hgQ0tKge3e4eBHc3NS+Mp4l22pcmv3Tepgz0T0wazSF5gM7U1dLi3AVjcKR1YtoazUNC8c8ou55k9J4MwH+floZX4jySMKMEHpy6NAhevfuTUZGBm3btmXv3r04ODgYuqzHZWTA88/D2bPqMQOHDkGtWoauSidSE1MI3raKusqiwvUw2XmWnE4cjPt/JuE7qKFWX+9eXDLXNgzD32MXACej+1B/yGo8nUvh3wMhjIiEGSH0YOfOnQwYMIDc3Fy6du3Kjh07sC2NnXEfNMI7dgzs7eHgQfWcpDLmkfUw9rpZD/NXv/96AofLA/HzuE1OngUnc/9Hx/8bJ9uuhdACCTOiXAgPD8fMzIwaNWro/bU3bNjAG2+8QUFBAX369GHjxo1Ylsb+LHl5MGCAusjX1hb27YPmzQ1dldb8uR5mIa3ddhauh7me0Jg4hylaXQ/zME2BhiMrPqN9xXep4FDAzbu1yWq5Gf9nWmj9tYQoryTMiDLtt99+46OPPmL//v0AdO7cmbFjx/LCCy9QQQ+da5csWcL48eMBGDp0KKtWrdLL6xZZQQEMHQq7dqmN8HbvhrZtDV1ViaWnpBN27DfuRwTiqtmHj0vII+thTBtOpsXALtTR0dWRpOhEIjcOIcBjHwC/RQ+k8bAVVKpSfra2C6EPJoqiKIYuQpfS0tKwt7cnNTWVSuWoN0Z5pigKgYGBfPTRR/z6668AmJmZodFoePDX3cPDg5EjRzJy5Ejc3d11UsPcuXN57z21Jf3EiRNZuHBh6Tgk8q8UBUaNgtWr1aMJdu5U18wYoYfDS5X8QOpXPYN5hfzCxx9eD1O7hW6nz0IOBuESMQg3+xiycq04qyym/ZDhMq0kxFMqyu9vCTOizFAUhYMHD/LRRx9x/PhxAMzNzRkyZAhvv/02ZmZmrFy5ktWrV5OYmAioIeell15izJgxdOrUCROTkv+iURSFGTNmsGDBAgBmzZrFrFmztDK21ikKTJ4MX34Jpqbw/ffqadhG4t/CC0DUPW9uZgaASwD1Oz+Pkw7WwzysIK+Aoyvm0KHyh5iZaohIqk9B2y3U9W2i09cVoqyRMPMQCTNln6Io/Pjjj3z00UecOXMGAEtLS4YPH86MGTMe6+GSk5PD9u3bWbp0KceOHSu8v379+owZM4bBgwdTuXLlYtVSUFDAmDFjWLVqFQCff/45kyeX4pb0778PH3+s3l63DoYMMWg5/+bpwosXNzM7gUsA1VsH4Fm/ut7qS7gVR9TW12jhfhiAo9FDaTHqK2ztS+FibyFKOQkzD5EwU3ZpNBp27NjBxx9/TEhICADW1taMHj2aqVOnPtX00e+//86yZcvYsGED6enpANjY2DBo0CDGjBlDixZPv0gzNzeXwYMHs3nzZkxNTVm1ahXDhg0r1vemF59+Cm+/rd7+6isYN86w9fyNjNQMrh49XmrDy8PO/3SIandepWrFBDJybAiusIz2rw82SC1ClAUSZh4iYabsKSgoYPPmzXzyySdcvnwZADs7O8aNG8eUKVNwdnYu8pj379/n22+/ZenSpVy8eLHwfj8/P8aOHUv//v2xsvrnnS6ZmZn069ePn376CXNzczZu3MjLL79c9G9OX5YsgT8WJvPppzB9umHrQd1tFHsjijsXgsm6cwrH/EAaVD1dasPLA/m5+Rxb9iEdq8zB1FThWkITKgRsoWaz+gatSwhjJ2HmIRJmyo68vDy+++475syZw/Xr1wGwt7dn4sSJvPXWW1SpUqXEr6EoCsePH2fp0qVs27aNvLw8ABwdHRk2bBijR4+m1l8ayKWlpdGrVy+OHDmCtbU127dvp3v37iWuRWfWrYM33lBvz5wJH32k9xI0BRpuXrxO3OVgcuODqZh3nur2wVSxu/vYc0tbeHlY1NWb3P1xMD7uRwE4EvMmvqMXYm1nbeDKhDB+EmYeImHG+OXk5LB+/Xrmzp3LzZs3ATVcTJkyhfHjx2Nvb6+T142Pj+frr79mxYoV3Lp1q/D+bt26MXbsWJ5//nnu3btH9+7dOXfuHJUqVWLv3r20b99eJ/VoxdatMHAgaDQwaRJ8/jnoeGFybnYuN4IvkXgtGE3SeRwIpqZDKHZWGY89N7/AjBt3GxKf1xITF/9SF14euHTkNKmnFtLadSsVzApIy6rIRZtVPPPKAEOXJkSZIWHmIRJmjFdWVharV69m/vz5REVFAeDs7MzUqVMZM2YMdnZ2eqmjoKCAffv2sXTpUvbv31+4vdvLywtzc3MiIiJwcnLiwIEDRVpjo3d790Lv3pCfDyNGwMqVWg8y6Snp3DgXyr0b5zFNDaaqWTA1q1zCokLeY8/NzLHmxr2mJCvNwbEFTnWaU7N5Y6x00LhOG/Jz8zmzYwe2UV/Q1O23wvvPx/yHKt1X4N24tgGrE6LsMZowc+TIERYsWMC5c+eIjY1lx44d9O7d+8/i/uEf2vnz5zNt2rSneg0JM8YnIyOD5cuX89lnnxEXFweAu7s706dPZ+TIkdjY2Bisths3brBixQrWrFnD3bvqlIinpyc///wz9euX4jUSO3bAK6+oxxUMGgTffANmZiUaMvF2PLcvhHL/djAWGcG4WQbj7XgdU9PH/0lJyaxMZEpzUs2aY+7cApcGzaneuC4VLEphA8G/SE1MIfiHNdQuWIyng3qFLjffnNPxr+DUfhL125adLslClCZGE2b27dvH8ePHadmyJX369HkszDz4Rfbw84cPH054eDg1a9Z8qteQMGM8NBoNq1atYubMmSQlJQHg7e3N22+/zRtvvFH8IwDS0+HNN9UutyNHwn/+U+IrEtnZ2Wzbto1Tp04xdepUvL29SzSezkRGwltvwZ496ucvvqhONZmbP/UQ+bn53Pw9jPirIeQlhGKXH4pXxVCcK8X/7fNjU925k96cTMvmWLm3wLNxczzqehtds7gH5ze1cFhLRSt1p1tSuhMXs8fQ4IUxuFR3M3CFQpRtRhNmHmZiYvJYmPmr3r17c//+fQ4fPvzU40qYMQ5Xr15l5MiRhX1fatWqxbvvvsvrr7+OeRF+8T4mNxd69VIPTHygXj0YM0btqVLMfjKlXlYWzJ8P8+ZBdrba2XfyZHWx7xNCYUrCPW4Gh5J6KxTTtFCczEKp4XgJK/Ocx56r0Zhw615t4rKbkWPTHDuvFng3b05Vz6LvJistFI1C6M9B5Fz4Al+33YVXma4nNiKu0iRa9XtVFvcKoSdF+f1d+q/x/iE+Pp69e/eyfv16Q5citCg3N5d58+bxySefkJubi62tLXPmzGHs2LElP8OooAAGD1aDjI2NuvB161YIC1MXv77zjjrlMmYMtGyple+nVNi7FyZOhBs31M//8x+1j0yDBoVP0RRouHUpnLgroeTEhWKTG4qHbSgele/QDMDuj48/3M+2I/JeU1LwAQcfHGv6UL1ZY2pUtkP/R3dqX05mDmd+2IxT0kKa6fn8JiFEyRlNmFm/fj0VK1akT58+T3xeTk4OOTl//l9kWlqarksTxXTixAlGjhzJpUuXAHjuuedYtmzZYx17i0VR1F/omzerUyrbt0O3bvDFF/Ddd7B0Kfz+O6xZo360bg1jx0L//mBtpP/n/dcpJXd3WLgQpe/LRIRcIWbNMrgXioNJKDUcfqeGVYYaRP7S3f9OcnVisnzIsvTBys0Ht4Y+VKtfg6ZmpfBcqRJKik7k4o7lNKiwlPaV4sBFXZh8NnkIHv+ZiO+gBv8+iBDC4Ixmmql+/fp07dqVxYsXP3GcDz/8kNmzZz92v0wzlR5paWm8++67LF26FEVRcHZ25ssvv2TAgAHaO7/oww9h9mx1bcymTTDgL1tmFQWOH4dly9SrNX/0k8HRUe3BMno01DaS3SnZ2eqU0ty5hVNKyeMnc7V5EwoSfqW2zUHcKkc/9mVZuVZEJjfmrsYHjb0Plav7UL1ZU+yrVtb/96Bn189eJDbwS3ydvsXaIhtQ1/qEacbTtM8oHN1K3rNICFEyZW7NzNGjR+nYsSMhISH4+Pg8cZy/uzJTrVq1ch1mFEXhzp07eHp6GvzU5t27dzN27Fiio9Vfrm+88QafffYZjo6O2nuRr76CCRPU20uWqFdcniQhQb06s2IFPNRPhmefVb/2+efVNSel0R9TSvk3b3K5dkOSO9TCqX40DV3PPbKrKCvXisuJHbhv3hILFx9c6vvg3aiOUewm0hZNgYZzew9gGraQlh4/F95/Oa4V91wn49vnZSysLAxYoRDiYWUuzAwdOpSLFy9y9uzZIo9b3hcA5+XlMWrUKNatW4eXlxeDBw9myJAh1NbzVYe4uDgmTpzI1q1bAXWB74oVK+jcubN2X2jTJnUdDKhXZ2bNevqvLSiAffvUKaj9+9WrNwDVqsGoUWpvFldX7dZbXJGRRE15hxtp0Vg0zaNBoyvY2zw6pXo9oTHRSjcq1nmWhgEdyuXC1cSoBMKPB5EbFYi3xUGqVwkHoEBjypnY3tg0n0yT/7Qzup1WQpQHRhNm0tPTCQ9X/3Fp3rw5n3/+OZ06dcLR0bFw3URaWhpubm7873//Y/To0UV+jfIcZjIyMujXrx/79u177LH27dszdOhQ+vXrp9M/F0VRWLNmDdOmTSMlJQUzMzOmTp3KBx98oP1+Mfv3qzuX8vPVc4cWLSr+FuwbN9QrNWvWwB/9ZKhQAfr0Ua/WdOyo8865f5Weks6VQ4fIPL0RL5cz1HC7+cjjyRmOXE3pSoFzN2p3eBa3mh56ra80SLwdz/XfgsiLDsKjQiC1q15+5PG0rIqcTx1BrR4TqNagLCxdFqLsMpowExgYSKdOnR67f8iQIaxbtw6AlStXMmnSJGJjY4vVtr68hpnExESef/55zpw5g7W1Nd9++y15eXmsW7eOgwcPotFoAPWU6b59+zJ06FA6deqk1Wmoa9euMWrUKIKCggBo2bIlq1evplmzZlp7jUInTkCXLpCZqTaH+/Zb0Mb3kp0N27apV2tOnPjz/oYN1V1Qr78OOjpOQdEoXDsdSuz5A9hnHqCR87FHOunmF5hxObY1yTY9qNq0G/XbtsTMvGSN8IzNg/CSHx2IR4VAalW98thzwhKaEqcJwNIrgIadOlOpSvn5d0AIY2Y0YUYfymOYiYyMpFu3bly/fh1HR0f27t1LmzZtCh+Pjo5mw4YNrFu3jrCwsML7vby8GDJkCEOGDHnsMMWiyMvLY8GCBfz3v/8lJycHGxsbPvroIyZOnFjy7dZ/59Il6NAB7t1Tdyzt3g0WOlj7EBKiLhj+9ls1NAFYWUH9+lC3rtq/pm7dP28XI+RkZ2Rzfs9uNHd+pG7Fg481pruT4EnklTpYeHahweix5WKx7sMSbsUR/lsQ+TGBeJgHUsvp6mPPCYv3IU4JwNLLn7rtOspiXiGMlISZh5S3MBMaGkr37t2Ji4vD29ub/fv3/2ObfUVROHXqFOvWreP7778nNTW18LEOHToUTkNVrFjxqV//9OnTjBgxgt9//x1QD2VctmwZNWro6JL+zZvQrh3ExECbNnDoENja6ua1HkhNVY8DWLYMrjx+JaCQs/OfAefhoFOr1mNh69rpC8QeXU3TSt/iYHuv8P6MHBsuXW5E1gUrvC5FU33gS5jMmgVF+JkYs/ibsUSc+OPKi0XQY+FFozHhWqIP8Yo/Vl4B1GnXQcKLEGWEhJmHlKcw8+uvv9K7d2/S0tJo0qQJ+/fvx93d/am+Nisri127dhVOQz34a2FjY1M4DRUQEPCP01Dp6enMnDmTRYsWoSgKVapU4YsvvuDVV1/V3nbrv0pIgPbt4fp1aNQIjhxRt1bri6Korx0WBteu/fnfa9cgNvafv87UFGrUIK1eI0K8nanifZZG1UIKH45Oqcb1hO7Y/3KDhieOYJmfB506qbu0GjbU/fdlILnZuUSGXCYhLBgl8RSeFoHUdAp75Dl/hpcArLwDqNuuAw6uevyZCyH0RsLMQ8pLmNmyZQuvv/46ubm5+Pv7s3PnTioXs1V/VFQU33777VNPQ/3000+MGTOG27dvA/D666/z+eef4+TkVKLv6YnS0tRf8OfPg7e32jPGoxQteE1L+9ugo4SF8btHTVIDKtHCLxhbK3W6KjffnHPnWmJ+DJrfT8bs+jV1HDc3+PxztU+Onhcc61JGagY3zl8gOeI8pinBOJkFU9PxIpbmuY88T6MxISyxGfFKANbVA6jXvgOVnR0MVLUQQp8kzDykPISZxYsX89Zbb6EoCi+//DIbNmzAysqqxOP+2zTU4MGD+eWXX9i0aRMA1atXZ8WKFTz77LMlfu0nys6GHj0gMBCqVoVjx9Tpm1IsMSqBS3u+wStv9SNXGyJi63DnYjManwnH6eoFdXs4qDunJk2CDz4w+imle3HJRJ4PJu1WMObpwbhanqe64zXMTDWPPTc1054bKc1JNWuJtXdHCS9ClGMSZh5SlsOMoii89957zJ07F4Bx48bx5ZdfYmam/R0t/zQNBWBqasrkyZOZPXs2trper5Kfrx45sGOH+kv+119L7blKBXkFnN93kIKw1bR02Y15hXwA0rNtCU4eQOWWI2js3+bPHid5eeqW8IgIdVHxU54MX1ooGoW4mzHcCQ0mM+o8VtnBeNoE4+lw62+fH5/myu37LciwaI6lW3M8m7TAs1516fkihAAkzDyirIaZvLw8Ro4cWXjw5ieffMI777yju/UpD3kwDfX999/j4ODAggULaNWqlc5fF0WBkSPV3i8WFmpfmb/Z2m9od65EEvHzWupWWIt75ajC+y/G+XHPYQTNeg+gooNxX20pyCvg1mX1oMrcuGDs8oLxrnSeqhUT//b5t5JrEpPVnBybFthWa463T3OcvUtJA0IhRKkkYeYhZTHMZGRk0L9/f3766SfMzMxYuXIlw4YNM3RZuvfOOzBvnrqAdts2eOklQ1dUKCczh3O7dmIZtZqWHocK70/OcOT3+4Nx7zicOq0aG7DC4rt/7z43g3/nXmQo3AvB0VQ9qNLWMvOx5xZoTLlxtwHxuS3Ir9ScytWbU6NFs3K3hVwIUXJF+f1dfg5mKSOSkpLo2bMnp06dwtrami1bttCzZ09Dl6V7//ufGmQAVq4sNUHm2pnfiT26hiYVN/CMbTL8sQb5XHRXcqqNoOWrL+JvY2nYIp+SolGICb9D1MUQsmJCscwKxd0qBO8qETQBsP7j4w+ZOdbcuNeEZE0zcGxBldrNqdmiCXXsrKljmG9BCFFOSZgxIjdv3qRbt25cu3YNR0dHfvzxR9q2bWvosnRv/XqYOlW9PW8eDB9u0HIK8go4u/tHLCM/p5n7Eer+MVsSk+LJtfxh1H72DVoOqm7QGv9NTmYOkaGXSbwWguZuKPaaELztL+Bhe0/NY3/Z7Ryb6k5Uug8ZFs2wcPbBtYF6UGXjctZxWAhROkmYMRIPN8Pz8vJi//79NGjQwNBl6d6ePX+Gl//7P5g+3WClZKRmcHbrOryzvsCvSji4Q15+Bc7Gv4h5vRE079cV91L4y70gr4CrJ86ReOkIFdJDcTEPobrjVepXyKe+OfDQ0pW8/ArcSG5IYp4P+RV9qOTVDO9mPri5O+FmsO9ACCGeTMKMEQgMDOTFF18sbIa3b98+PIrSU+XKFZg/H5o1g5491Q60xuDIEXXnUkEBDBkCCxYYpNdKXGQMV3d/hY/Ncvxt74ENpGRWJiR9NPVeGE/bUnigY2xEFOHHDmKWcID6lQ/RyDYZ7FE//pCc4citVB/STH0wc2pG1bo+VG/agHo2ltQzWOVCCFF0sgC4lNu2bRuvvvoqubm5dOzYkV27dhWtGd6NG2qX3Ic70jZooJ4u3asXtG0LOtjKXWIhIeDvrzafe+EF+OEHtfeKHoWdDCHx6Oe0dvm+8IDHW3drcdN6Mi1fHoJdZTu91vMkWelZXPr1COnXD+BhdpA6VS898nhqpj1X7nUi27oVNh4+eDbxwa2mp2yDFkKUWrKb6SHGHGa++uorJk6ciKIo9OnTh++++65ozfDi4tQg86BviZuberXjQWM2gCpV4Lnn1GDTrRuUhj+jiAj1vKX4eOjYUd2CbW3971+nBZoCDef27MMs/HNauP9SeH9oTAeyq0+h1Yu9SsXJ1IpGIfz8JaLPHsTu/gEaVT2CtUV24eMFGlOuJPiSVKEbVRp3o0H71lSwkAuxQgjjIWHmIcYYZhRFYebMmcyZMweAsWPHsmjRoqI1w0tNVa9shIZC9epqu393d0hJUcPBnj2wb5960vQD5uZqeHhw1UafTduysiA8XG37P306REaCjw8EBRXr9OmiykzL5Oy2DXimLyzs0JtfYMapuP44tJlMww6+Oq/h3yTH3uVq4CEKog9Q2+YgbpWjH3k8NsWD8MxumHl2o0FAFzmzSAhh1CTMPMTYwkx+fj6jRo1i7dq1AHz88ce8++67RWuGl5UF3burV2GcndUgU7v2372Y+tiePerHtWuPPt6w4Z/Bpk2bkk9HFRTA7dt/Hsb48LlFd+6oTfEeqFVLPabAVbeN1RJuxXF511KaWC2lit1dAFKzKhGcNoo6z0/Ao66XTl//SfJz87l85CTJlw/ilH+Ahs5nMDX9888oK9eKS4n+pFfqhqdvN2o1ayDTRkKIMkPCzEOMKczcuXOHESNGcPDgQUxNTVm5ciXDi7oNOT8f+vaF3bvVKaOgIHXh79O4dg1+/FENNkePFn866u7dx0+SDgtTr7zk5Pzz11WuDPXqQdOmMHMmeOkuSFw78zvxQQtpXfW7wsMN7yRX54bFJFr0G2awDr1pd9MI3bMV88S9NHA8jL112iOPX09sRLSmGxXrdKNhQAes7fQz/SaEEPomYeYhxhBmCgoKWLZsGe+88w7p6elYWVmxZcsWevXqVbSBFAWGDYN168DSEg4cUKeaiuPevUeno1JS/nzM3Fwdt1cvderqr1dakpP/eVwLC6hTRz0Ysm5dNbw8+G+VKjrdraRoFM7tPYjJ1f/R0uPnwvt/j21LerUp+PbubZB1JYpG4cIvx7gfvIbmTlsf6aybnOHI1ZSuFDh3o3aHZ3ErhTunhBBCFyTMPKS0h5lLly4xYsQITp48CUDbtm1ZtWoVjRo1Kvpg06bBZ5+p00Hbt6u7gLTh36aj/o6X198HFi8vve+eysnM4fTW73BN+bxwl0+BxpTTsX2wazWFJp0M03gw4VYcl/d+g3f+Gmo4/flneiOpHrdNBlHVpzv127YsFQuOhRBC3yTMPKS0hpmcnBw++eQT5s2bR15eHhUrVmTevHmMHj0aU1PTog84fz7MmKHeXrsWhg7Var2PuHZNDTU//QQZGY8Hltq1wcZGd6//lFKTUgnesoL6Jl/gaq9uTb+fbcf5lBHU7DGRag1q6L2m/Nx8zu/dhxK+hpauP1LBTJ3KU0/S7k/lFiNoHNBW1r4IIco9CTMPKY1h5ujRo4wcOZKwMHXXzAsvvMCSJUvw9PQs3oBr1sCIEertBQv+bP1fTsXeiCZs15e0qLScStb31ftSPAgzeYvmL480yKGHty6GE3n4a+pbrCsMVgC/x7YhxXF4mThJWwghtEkOmiylUlNTmTFjBitWrADA1dWVxYsX07dv36LtVnrYjh0wapR6e8aMch1kIoKvEHP4M/ycNxDgoja5C09sSJzDNFoPG0SAlYVe68lMy+T87h+wi1tDM/cgvKuq9yelO3ExYzCeHYfRZFAxphOFEEI8QsKMnmzfvp3x48cT+0cn3hEjRjB//nwcHByKP2hgILzyCmg06vlFc+dqp1gjc+HwcbLOz8fPYze13NX7QmM6kFNrOq3GP0dts2JM2xWTolG4euI8iSfX4GO/kfY2qeAOGo0J52K7ke89nJaDX9B7sBJCiLJMwoyOxcTEMH78eHbs2AFAnTp1WLVqFf7F3WX0wPnz6gLfnBzo3RuWLzfIuUWGoinQcGbXj1hHfkpTt9/AQw0Mp2NfxLbVdHwG6XdR7724ZC7s+Q7X9DU0cAmlwR+nMt5Jrk4Ew6jbfSi+tavptSYhhCgvJMzoiEajYeXKlcyYMYO0tDQqVKjAjBkzmDlzZtGOJPg7166pTfHu34eAANi0Se/nFhnKg51J7qkL8HO6Cm6Qk2fBqcTBeHb5P9q8Vl9vtWgKNIQc+JWsS2to6bwdf9scsIXsPEvOJfTButFwmg3oRDU9XhkSQojyqHz8BtSzq1evMnLkSI4dOwZA69atWb16NU2aNCn54NHR8OyzkJgILVrArl1Q0nBkBFKTUgneupJ6fEEH+xhw+qNT7/0xNOj9Fh2ru+mtloePPmjhFAZ/tH4Ji/chzm4ETXsNop0cJSCEEHojYUaLcnNzmTdvHp988gm5ubnY2toyZ84cxo0bV7Rzlf5JcrLafffWLbXx3L59peNgSB2KvxnLlZ1f0LzicgLs1W64sanuhDGZFv1HEVBFf99//M1YruxaQhPr5XS0uwtWaqAKTXmVqm2GU39gC+rJlmohhNA7CTNa8ttvvzFy5EguX74MwHPPPceyZcvw0lZL/owM6NkTLl1Su+4ePKieu1RG3Qi5SvShz2hddQMBzupxAxGJDYh1mE7rN/S7MynsZAiJRxfS2mUTAVXVXVK3k2sQafEWLfoNo6NsqRZCCIOSMFNCaWlpvPvuuyxduhRFUahatSqLFi1iwIABxd9u/Ve5ufDyy3DiBDg4qEGmenXtjF3KXDpymvRTc/Dz2EXNBzuTYtuTU3M6rcY/Ty09rT/RFGg4u3sv5hELae7+K/U8/qwly2syvm++iJd05hVCiFJBwkwJ7N69m7FjxxIdHQ3A0KFD+eyzz6hSpYr2XkSjUbv57t+vdtXduxeKc9RBKXcx8CRZZ2bj67G/cA3Kyeje2Lachs+gZ/RWR0ZqBme3rscr6wtaV7kO7pBfYMapuP44tJmMzyBfvdUihBDi6UiYKaYpU6awcOFCAGrVqsWKFSvo3Lmzdl9EUWDSpD93K/3wA7Q1zDlCunLh8HHyzs9WD370UIPDybjXcO/6Nm0G6W9nUuyNaMJ2f4WP7Qr8be+BDaRkViYkfRR1e46nnWyrFkKIUkvCTDF169aNRYsWMXXqVD744ANsdHEW0ccfw+LFav+Yb75Rt2OXESEHg9Bc+C8t3H8BD8jLr8DJhCF49XiH9o1q6a2OK8fPkfzbQlq7bMbNOR+AW3drcdNqEi37DSWgsp3eahFCCFE8cjZTCdy6dQtvb2+tjllo2TIYO1a9vXgxjB+vm9fRI0WjEHIwEJOLs2nmHgRAbr45JxPeoMbzb+vt4MeCvALO7tqD5c2FNHM/Unh/SExHcmpModULPeWkaiGEMDA5m0lPdBZktmyBcePU27NmGX2QUTQKwfsPY3ZlNs3djoH7H43ukoZTq9fbdKyrpR1f/yI9JZ1zW9dSPftL/KpEgLt6Reh0/AAcn5lMs0Et9VKHEEII7ZIwU9ocPAivvaaulxk3Tg0zRkrRKJzbexDLa7Np4XYC3NTuuKeSRlK39ww61irmKeFFFBcZw9VdX9LMbiX+tilgC/cyHAjNeJN6L4ynXU0PvdQhhBBCNyTMlCbnzkGfPpCXBwMGwKJFRnnekqJROLtnH9YR/6WV6ylwg6xcK04nv0m9l6bjX8NdL3WEn7tE7C+f4efyHQHOan+YyLt1uG09iVb9hxBgb6uXOoQQQuiWhJnS4sYNeO45tTle167qgl9T4zrTR9EonNn1I3aR/8XX9Sy4QmaONadTxtDgpan46+HIAUWjEHroCLmhC2jtsZfaD/rDxHQgu+ZUfMf2pIaclSSEEGWKhJnSIClJ3amUkADNmqlbsC301+G2pDQFGs7s2E2lO/+ltUswuEJGjg1nUsbRqN9UAjx136m4IK+A0zt2UDFqAc1cTxeeon0qtg8VW0/DZ5CfzmsQQghhGBJmDC0zUz2m4Pp18PaGn36CisbRHl9ToOHUD9txjPkIP+cL4AL3s+04lzaexv2mEOBRVec1ZKVncWbzOrwz/0fbKhHgqk5pnbk7FK9np9D2tTo6r0EIIYRhSZgxpPx8eOUVOHUKHB3VLr9u+jv9ubjycvI4tfV7XO5+Stuql8AZ0rIqcj59Ik37TybATYsdkP/B3Zgkfv9hKY0tF9PRLgmsITnDkQtZ42jUZzwd9XA1SAghROkgYcZQFEXdcr17N1hZqf+tr7+Ot8WRkZrB2c1rqJX3P9o73IaqkJppT3DmWzQbOIkAZwed13D78g0i932Or+PXBFTJAuBOcnVuWE6hVf9hsqhXCCHKIQkzhjJnDqxYoe5W2rgR2rUzdEX/6F5cMqFbv6KJ5SL87e4CkJDmwmXNZJr3H02Ak73Oa7h87CwpJxbg57YNLzcNAFfiW3DPdTqtR/WlmoX8VRZCiPJKfgMYwrp1MHOmenvxYnjpJYOW809iI6II2/U5rSqvJKBKBgC3kmtyy2Y6rV8fQoCtlU5fX9EonP1xPxWuLaC5+6+FB1Ceie5OhcbTaDawEyamxrd1XQghhHZJmNG3Awdg5Ej19ttv/9nptxS5EXKV6EPz8XP+lgBXtT/L1fhmJLu+TetRffHW8VWQ3OxcTm/9Hpe7C/B1vljYqfdU/Cs4+0/Fd1BTnb6+EEII4yJhRp/OnYO+fdWFv6+9pk41lSIXg06RfvpTWrvtpKa7emRXcEwABfXepuXAZ3V+FSQzLZMz36+iTv5ntK8cBc5/7I5KHUXdXpNoLydXCyGE+BsSZvQlMhKef15titelC6xZUyq6+z44csAsbB7N3QMLp3JORr+EXesZNNdDf5b0lHTOblpOI9MF+FdMACA+zZUrmrdo3m80AVUr67wGIYQQxkvCjD48aIoXH19qmuIV5BVwats2HOPm0colpHAq52TC67h3nkabQQ10XkPa3TTOf/8VTcw/J8BeXVh8J7k6kTbv4Dd4CAE2ljqvQQghhPGTMKNrmZnQqxdcu6Y2xdu7F/7lKHNdys7I5vTm9XhnLOCZKhHgAunZtpxNGUXdFybTQQ9TOSkJ9wjZvIhm1l8Q4JACwM27tYmyfw+/ka9SzdJc5zUIIYQoOyTM6NKDpngnT4KDA+zbB+76OWTxr1KTUgnespyGpgvpWCkerOBuehV+z5lI05fH6aXRXXLsXS5sWUhzu8UEVEkDICKpPnFVZuL35gCqy/ZqIYQQxSC/PXRFUWDCBLUZnqUl7NkDDXQ/dfNXty6GE3lwKc3t1xBQWQ0QUfe8iDD/P1oNGK6XJnOJUQlc2vY/WlVaQkBVdYv39YTGJLq+j9+YvtQyN9N5DUIIIcouCTO6MncuLF9ukKZ4mgIN5/ceRAlbTEu3fXi7qjuTwhMbElflbfxGDMRTD1M5cZExhO1YgK/DCgKc1W69V+Kbk1rtfVpPeJE6cnq1EEIILZAwowvr18N776m3Fy2CPn308rKpSamEbF+HV84SWlW5/lCTuR5QbwItB3Sjth4CREz4Ha7v+hQ/p9X4u+YAcDGuNZk13sf3reel0Z0QQgitkjCjbQcOwIgR6u0ZM9Tzl3QsIvgKUb98RQuHb/C3Swc7SM2qREjqMKo/Ow7fQbV1XgPAnSuRRO6dRxvntbi7qc32LsS2I7fu+3rpUyOEEKJ8kjCjTefP/9kU79VXddoUryCvgLO7f8Q8cjEt3A9T64/DtsMTGxJjN54WfV/Hv7Kdzl7/YbcuhnN7/xzaunxDNfcCQG22R+MPaDYwQEKMEEIInZIwoy2RkfDcc2pTvM6d4euvwVT7Uzr34pIJ3bGGWgVL8XO8Ce5QoDHlTOwLWDaeQLOBnaitp/AQEXyF2ENzaOu2EW939fDHc9FdqdD8fZoP6qCXGoQQQggJM9rwcFM8Hx/Yvl3rTfHCToWScHQxrZy+I8A+G4DkDEcuZIykdo8xtKnnrdXXe5Lffz1B5tlP8fPYRa3CdTnPYe37Pi0HtdFbHUIIIQRImCm5zEx44QW1KZ6XF/z0k9aa4uXl5HF2505s7izGx/0o9f5oUXM1vhmJjhNo9corBNhZa+W1/o2iUTi7+ycswj/Fx/1o4eLiU9EvUumZ9/Ed1FIvdQghhBB/JWGmJAoKYNAgOHFCbYq3f79WmuIlRiVwaedK6pkup23l6MKjBs7E98WuxQSaDHyG+nqaSsrLyePU1u9xSZpfeIJ1br45pxJew73zNPz0cOyBEEII8SQSZorrQVO8XbvUpni7d5e4KV5E8BViDs2ntfNGAhxzAUi878ylnDep32s0z9TQX/fg9JR0zm1ZQ628z2nvcPuhE6zfpN4Lk+hQy1NvtQghhBBPImGmuObNg2XL1KZ4330H7dsXe6jLx86SdmIurd12UMtDbXB3Mc6PVJcJtHr9Zb0euJgUncjFHxbT1HoJ/nbJwB+BKv8tmvUbQ4Czg95qEUIIIZ6GhJniqlFDXeT72WfqduwiUjQKoT8HUXBhDi09fi5cg3Iy+iXsWs+g8SA/LRf8ZHeuRHLjp//h6/g1AU5qt95bd2txy3Yavq8O1tvaHCGEEKKoTBRFUQxdhC6lpaVhb29PamoqlbR9WvWNG1CzZpG+RNEonNm1F+sbc2jidgKA/AIzTsa9imvnGdRu0VC7Nf6LsFOhJB35FD/XLVQwU3vEXI5rSarHDFr36YOZnJskhBDCAIry+1uuzJREEYJMfm4+p7dtxSlhLq2dfwc3yM6z5FTScGo9P4329avrrs6/UDQKIQcDKfj9U1p5HKDeH1eFzkV3xaTRDJoP/I80uhNCCGE0JMzoWE5mDqc2f4N3+qc8UyUCnCEtqyLn74+l4UuT8Pd21VstBXkFnN6xk0pRn9Lc9Qx4qA33TsX2w6HddFoOaqG3WoQQQghtkTCjI+kp6Zz9fiX1lP/R0T4GLCEp3YmLuW/RrP84vS6kzUrP4szWb6mWvoC2Va6DK2TlWnH67jBq9Pg/nmlYtKkyIYQQojSRMKNl9+KSCd26mKZWiwiopO4Gik3x4FqFabQaMIIAe1u91RJ19Sbh+5fR1HY1HW2TwRLuZTgQmjWORn0m4O/prLdahBBCCF2RMKMl8TdjubLjc1raLyegSjoAkXfrEFVxBn7DXsffSrvHG/wTRaNwft8h8i9/ha/bHjyd1fXdUfe8CK8wiVYDRhKgpwMohRBCCH2QMFNCty/f4Oa+Bfg5fU2Ai9roLizeh7tu7+I3ui819LQbKO1uGsHb11MtawktncIKt3qfi+5Kfq3xtBr1PJ6yM0kIIUQZJGGmmK6fvUjCr/Pwc/0eLzd1S/OF2Hbk1HmPVgO76203UPj5y0T/uoQWDt/gb5sOtuoC4+CUoVTrPJaWg+rrpQ4hhBDCUCTMFFNM0Ar8Pb4D4Ex0dyyav4vPoA56ee383HzO7t6Dxc2vaOH+C7Xd1PsjEhsQZTueFn1fx9+hol5qEUIIIQxNwkwx1eo5ld92J+DY/m18BzXXy2smRSdycedq6pgso03lO+Cubq0+E/silo3H02xgJ2pJfxghhBDljKkhX/zIkSP06tULd3d3TExM2Llz52PPuXLlCi+88AL29vbY2tri6+vL7du39V/sX3jW8+aZaZup31b3Qeby0TMcWzCEioc8CXB4F4/Kd0hKdyIw8R3iWkfSZtp2mveQRndCCCHKJ4NemcnIyMDHx4dhw4bRp0+fxx6PiIigffv2DB8+nNmzZ1OpUiUuXbqElZWVAarVr+yMbM5u30LlxCU0dj1duKD3Upwv96qOp9Wr/QmwLft/DkIIIcS/KTVnM5mYmLBjxw569+5deN/AgQMxNzdnw4YNxR5Xp2cz6UBM+B2u7V1GY+tVONklAZCTZ8GZhIE4+I2jUcfWBq5QCCGE0L2i/P426DTTk2g0Gvbu3UvdunXp1q0bzs7O+Pn5/e1U1MNycnJIS0t75MMYRARf4diCoVT9rSYBVefiZJdEdEo1Au/NIa3zHdpPWy9BRgghhPgbpTbMJCQkkJ6ezrx58+jevTsHDx7kpZdeok+fPgQFBf3j182dOxd7e/vCj2rVqumx6qK7dOQ0Jxf0ocalRrT3WI95hXyCYwI4abEdlxE3CBj3DlWlU68QQgjxj0rtNFNMTAweHh688sorbNy4sfB5L7zwAra2tmzatOlvx8nJySEnJ6fw87S0NKpVq1aqppkUjULw/sNweS4t3H8pvP9k9EtU9HtbrsAIIYQo94oyzVRqt2Y7OTlRoUIFGjZs+Mj9DRo04NixY//4dZaWllhaWuq6vGJ5cGq1fdQ8WrieBXfIy6/AyfjXcO8ynTaDGhi6RCGEEMLolNowY2Fhga+vL2FhYY/cf+3aNby9vQ1UVfHkZudyavO3eKTOp61TGLhCZo41Z+6NpHbP/6NDXS9DlyiEEEIYLYOGmfT0dMLDwws/j4yMJCQkBEdHR7y8vJg2bRoDBgygY8eOdOrUif3797Nnzx4CAwMNV3QRpKekc3bzKuoV/I8OlaPBCVIyKxOSOYEmL0/E393J0CUKIYQQRs+ga2YCAwPp1KnTY/cPGTKEdevWAfD1118zd+5coqKiqFevHrNnz+bFF1986tcwxNbs5Ni7XNj2FU2tFuFomwxAXKobV03+j5YDRlFRjhoQQgghnqgov79LzQJgXdFnmImNiCJs1+e0qrwSO6sMAG7erc1tu+n4DRiMpU3pXMsjhBBClDZlYgGwMYm8cI2og/Pxc/6GANc8AK7GNyPZ7R38RvelurmZgSsUQgghyi4JMyVw5fg5Un6bh5/bD9RwVy9whcT4k1/vHVoOfFbOShJCCCH0QMJMMQUunEqAy/8Kz0w6Ff0CNq3eptmgtoYtTAghhChnJMwUk7VXB/Izv+Bk3CBcOk3Hb1BjQ5ckhBBClEsSZorJt3cvYsIjaF/PuHreCCGEEGVNqT2bqbQzNTPFU4KMEEIIYXASZoQQQghh1CTMCCGEEMKoSZgRQgghhFGTMCOEEEIIoyZhRgghhBBGTcKMEEIIIYyahBkhhBBCGDUJM0IIIYQwahJmhBBCCGHUJMwIIYQQwqhJmBFCCCGEUZMwI4QQQgijJmFGCCGEEEatgqEL0DVFUQBIS0szcCVCCCGEeFoPfm8/+D3+JGU+zNy/fx+AatWqGbgSIYQQQhTV/fv3sbe3f+JzTJSniTxGTKPREBMTQ8WKFTExMdHq2GlpaVSrVo07d+5QqVIlrY4ttEt+VsZDflbGRX5exsPYflaKonD//n3c3d0xNX3yqpgyf2XG1NQUT09Pnb5GpUqVjOIvhpCflTGRn5VxkZ+X8TCmn9W/XZF5QBYACyGEEMKoSZgRQgghhFGTMFMClpaWzJo1C0tLS0OXIv6F/KyMh/ysjIv8vIxHWf5ZlfkFwEIIIYQo2+TKjBBCCCGMmoQZIYQQQhg1CTNCCCGEMGoSZoQQQghh1CTMFNOSJUuoXr06VlZW+Pn5cfr0aUOXJP7Ghx9+iImJySMf9evXN3RZAjhy5Ai9evXC3d0dExMTdu7c+cjjiqLwwQcf4ObmhrW1NV26dOH69euGKbac+7ef1dChQx97n3Xv3t0wxZZzc+fOxdfXl4oVK+Ls7Ezv3r0JCwt75DnZ2dmMGzeOKlWqYGdnR9++fYmPjzdQxdohYaYYNm/ezJQpU5g1axbnz5/Hx8eHbt26kZCQYOjSxN9o1KgRsbGxhR/Hjh0zdEkCyMjIwMfHhyVLlvzt4/Pnz2fRokUsX76cU6dOYWtrS7du3cjOztZzpeLfflYA3bt3f+R9tmnTJj1WKB4ICgpi3LhxnDx5kp9//pm8vDyeffZZMjIyCp8zefJk9uzZw9atWwkKCiImJoY+ffoYsGotUESRtW7dWhk3blzh5wUFBYq7u7syd+5cA1Yl/s6sWbMUHx8fQ5ch/gWg7Nixo/BzjUajuLq6KgsWLCi8LyUlRbG0tFQ2bdpkgArFA3/9WSmKogwZMkR58cUXDVKPeLKEhAQFUIKCghRFUd9H5ubmytatWwufc+XKFQVQTpw4YagyS0yuzBRRbm4u586do0uXLoX3mZqa0qVLF06cOGHAysQ/uX79Ou7u7tSsWZNXX32V27dvG7ok8S8iIyOJi4t75H1mb2+Pn5+fvM9KqcDAQJydnalXrx5jxozh7t27hi5JAKmpqQA4OjoCcO7cOfLy8h55b9WvXx8vLy+jfm9JmCmipKQkCgoKcHFxeeR+FxcX4uLiDFSV+Cd+fn6sW7eO/fv3s2zZMiIjI+nQoQP37983dGniCR68l+R9Zhy6d+/ON998w+HDh/n0008JCgqiR48eFBQUGLq0ck2j0TBp0iTatWtH48aNAfW9ZWFhQeXKlR95rrG/t8r8qdmifOvRo0fh7aZNm+Ln54e3tzdbtmxh+PDhBqxMiLJj4MCBhbebNGlC06ZNqVWrFoGBgXTu3NmAlZVv48aN4+LFi+VinaBcmSkiJycnzMzMHlv5HR8fj6urq4GqEk+rcuXK1K1bl/DwcEOXIp7gwXtJ3mfGqWbNmjg5Ocn7zIDGjx/Pjz/+yK+//oqnp2fh/a6uruTm5pKSkvLI8439vSVhpogsLCxo2bIlhw8fLrxPo9Fw+PBh2rZta8DKxNNIT08nIiICNzc3Q5cinqBGjRq4uro+8j5LS0vj1KlT8j4zAlFRUdy9e1feZwagKArjx49nx44d/PLLL9SoUeORx1u2bIm5ufkj762wsDBu375t1O8tmWYqhilTpjBkyBBatWpF69at+eKLL8jIyOCNN94wdGniL6ZOnUqvXr3w9vYmJiaGWbNmYWZmxiuvvGLo0sq99PT0R/7PPTIykpCQEBwdHfHy8mLSpEl8/PHH1KlThxo1avD+++/j7u5O7969DVd0OfWkn5WjoyOzZ8+mb9++uLq6EhERwfTp06lduzbdunUzYNXl07hx49i4cSO7du2iYsWKhetg7O3tsba2xt7enuHDhzNlyhQcHR2pVKkSEyZMoG3btrRp08bA1ZeAobdTGavFixcrXl5eioWFhdK6dWvl5MmThi5J/I0BAwYobm5uioWFheLh4aEMGDBACQ8PN3RZQlGUX3/9VQEe+xgyZIiiKOr27Pfff19xcXFRLC0tlc6dOythYWGGLbqcetLPKjMzU3n22WeVqlWrKubm5oq3t7cycuRIJS4uztBll0t/93MClLVr1xY+JysrSxk7dqzi4OCg2NjYKC+99JISGxtruKK1wERRFEX/EUoIIYQQQjtkzYwQQgghjJqEGSGEEEIYNQkzQgghhDBqEmaEEEIIYdQkzAghhBDCqEmYEUIIIYRRkzAjhBBCCKMmYUYIIYQQRk3CjBBC50xMTJ748eGHHxq6RCGEEZOzmYQQOhcbG1t4e/PmzXzwwQeEhYUV3mdnZ2eIsoQQZYRcmRFC6Jyrq2vhh729PSYmJo/c9/3339OgQQOsrKyoX78+S5cuLfzamzdvYmJiwpYtW+jQoQPW1tb4+vpy7do1zpw5Q6tWrbCzs6NHjx4kJiYWft3QoUPp3bs3s2fPpmrVqlSqVInRo0eTm5tb+JycnBwmTpyIs7MzVlZWtG/fnjNnzuj1z0YIUXISZoQQBvXdd9/xwQcf8Mknn3DlyhXmzJnD+++/z/r16x953qxZs5g5cybnz5+nQoUKDBo0iOnTp/Pll19y9OhRwsPD+eCDDx75msOHD3PlyhUCAwPZtGkT27dvZ/bs2YWPT58+nR9++IH169dz/vz5wpOek5OT9fK9CyG0xNAnXQohype1a9cq9vb2hZ/XqlVL2bhx4yPP+eijj5S2bdsqiqIokZGRCqCsXr268PFNmzYpgHL48OHC++bOnavUq1ev8PMhQ4Yojo6OSkZGRuF9y5YtU+zs7JSCggIlPT1dMTc3V7777rvCx3NzcxV3d3dl/vz5Wvt+hRC6J2tmhBAGk5GRQUREBMOHD2fkyJGF9+fn52Nvb//Ic5s2bVp428XFBYAmTZo8cl9CQsIjX+Pj44ONjU3h523btiU9PZ07d+6QmppKXl4e7dq1K3zc3Nyc1q1bc+XKFe18g0IIvZAwI4QwmPT0dABWrVqFn5/fI4+ZmZk98rm5uXnhbRMTk7+9T6PR6KpUIUQpJmtmhBAG4+Ligru7Ozdu3KB27dqPfNSoUaPE44eGhpKVlVX4+cmTJ7Gzs6NatWrUqlULCwsLjh8/Xvh4Xl4eZ86coWHDhiV+bSGE/siVGSGEQc2ePZuJEydib29P9+7dycnJ4ezZs9y7d48pU6aUaOzc3FyGDx/OzJkzuXnzJrNmzWL8+PGYmppia2vLmDFjmDZtGo6Ojnh5eTF//nwyMzMZPny4lr47IYQ+SJgRQhjUiBEjsLGxYcGCBUybNg1bW1uaNGnCpEmTSjx2586dqVOnDh07diQnJ4dXXnnlkQZ98+bNQ6PR8Prrr3P//n1atWrFgQMHcHBwKPFrCyH0x0RRFMXQRQghhLYNHTqUlJQUdu7caehShBA6JmtmhBBCCGHUJMwIIYQQwqjJNJMQQgghjJpcmRFCCCGEUZMwI4QQQgijJmFGCCGEEEZNwowQQgghjJqEGSGEEEIYNQkzQgghhDBqEmaEEEIIYdQkzAghhBDCqEmYEUIIIYRR+38YOT5UBOEArAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_open, color='red', label='Preço de Abertura Real')\n",
    "plt.plot(y_high, color='black', label='Preço Alta Real')\n",
    "\n",
    "plt.plot(prevs, color='blue', label='Previsões Abertura')\n",
    "plt.plot(prevs, color='orange', label='Previsões Alta')\n",
    "\n",
    "plt.title('Previsão dos preços das ações')\n",
    "\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Valor')\n",
    "\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
